"""
è¯­ä¹‰è®°å¿†æå–å™¨ - åŸºäºè”æƒ³é¢„æµ‹æ–¹æ³•
ä»MemCellä¸­ç”Ÿæˆå¯¹ç”¨æˆ·æœªæ¥ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“é¢„æµ‹
"""

import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

# ä½¿ç”¨åŠ¨æ€è¯­è¨€æç¤ºè¯å¯¼å…¥ï¼ˆæ ¹æ® MEMORY_LANGUAGE ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©ï¼‰
from ..prompts import (
    get_group_semantic_generation_prompt,
    get_semantic_generation_prompt,
)
from ..llm.llm_provider import LLMProvider
from .base_memory_extractor import MemoryExtractor, MemoryExtractRequest
from ..types import MemoryType, MemCell, Memory, SemanticMemoryItem
from agentic_layer.vectorize_service import get_vectorize_service
from core.observation.logger import get_logger

logger = get_logger(__name__)


class SemanticMemoryExtractor(MemoryExtractor):
    """
    è¯­ä¹‰è®°å¿†æå–å™¨ - åŸºäºè”æƒ³é¢„æµ‹æ–¹æ³•

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. use_group_prompt=False: åŸºäºEpisodeMemoryå¯¹è±¡ç”Ÿæˆè”æƒ³ï¼Œè¿”å›çš„EpisodeMemoryå¯¹è±¡ä¸­æ·»åŠ semantic_memorieså­—æ®µ
    2. use_group_prompt=True: åŸºäºMemCellå¯¹è±¡ç”Ÿæˆè”æƒ³ï¼Œè¿”å›çš„MemCellå¯¹è±¡ä¸­æ·»åŠ semantic_memorieså­—æ®µ

    æ–°çš„ç­–ç•¥å®ç°ï¼š
    1. åŸºäºå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“
    2. æ¯æ¡è”æƒ³è€ƒè™‘å¯èƒ½äº§ç”Ÿçš„æŒç»­æ—¶é—´
    3. é‡ç‚¹å…³æ³¨ç”¨æˆ·ä¸ªäººå±‚é¢çš„å½±å“

    ä¸»è¦æ–¹æ³•ï¼š
    - generate_semantic_memories_for_memcell(): ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³
    - generate_semantic_memories_for_episode(): ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³
    """

    def __init__(self, llm_provider: LLMProvider):
        """
        åˆå§‹åŒ–è¯­ä¹‰è®°å¿†æå–å™¨

        Args:
            llm_provider: LLMæä¾›è€…
        """
        super().__init__(MemoryType.SEMANTIC_MEMORY)
        self.llm_provider = llm_provider

        logger.info("è¯­ä¹‰è®°å¿†æå–å™¨å·²åˆå§‹åŒ–ï¼ˆè”æƒ³é¢„æµ‹æ¨¡å¼ï¼‰")

    async def extract_memory(self, request: MemoryExtractRequest) -> Optional[Memory]:
        """
        å®ç°æŠ½è±¡åŸºç±»è¦æ±‚çš„ extract_memory æ–¹æ³•

        æ³¨æ„ï¼šSemanticMemoryExtractor ä¸åº”è¯¥ç›´æ¥ä½¿ç”¨ extract_memory æ–¹æ³•
        åº”è¯¥ä½¿ç”¨ generate_semantic_memories_for_memcell æˆ– generate_semantic_memories_for_episode

        Args:
            request: è®°å¿†æå–è¯·æ±‚

        Returns:
            None - æ­¤æ–¹æ³•ä¸åº”è¯¥è¢«è°ƒç”¨
        """
        raise NotImplementedError(
            "SemanticMemoryExtractor ä¸åº”è¯¥ç›´æ¥ä½¿ç”¨ extract_memory æ–¹æ³•ã€‚"
            "è¯·ä½¿ç”¨ generate_semantic_memories_for_memcell æˆ– generate_semantic_memories_for_episode æ–¹æ³•ã€‚"
        )

    async def generate_semantic_memories_for_memcell(
        self, memcell: MemCell
    ) -> List[SemanticMemoryItem]:
        """
        ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é¢„æµ‹

        è¿™æ˜¯æ–°çš„ç­–ç•¥ï¼šåŸºäºMemCellå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“

        Args:
            memcell: MemCellå¯¹è±¡

        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨ï¼ˆ10æ¡ï¼‰ï¼ŒåŒ…å«æ—¶é—´ä¿¡æ¯
        """
        try:
            logger.info(f"ğŸ¯ ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³: {memcell.subject}")

            # æ„å»ºæç¤ºè¯
            prompt = get_group_semantic_generation_prompt(
                memcell_summary=memcell.summary,
                memcell_episode=memcell.episode or "",
                user_ids=memcell.user_id_list,
            )

            # è°ƒç”¨LLMç”Ÿæˆè”æƒ³
            logger.debug(f"ğŸ“ å¼€å§‹è°ƒç”¨LLMç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³ï¼Œæç¤ºè¯é•¿åº¦: {len(prompt)}")
            response = await self.llm_provider.generate(prompt=prompt, temperature=0.3)
            logger.debug(
                f"âœ… LLMè°ƒç”¨å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}"
            )

            # è§£æJSONå“åº”
            start_time = self._extract_start_time_from_timestamp(memcell.timestamp)
            semantic_memories = await self._parse_semantic_memories_response(
                response, memcell.event_id, start_time
            )

            # ç¡®ä¿è¿”å›æ°å¥½10æ¡
            if len(semantic_memories) > 10:
                semantic_memories = semantic_memories[:10]
            elif len(semantic_memories) < 10:
                logger.warning(
                    f"ç”Ÿæˆçš„è¯­ä¹‰è®°å¿†è”æƒ³æ•°é‡ä¸è¶³10æ¡ï¼Œå®é™…ç”Ÿæˆ: {len(semantic_memories)}"
                )

            logger.info(f"æˆåŠŸç”Ÿæˆ {len(semantic_memories)} æ¡è¯­ä¹‰è®°å¿†è”æƒ³")
            for i, memory in enumerate(semantic_memories[:3], 1):
                logger.info(f"  è”æƒ³{i}: {memory.content}")

            return semantic_memories

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³æ—¶å‡ºé”™: {e}")
            import traceback

            traceback.print_exc()
            return []

    async def generate_semantic_memories_for_episode(
        self, episode: Memory
    ) -> List[SemanticMemoryItem]:
        """
        ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é¢„æµ‹

        è¿™æ˜¯ä¸ªäººæ¨¡å¼ï¼šåŸºäºEpisodeMemoryå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“

        Args:
            episode: EpisodeMemoryå¯¹è±¡

        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨ï¼ˆ10æ¡ï¼‰ï¼ŒåŒ…å«æ—¶é—´ä¿¡æ¯
        """
        try:
            logger.info(f"ğŸ¯ ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³: {episode.subject}")

            # æ„å»ºæç¤ºè¯
            # ç›´æ¥ä½¿ç”¨episodeçš„user_id
            prompt = get_semantic_generation_prompt(
                episode_memory=episode.summary or "",
                episode_content=episode.episode or "",
                user_id=episode.user_id,
            )

            # è°ƒç”¨LLMç”Ÿæˆè”æƒ³
            response = await self.llm_provider.generate(prompt=prompt, temperature=0.3)

            # è§£æJSONå“åº”
            source_episode_id = (
                episode.ori_event_id_list[0] if episode.ori_event_id_list else None
            )
            start_time = self._extract_start_time_from_timestamp(episode.timestamp)
            semantic_memories = await self._parse_semantic_memories_response(
                response, source_episode_id, start_time
            )

            # ç¡®ä¿è¿”å›æ°å¥½10æ¡
            if len(semantic_memories) > 10:
                semantic_memories = semantic_memories[:10]
            elif len(semantic_memories) < 10:
                logger.warning(
                    f"ç”Ÿæˆçš„è¯­ä¹‰è®°å¿†è”æƒ³æ•°é‡ä¸è¶³10æ¡ï¼Œå®é™…ç”Ÿæˆ: {len(semantic_memories)}"
                )

            logger.info(f"æˆåŠŸç”Ÿæˆ {len(semantic_memories)} æ¡è¯­ä¹‰è®°å¿†è”æƒ³")
            for i, memory in enumerate(semantic_memories[:3], 1):
                logger.info(f"  è”æƒ³{i}: {memory.content}")

            return semantic_memories

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³æ—¶å‡ºé”™: {e}")
            import traceback

            traceback.print_exc()
            return []

    @staticmethod
    def _clean_date_string(date_str: Optional[str]) -> Optional[str]:
        """æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²ï¼Œç§»é™¤éæ³•å­—ç¬¦

        Args:
            date_str: åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²

        Returns:
            æ¸…ç†åçš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ•ˆåˆ™è¿”å› None
        """
        if not date_str or not isinstance(date_str, str):
            return None

        import re

        # åªä¿ç•™æ•°å­—å’Œè¿å­—ç¬¦ï¼Œç§»é™¤å…¶ä»–å­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ã€ç©ºæ ¼ç­‰ï¼‰
        cleaned = re.sub(r'[^\d\-]', '', date_str)

        # éªŒè¯æ ¼å¼æ˜¯å¦ä¸º YYYY-MM-DD
        if re.match(r'^\d{4}-\d{2}-\d{2}$', cleaned):
            return cleaned
        else:
            logger.warning(
                f"æ—¶é—´æ ¼å¼æ— æ•ˆï¼Œå·²æ¸…ç†ä½†ä»ä¸ç¬¦åˆ YYYY-MM-DD: åŸå§‹='{date_str}', æ¸…ç†å='{cleaned}'"
            )
            return None

    async def _parse_semantic_memories_response(
        self,
        response: str,
        source_episode_id: Optional[str] = None,
        start_time: Optional[str] = None,
    ) -> List[SemanticMemoryItem]:
        """
        è§£æLLMçš„JSONå“åº”ï¼Œæå–è¯­ä¹‰è®°å¿†è”æƒ³åˆ—è¡¨

        Args:
            response: LLMå“åº”æ–‡æœ¬
            source_episode_id: æ¥æºäº‹ä»¶ID
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD

        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨
        """
        try:
            # é¦–å…ˆå°è¯•æå–ä»£ç å—ä¸­çš„JSON
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end > start:
                    json_str = response[start:end].strip()
                    data = json.loads(json_str)
                else:
                    data = json.loads(response)
            else:
                # å°è¯•è§£ææ•´ä¸ªå“åº”ä¸ºJSONæ•°ç»„
                data = json.loads(response)

            # ç¡®ä¿dataæ˜¯åˆ—è¡¨
            if isinstance(data, list):
                semantic_memories = []

                for item in data:

                    content = item.get('content', '')
                    evidence = item.get('evidence', '')  # â† è¯»å– evidence

                    # ä½¿ç”¨ä¼ å…¥çš„start_timeæˆ–LLMæä¾›çš„æ—¶é—´
                    item_start_time = item.get('start_time', start_time)
                    item_end_time = item.get('end_time')
                    item_duration_days = item.get('duration_days')

                    # æ¸…ç†æ—¶é—´æ ¼å¼ï¼ˆé˜²æ­¢ LLM è¾“å‡ºé”™è¯¯çš„æ ¼å¼ï¼‰
                    item_start_time = self._clean_date_string(item_start_time)
                    item_end_time = self._clean_date_string(item_end_time)

                    # æ™ºèƒ½æ—¶é—´è®¡ç®—ï¼šä¼˜å…ˆä½¿ç”¨LLMæä¾›çš„æ—¶é—´ä¿¡æ¯
                    if item_start_time:
                        # å¦‚æœLLMæä¾›äº†duration_daysä½†æ²¡æœ‰end_timeï¼Œè®¡ç®—end_time
                        if item_duration_days and not item_end_time:
                            item_end_time = self._calculate_end_time_from_duration(
                                item_start_time, item_duration_days
                            )
                        # å¦‚æœLLMæä¾›äº†end_timeä½†æ²¡æœ‰duration_daysï¼Œè®¡ç®—duration_days
                        elif item_end_time and not item_duration_days:
                            item_duration_days = self._calculate_duration_days(
                                item_start_time, item_end_time
                            )
                        # å¦‚æœLLMéƒ½æ²¡æœ‰æä¾›ï¼Œåˆ™ä¿æŒä¸ºNoneï¼ˆä¸è¿›è¡Œé¢å¤–æå–ï¼‰

                    vs = get_vectorize_service()
                    vec = await vs.get_embedding(content)
                    # åˆ›å»ºSemanticMemoryItemå¯¹è±¡
                    memory_item = SemanticMemoryItem(
                        content=content,
                        evidence=evidence,  # â† æ·»åŠ  evidence å­—æ®µ
                        start_time=item_start_time,
                        end_time=item_end_time,
                        duration_days=item_duration_days,
                        source_episode_id=item.get(
                            'source_episode_id', source_episode_id
                        ),
                        embedding=vec.tolist(),
                    )

                    semantic_memories.append(memory_item)

                return semantic_memories
            else:
                logger.error(f"å“åº”ä¸æ˜¯JSONæ•°ç»„æ ¼å¼: {data}")
                return []

        except json.JSONDecodeError as e:
            logger.error(f"è§£æJSONå“åº”æ—¶å‡ºé”™: {e}")
            logger.debug(f"å“åº”å†…å®¹: {response[:200]}...")
            return []
        except Exception as e:
            logger.error(f"è§£æè¯­ä¹‰è®°å¿†å“åº”æ—¶å‡ºé”™: {e}")
            return []

    def _extract_start_time_from_timestamp(self, timestamp: datetime) -> str:
        """
        ä»MemCellçš„timestampå­—æ®µæå–å¼€å§‹æ—¶é—´

        Args:
            timestamp: MemCellçš„æ—¶é—´æˆ³

        Returns:
            å¼€å§‹æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
        """
        return timestamp.strftime('%Y-%m-%d')

    def _calculate_end_time_from_duration(
        self, start_time: str, duration_days: int
    ) -> Optional[str]:
        """
        æ ¹æ®å¼€å§‹æ—¶é—´å’ŒæŒç»­æ—¶é—´è®¡ç®—ç»“æŸæ—¶é—´

        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
            duration_days: æŒç»­å¤©æ•°

        Returns:
            ç»“æŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›None
        """
        try:
            if not start_time or duration_days is None:
                return None

            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            end_date = start_date + timedelta(days=duration_days)

            return end_date.strftime('%Y-%m-%d')

        except Exception as e:
            logger.error(f"æ ¹æ®æŒç»­æ—¶é—´è®¡ç®—ç»“æŸæ—¶é—´æ—¶å‡ºé”™: {e}")
            return None

    def _calculate_duration_days(self, start_time: str, end_time: str) -> Optional[int]:
        """
        è®¡ç®—æŒç»­æ—¶é—´ï¼ˆå¤©æ•°ï¼‰

        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
            end_time: ç»“æŸæ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD

        Returns:
            æŒç»­å¤©æ•°ï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›None
        """
        try:
            if not start_time or not end_time:
                return None

            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            end_date = datetime.strptime(end_time, '%Y-%m-%d')

            duration = end_date - start_date
            return duration.days

        except Exception as e:
            logger.error(f"è®¡ç®—æŒç»­æ—¶é—´æ—¶å‡ºé”™: {e}")
            return None
