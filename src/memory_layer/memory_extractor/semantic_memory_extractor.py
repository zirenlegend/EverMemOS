"""
è¯­ä¹‰è®°å¿†æå–å™¨ - åŸºäºè”æƒ³é¢„æµ‹æ–¹æ³•
ä»MemCellä¸­ç”Ÿæˆå¯¹ç”¨æˆ·æœªæ¥ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“é¢„æµ‹
"""

import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

# ä½¿ç”¨åŠ¨æ€è¯­è¨€æç¤ºè¯å¯¼å…¥ï¼ˆæ ¹æ® MEMORY_LANGUAGE ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©ï¼‰
from ..prompts import (
    get_group_semantic_generation_prompt,
    get_semantic_generation_prompt,
)
from ..llm.llm_provider import LLMProvider
from .base_memory_extractor import MemoryExtractor, MemoryExtractRequest
from api_specs.memory_types import MemoryType, MemCell, Memory, SemanticMemoryItem
from agentic_layer.vectorize_service import get_vectorize_service
from core.observation.logger import get_logger

logger = get_logger(__name__)


class SemanticMemoryExtractor(MemoryExtractor):
    """
    è¯­ä¹‰è®°å¿†æå–å™¨ - åŸºäºè”æƒ³é¢„æµ‹æ–¹æ³•

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. use_group_prompt=False: åŸºäºEpisodeMemoryå¯¹è±¡ç”Ÿæˆè”æƒ³ï¼Œè¿”å›çš„EpisodeMemoryå¯¹è±¡ä¸­æ·»åŠ semantic_memorieså­—æ®µ
    2. use_group_prompt=True: åŸºäºMemCellå¯¹è±¡ç”Ÿæˆè”æƒ³ï¼Œè¿”å›çš„MemCellå¯¹è±¡ä¸­æ·»åŠ semantic_memorieså­—æ®µ

    æ–°çš„ç­–ç•¥å®ç°ï¼š
    1. åŸºäºå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“
    2. æ¯æ¡è”æƒ³è€ƒè™‘å¯èƒ½äº§ç”Ÿçš„æŒç»­æ—¶é—´
    3. é‡ç‚¹å…³æ³¨ç”¨æˆ·ä¸ªäººå±‚é¢çš„å½±å“

    ä¸»è¦æ–¹æ³•ï¼š
    - generate_semantic_memories_for_memcell(): ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³
    - generate_semantic_memories_for_episode(): ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³
    """

    def __init__(self, llm_provider: LLMProvider):
        """
        åˆå§‹åŒ–è¯­ä¹‰è®°å¿†æå–å™¨

        Args:
            llm_provider: LLMæä¾›è€…
        """
        super().__init__(MemoryType.SEMANTIC_MEMORY)
        self.llm_provider = llm_provider

        logger.info("è¯­ä¹‰è®°å¿†æå–å™¨å·²åˆå§‹åŒ–ï¼ˆè”æƒ³é¢„æµ‹æ¨¡å¼ï¼‰")

    async def extract_memory(self, request: MemoryExtractRequest) -> Optional[Memory]:
        """
        å®ç°æŠ½è±¡åŸºç±»è¦æ±‚çš„ extract_memory æ–¹æ³•

        æ³¨æ„ï¼šSemanticMemoryExtractor ä¸åº”è¯¥ç›´æ¥ä½¿ç”¨ extract_memory æ–¹æ³•
        åº”è¯¥ä½¿ç”¨ generate_semantic_memories_for_memcell æˆ– generate_semantic_memories_for_episode

        Args:
            request: è®°å¿†æå–è¯·æ±‚

        Returns:
            None - æ­¤æ–¹æ³•ä¸åº”è¯¥è¢«è°ƒç”¨
        """
        raise NotImplementedError(
            "SemanticMemoryExtractor ä¸åº”è¯¥ç›´æ¥ä½¿ç”¨ extract_memory æ–¹æ³•ã€‚"
            "è¯·ä½¿ç”¨ generate_semantic_memories_for_memcell æˆ– generate_semantic_memories_for_episode æ–¹æ³•ã€‚"
        )

    async def generate_semantic_memories_for_memcell(
        self, memcell: MemCell
    ) -> List[SemanticMemoryItem]:
        """
        ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é¢„æµ‹
        
        è¿™æ˜¯æ–°çš„ç­–ç•¥ï¼šåŸºäºMemCellå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“
        
        Args:
            memcell: MemCellå¯¹è±¡
        
        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨ï¼ˆ10æ¡ï¼‰ï¼ŒåŒ…å«æ—¶é—´ä¿¡æ¯
        """
        # æœ€å¤šé‡è¯•5æ¬¡
        for retry in range(5):
            try:
                logger.info(f"ğŸ¯ ä¸ºMemCellç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³: {memcell.subject}ï¼Œé‡è¯•æ¬¡æ•°: {retry+1}/5")

                # æ„å»ºæç¤ºè¯
                prompt = get_group_semantic_generation_prompt(
                    memcell_summary=memcell.summary,
                    memcell_episode=memcell.episode or "",
                    user_ids=memcell.user_id_list,
                )

                # è°ƒç”¨LLMç”Ÿæˆè”æƒ³
                logger.debug(f"ğŸ“ å¼€å§‹è°ƒç”¨LLMç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³ï¼Œæç¤ºè¯é•¿åº¦: {len(prompt)}")
                response = await self.llm_provider.generate(prompt=prompt, temperature=0.3)
                logger.debug(
                    f"âœ… LLMè°ƒç”¨å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}"
                )

                # è§£æJSONå“åº”
                start_time = self._extract_start_time_from_timestamp(memcell.timestamp)
                semantic_memories = await self._parse_semantic_memories_response(
                    response, memcell.event_id, start_time
                )

                # éªŒè¯å¿…é¡»è‡³å°‘æœ‰1æ¡
                if len(semantic_memories) == 0:
                    raise ValueError("LLMè¿”å›çš„è¯­ä¹‰è®°å¿†åˆ—è¡¨ä¸ºç©º")

                # ç¡®ä¿è¿”å›æ°å¥½10æ¡ï¼ˆä¸è¶³åˆ™è­¦å‘Šï¼Œä½†ä¸é‡è¯•ï¼‰
                if len(semantic_memories) > 10:
                    semantic_memories = semantic_memories[:10]
                elif len(semantic_memories) < 10:
                    logger.warning(
                        f"ç”Ÿæˆçš„è¯­ä¹‰è®°å¿†è”æƒ³æ•°é‡ä¸è¶³10æ¡ï¼Œå®é™…ç”Ÿæˆ: {len(semantic_memories)}"
                    )

                logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(semantic_memories)} æ¡è¯­ä¹‰è®°å¿†è”æƒ³")
                for i, memory in enumerate(semantic_memories[:3], 1):
                    logger.info(f"  è”æƒ³{i}: {memory.content}")

                return semantic_memories

            except Exception as e:
                logger.warning(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é‡è¯• {retry+1}/5: {e}")
                if retry == 4:
                    logger.error(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³å¤±è´¥ï¼Œå·²é‡è¯•5æ¬¡")
                    return []
                continue
        
        return []

    async def generate_semantic_memories_for_episode(
        self, episode: Memory
    ) -> List[SemanticMemoryItem]:
        """
        ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é¢„æµ‹
        
        è¿™æ˜¯ä¸ªäººæ¨¡å¼ï¼šåŸºäºEpisodeMemoryå†…å®¹ï¼Œå¤§æ¨¡å‹è”æƒ³å‡º10æ¡å¯¹ç”¨æˆ·åç»­çš„ç”Ÿæ´»ã€å†³ç­–å¯èƒ½äº§ç”Ÿçš„å½±å“
        
        Args:
            episode: EpisodeMemoryå¯¹è±¡
        
        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨ï¼ˆ10æ¡ï¼‰ï¼ŒåŒ…å«æ—¶é—´ä¿¡æ¯
        """
        # æœ€å¤šé‡è¯•5æ¬¡
        for retry in range(5):
            try:
                logger.info(f"ğŸ¯ ä¸ºEpisodeMemoryç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³: {episode.subject}ï¼Œé‡è¯•æ¬¡æ•°: {retry+1}/5")

                # æ„å»ºæç¤ºè¯
                # ç›´æ¥ä½¿ç”¨episodeçš„user_id
                prompt = get_semantic_generation_prompt(
                    episode_memory=episode.summary or "",
                    episode_content=episode.episode or "",
                    user_id=episode.user_id,
                )

                # è°ƒç”¨LLMç”Ÿæˆè”æƒ³
                response = await self.llm_provider.generate(prompt=prompt, temperature=0.3)

                # è§£æJSONå“åº”
                source_episode_id = (
                    episode.ori_event_id_list[0] if episode.ori_event_id_list else None
                )
                start_time = self._extract_start_time_from_timestamp(episode.timestamp)
                semantic_memories = await self._parse_semantic_memories_response(
                    response, source_episode_id, start_time
                )

                # éªŒè¯å¿…é¡»è‡³å°‘æœ‰1æ¡
                if len(semantic_memories) == 0:
                    raise ValueError("LLMè¿”å›çš„è¯­ä¹‰è®°å¿†åˆ—è¡¨ä¸ºç©º")

                # ç¡®ä¿è¿”å›æ°å¥½10æ¡ï¼ˆä¸è¶³åˆ™è­¦å‘Šï¼Œä½†ä¸é‡è¯•ï¼‰
                if len(semantic_memories) > 10:
                    semantic_memories = semantic_memories[:10]
                elif len(semantic_memories) < 10:
                    logger.warning(
                        f"ç”Ÿæˆçš„è¯­ä¹‰è®°å¿†è”æƒ³æ•°é‡ä¸è¶³10æ¡ï¼Œå®é™…ç”Ÿæˆ: {len(semantic_memories)}"
                    )

                logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(semantic_memories)} æ¡è¯­ä¹‰è®°å¿†è”æƒ³")
                for i, memory in enumerate(semantic_memories[:3], 1):
                    logger.info(f"  è”æƒ³{i}: {memory.content}")

                return semantic_memories

            except Exception as e:
                logger.warning(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³é‡è¯• {retry+1}/5: {e}")
                if retry == 4:
                    logger.error(f"ç”Ÿæˆè¯­ä¹‰è®°å¿†è”æƒ³å¤±è´¥ï¼Œå·²é‡è¯•5æ¬¡")
                    return []
                continue
        
        return []

    @staticmethod
    def _clean_date_string(date_str: Optional[str]) -> Optional[str]:
        """æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²ï¼Œç§»é™¤éæ³•å­—ç¬¦å¹¶éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§

        Args:
            date_str: åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²

        Returns:
            æ¸…ç†åçš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ•ˆåˆ™è¿”å› None
        """
        if not date_str or not isinstance(date_str, str):
            return None

        import re

        # åªä¿ç•™æ•°å­—å’Œè¿å­—ç¬¦ï¼Œç§»é™¤å…¶ä»–å­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ã€ç©ºæ ¼ç­‰ï¼‰
        cleaned = re.sub(r'[^\d\-]', '', date_str)

        # éªŒè¯æ ¼å¼æ˜¯å¦ä¸º YYYY-MM-DD
        if not re.match(r'^\d{4}-\d{2}-\d{2}$', cleaned):
            logger.warning(
                f"æ—¶é—´æ ¼å¼æ— æ•ˆï¼Œä¸ç¬¦åˆ YYYY-MM-DD: åŸå§‹='{date_str}', æ¸…ç†å='{cleaned}'"
            )
            return None
        
        # éªŒè¯æ—¥æœŸå€¼æ˜¯å¦åˆæ³•ï¼ˆæœˆä»½ 1-12ï¼Œæ—¥æœŸ 1-31 ç­‰ï¼‰
        try:
            year, month, day = map(int, cleaned.split('-'))
            # ä½¿ç”¨ datetime éªŒè¯æ—¥æœŸåˆæ³•æ€§
            datetime(year, month, day)
            return cleaned
        except ValueError as e:
            logger.warning(
                f"æ—¥æœŸå€¼æ— æ•ˆ: '{cleaned}', é”™è¯¯: {e}"
            )
            return None

    async def _parse_semantic_memories_response(
        self,
        response: str,
        source_episode_id: Optional[str] = None,
        start_time: Optional[str] = None,
    ) -> List[SemanticMemoryItem]:
        """
        è§£æLLMçš„JSONå“åº”ï¼Œæå–è¯­ä¹‰è®°å¿†è”æƒ³åˆ—è¡¨

        Args:
            response: LLMå“åº”æ–‡æœ¬
            source_episode_id: æ¥æºäº‹ä»¶ID
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD

        Returns:
            è¯­ä¹‰è®°å¿†è”æƒ³é¡¹ç›®åˆ—è¡¨
        """
        try:
            # é¦–å…ˆå°è¯•æå–ä»£ç å—ä¸­çš„JSON
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end > start:
                    json_str = response[start:end].strip()
                    data = json.loads(json_str)
                else:
                    data = json.loads(response)
            else:
                # å°è¯•è§£ææ•´ä¸ªå“åº”ä¸ºJSONæ•°ç»„
                data = json.loads(response)

            # ç¡®ä¿dataæ˜¯åˆ—è¡¨
            if isinstance(data, list):
                semantic_memories = []
                
                # å…ˆæ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ•°æ®
                items_to_process = []
                for item in data:
                    content = item.get('content', '')
                    evidence = item.get('evidence', '')

                    # ä½¿ç”¨ä¼ å…¥çš„start_timeæˆ–LLMæä¾›çš„æ—¶é—´
                    item_start_time = item.get('start_time', start_time)
                    item_end_time = item.get('end_time')
                    item_duration_days = item.get('duration_days')

                    # æ¸…ç†æ—¶é—´æ ¼å¼ï¼ˆé˜²æ­¢ LLM è¾“å‡ºé”™è¯¯çš„æ ¼å¼ï¼‰
                    item_start_time = self._clean_date_string(item_start_time)
                    item_end_time = self._clean_date_string(item_end_time)

                    # æ™ºèƒ½æ—¶é—´è®¡ç®—ï¼šä¼˜å…ˆä½¿ç”¨LLMæä¾›çš„æ—¶é—´ä¿¡æ¯
                    if item_start_time:
                        # å¦‚æœLLMæä¾›äº†duration_daysä½†æ²¡æœ‰end_timeï¼Œè®¡ç®—end_time
                        if item_duration_days and not item_end_time:
                            item_end_time = self._calculate_end_time_from_duration(
                                item_start_time, item_duration_days
                            )
                        # å¦‚æœLLMæä¾›äº†end_timeä½†æ²¡æœ‰duration_daysï¼Œè®¡ç®—duration_days
                        elif item_end_time and not item_duration_days:
                            item_duration_days = self._calculate_duration_days(
                                item_start_time, item_end_time
                            )
                        # å¦‚æœLLMéƒ½æ²¡æœ‰æä¾›ï¼Œåˆ™ä¿æŒä¸ºNoneï¼ˆä¸è¿›è¡Œé¢å¤–æå–ï¼‰

                    items_to_process.append({
                        'content': content,
                        'evidence': evidence,
                        'start_time': item_start_time,
                        'end_time': item_end_time,
                        'duration_days': item_duration_days,
                        'source_episode_id': item.get('source_episode_id', source_episode_id),
                    })

                # æ‰¹é‡è®¡ç®—æ‰€æœ‰ content çš„ embeddingsï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
                vs = get_vectorize_service()
                contents = [item['content'] for item in items_to_process]
                vectors_batch = await vs.get_embeddings(contents)  # ä½¿ç”¨ get_embeddings (List[str])
                
                # åˆ›å»ºSemanticMemoryItemå¯¹è±¡
                for i, item_data in enumerate(items_to_process):
                    # å¤„ç† embeddingï¼šå¯èƒ½æ˜¯ numpy æ•°ç»„æˆ–å·²ç»æ˜¯åˆ—è¡¨
                    vector = vectors_batch[i]
                    if hasattr(vector, 'tolist'):
                        vector = vector.tolist()
                    elif not isinstance(vector, list):
                        vector = list(vector)
                    
                    memory_item = SemanticMemoryItem(
                        content=item_data['content'],
                        evidence=item_data['evidence'],
                        start_time=item_data['start_time'],
                        end_time=item_data['end_time'],
                        duration_days=item_data['duration_days'],
                        source_episode_id=item_data['source_episode_id'],
                        vector=vector,
                        vector_model=vs.get_model_name(),
                    )
                    semantic_memories.append(memory_item)

                return semantic_memories
            else:
                logger.error(f"å“åº”ä¸æ˜¯JSONæ•°ç»„æ ¼å¼: {data}")
                return []

        except json.JSONDecodeError as e:
            logger.error(f"è§£æJSONå“åº”æ—¶å‡ºé”™: {e}")
            logger.debug(f"å“åº”å†…å®¹: {response[:200]}...")
            return []
        except Exception as e:
            logger.error(f"è§£æè¯­ä¹‰è®°å¿†å“åº”æ—¶å‡ºé”™: {e}")
            return []

    def _extract_start_time_from_timestamp(self, timestamp: datetime) -> str:
        """
        ä»MemCellçš„timestampå­—æ®µæå–å¼€å§‹æ—¶é—´

        Args:
            timestamp: MemCellçš„æ—¶é—´æˆ³

        Returns:
            å¼€å§‹æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
        """
        return timestamp.strftime('%Y-%m-%d')

    def _calculate_end_time_from_duration(
        self, start_time: str, duration_days: int
    ) -> Optional[str]:
        """
        æ ¹æ®å¼€å§‹æ—¶é—´å’ŒæŒç»­æ—¶é—´è®¡ç®—ç»“æŸæ—¶é—´

        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
            duration_days: æŒç»­å¤©æ•°

        Returns:
            ç»“æŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›None
        """
        try:
            if not start_time or duration_days is None:
                return None

            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            end_date = start_date + timedelta(days=duration_days)

            return end_date.strftime('%Y-%m-%d')

        except Exception as e:
            logger.error(f"æ ¹æ®æŒç»­æ—¶é—´è®¡ç®—ç»“æŸæ—¶é—´æ—¶å‡ºé”™: {e}")
            return None

    def _calculate_duration_days(self, start_time: str, end_time: str) -> Optional[int]:
        """
        è®¡ç®—æŒç»­æ—¶é—´ï¼ˆå¤©æ•°ï¼‰

        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
            end_time: ç»“æŸæ—¶é—´ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD

        Returns:
            æŒç»­å¤©æ•°ï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›None
        """
        try:
            if not start_time or not end_time:
                return None

            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            end_date = datetime.strptime(end_time, '%Y-%m-%d')

            duration = end_date - start_date
            return duration.days

        except Exception as e:
            logger.error(f"è®¡ç®—æŒç»­æ—¶é—´æ—¶å‡ºé”™: {e}")
            return None
