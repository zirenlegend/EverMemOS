"""
Simple Boundary Detection Base Class for EverMemOS

This module provides a simple and extensible base class for detecting
boundaries in various types of content (conversations, emails, notes, etc.).
"""

import time
import os
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from dataclasses import dataclass
import uuid
import json, re
import asyncio
from common_utils.datetime_utils import (
    from_iso_format as dt_from_iso_format,
    from_timestamp as dt_from_timestamp,
    get_now_with_timezone,
)
from ..llm.llm_provider import LLMProvider
from ..types import RawDataType
from ..prompts.zh.conv_prompts import CONV_BOUNDARY_DETECTION_PROMPT

from ..prompts.eval.conv_prompts import CONV_BOUNDARY_DETECTION_PROMPT as EVAL_CONV_BOUNDARY_DETECTION_PROMPT
from .base_memcell_extractor import (
    MemCellExtractor,
    RawData,
    MemCell,
    StatusResult,
    MemCellExtractRequest,
)
from ..memory_extractor.episode_memory_extractor import (
    EpisodeMemoryExtractor,
    EpisodeMemoryExtractRequest,
)
from core.observation.logger import get_logger
from agentic_layer.vectorize_service import get_vectorize_service

logger = get_logger(__name__)


@dataclass
class BoundaryDetectionResult:
    """Boundary detection result."""

    should_end: bool
    should_wait: bool
    reasoning: str
    confidence: float
    topic_summary: Optional[str] = None


@dataclass
class ConversationMemCellExtractRequest(MemCellExtractRequest):
    pass


class ConvMemCellExtractor(MemCellExtractor):
    def __init__(
        self,
        llm_provider=LLMProvider,
        use_eval_prompts: bool = False,
    ):
        # Ensure base class receives the correct raw_data_type and provider
        super().__init__(RawDataType.CONVERSATION, llm_provider)
        self.llm_provider = llm_provider
        self.use_eval_prompts = use_eval_prompts
        self.episode_extractor = EpisodeMemoryExtractor(llm_provider, use_eval_prompts)
        
        if use_eval_prompts:
            self.conv_boundary_detection_prompt = EVAL_CONV_BOUNDARY_DETECTION_PROMPT
        else:
            self.conv_boundary_detection_prompt = CONV_BOUNDARY_DETECTION_PROMPT

    def shutdown(self) -> None:
        """Cleanup resources."""
        pass

    def _extract_participant_ids(
        self, chat_raw_data_list: List[Dict[str, Any]]
    ) -> List[str]:
        """
        ä»chat_raw_data_listä¸­æå–æ‰€æœ‰å‚ä¸è€…ID

        ä»æ¯ä¸ªå…ƒç´ çš„contentå­—å…¸ä¸­è·å–ï¼š
        1. speaker_idï¼ˆå‘è¨€è€…IDï¼‰
        2. referListä¸­æ‰€æœ‰çš„_idï¼ˆ@æåŠçš„ç”¨æˆ·IDï¼‰

        Args:
            chat_raw_data_list: èŠå¤©åŸå§‹æ•°æ®åˆ—è¡¨

        Returns:
            List[str]: å»é‡åçš„æ‰€æœ‰å‚ä¸è€…IDåˆ—è¡¨
        """
        participant_ids = set()

        for raw_data in chat_raw_data_list:

            # æå–speaker_id
            if 'speaker_id' in raw_data and raw_data['speaker_id']:
                participant_ids.add(raw_data['speaker_id'])

            # æå–referListä¸­çš„æ‰€æœ‰ID
            if 'referList' in raw_data and raw_data['referList']:
                for refer_item in raw_data['referList']:
                    # refer_itemå¯èƒ½æ˜¯å­—å…¸æ ¼å¼ï¼ŒåŒ…å«_idå­—æ®µ
                    if isinstance(refer_item, dict):
                        # å¤„ç†MongoDB ObjectIdæ ¼å¼çš„_id
                        if '_id' in refer_item:
                            refer_id = refer_item['_id']
                            # å¦‚æœæ˜¯ObjectIdå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            if hasattr(refer_id, '__str__'):
                                participant_ids.add(str(refer_id))
                            else:
                                participant_ids.add(refer_id)
                        # ä¹Ÿæ£€æŸ¥æ™®é€šçš„idå­—æ®µ
                        elif 'id' in refer_item:
                            participant_ids.add(refer_item['id'])
                    # å¦‚æœrefer_itemç›´æ¥æ˜¯IDå­—ç¬¦ä¸²
                    elif isinstance(refer_item, str):
                        participant_ids.add(refer_item)

        return list(participant_ids)

    def _format_conversation_dicts(
        self, messages: list[dict[str, str]], include_timestamps: bool = False
    ) -> str:
        """Format conversation from message dictionaries into plain text."""
        lines = []
        for i, msg in enumerate(messages):
            content = msg.get("content", "")
            speaker_name = msg.get("speaker_name", "")
            timestamp = msg.get("timestamp", "")

            if content:
                if include_timestamps and timestamp:
                    try:
                        # å¤„ç†ä¸åŒç±»å‹çš„timestamp
                        if isinstance(timestamp, datetime):
                            # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œç›´æ¥æ ¼å¼åŒ–
                            time_str = timestamp.strftime("%Y-%m-%d %H:%M:%S")
                            lines.append(f"[{time_str}] {speaker_name}: {content}")
                        elif isinstance(timestamp, str):
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆè§£æå†æ ¼å¼åŒ–
                            dt = datetime.fromisoformat(
                                timestamp.replace("Z", "+00:00")
                            )
                            time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                            lines.append(f"[{time_str}] {speaker_name}: {content}")
                        else:
                            # å…¶ä»–ç±»å‹ï¼Œä¸åŒ…å«æ—¶é—´æˆ³
                            lines.append(f"{speaker_name}: {content}")
                    except (ValueError, AttributeError, TypeError):
                        # Fallback if timestamp parsing fails
                        lines.append(f"{speaker_name}: {content}")
                else:
                    lines.append(f"{speaker_name}: {content}")
            else:
                print(msg)
                print(
                    f"[ConversationEpisodeBuilder] Warning: message {i} has no content"
                )
        return "\n".join(lines)

    def _calculate_time_gap(
        self,
        conversation_history: list[dict[str, str]],
        new_messages: list[dict[str, str]],
    ):
        if not conversation_history or not new_messages:
            return "No time gap information available"

        try:
            # Get the last message from history and first new message
            last_history_msg = conversation_history[-1]
            first_new_msg = new_messages[0]

            last_timestamp_str = last_history_msg.get("timestamp", "")
            first_timestamp_str = first_new_msg.get("timestamp", "")

            if not last_timestamp_str or not first_timestamp_str:
                return "No timestamp information available"

            # Parse timestamps - å¤„ç†ä¸åŒç±»å‹çš„timestampã€
            try:
                if isinstance(last_timestamp_str, datetime):
                    last_time = last_timestamp_str
                elif isinstance(last_timestamp_str, str):
                    last_time = datetime.fromisoformat(
                        last_timestamp_str.replace("Z", "+00:00")
                    )
                else:
                    return "Invalid timestamp format for last message"

                if isinstance(first_timestamp_str, datetime):
                    first_time = first_timestamp_str
                elif isinstance(first_timestamp_str, str):
                    first_time = datetime.fromisoformat(
                        first_timestamp_str.replace("Z", "+00:00")
                    )
                else:
                    return "Invalid timestamp format for first message"
            except (ValueError, TypeError):
                return "Failed to parse timestamps"

            # Calculate time difference
            time_diff = first_time - last_time
            total_seconds = time_diff.total_seconds()

            if total_seconds < 0:
                return "Time gap: Messages appear to be out of order"
            elif total_seconds < 60:  # Less than 1 minute
                return f"Time gap: {int(total_seconds)} seconds (immediate response)"
            elif total_seconds < 3600:  # Less than 1 hour
                minutes = int(total_seconds // 60)
                return f"Time gap: {minutes} minutes (recent conversation)"
            elif total_seconds < 86400:  # Less than 1 day
                hours = int(total_seconds // 3600)
                return f"Time gap: {hours} hours (same day, but significant pause)"
            else:  # More than 1 day
                days = int(total_seconds // 86400)
                return f"Time gap: {days} days (long gap, likely new conversation)"

        except (ValueError, KeyError, AttributeError) as e:
            return f"Time gap calculation error: {str(e)}"

    async def _detect_boundary(
        self,
        conversation_history: list[dict[str, str]],
        new_messages: list[dict[str, str]],
    ) -> BoundaryDetectionResult:
        if not conversation_history:
            return BoundaryDetectionResult(
                should_end=False,
                should_wait=False,
                reasoning="First messages in conversation",
                confidence=1.0,
                topic_summary="",
            )
        history_text = self._format_conversation_dicts(
            conversation_history, include_timestamps=True
        )
        new_text = self._format_conversation_dicts(
            new_messages, include_timestamps=True
        )
        time_gap_info = self._calculate_time_gap(conversation_history, new_messages)

        print(
            f"[ConversationEpisodeBuilder] Detect boundary â€“ history tokens: {len(history_text)} new tokens: {len(new_text)} time gap: {time_gap_info}"
        )

        prompt = self.conv_boundary_detection_prompt.format(
            conversation_history=history_text,
            new_messages=new_text,
            time_gap_info=time_gap_info,
        )
        for i in range(5):
            try:
                resp = await self.llm_provider.generate(prompt)
                print(
                    f"[ConversationEpisodeBuilder] Boundary response length: {len(resp)} chars"
                )

                # Parse JSON response from LLM boundary detection
                json_match = re.search(r"\{[^{}]*\}", resp, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                    return BoundaryDetectionResult(
                        should_end=data.get("should_end", False),
                        should_wait=data.get("should_wait", True),
                        reasoning=data.get("reasoning", "No reason provided"),
                        confidence=data.get("confidence", 1.0),
                        topic_summary=data.get("topic_summary", ""),
                    )
                else:
                    return BoundaryDetectionResult(
                        should_end=False,
                        should_wait=True,
                        reasoning="Failed to parse LLM response",
                        confidence=1.0,
                        topic_summary="",
                    )
                break
            except Exception as e:
                print('retry: ', i)
                if i == 4:
                    raise Exception("Boundary detection failed")
                continue

    async def extract_memcell(
        self,
        request: ConversationMemCellExtractRequest,
        use_semantic_extraction: bool = False,
    ) -> tuple[Optional[MemCell], Optional[StatusResult]]:
        history_message_dict_list = []
        for raw_data in request.history_raw_data_list:
            processed_data = self._data_process(raw_data)
            if processed_data is not None:  # è¿‡æ»¤æ‰ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹
                history_message_dict_list.append(processed_data)

        # æ£€æŸ¥æœ€åä¸€æ¡new_raw_dataæ˜¯å¦ä¸ºNone
        if (
            request.new_raw_data_list
            and self._data_process(request.new_raw_data_list[-1]) is None
        ):
            logger.warning(
                f"[ConvMemCellExtractor] æœ€åä¸€æ¡new_raw_dataä¸ºNoneï¼Œè·³è¿‡å¤„ç†"
            )
            status_control_result = StatusResult(should_wait=True)
            return (None, status_control_result)

        new_message_dict_list = []
        for new_raw_data in request.new_raw_data_list:
            processed_data = self._data_process(new_raw_data)
            if processed_data is not None:  # è¿‡æ»¤æ‰ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹
                new_message_dict_list.append(processed_data)

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ¶ˆæ¯å¯å¤„ç†
        if not new_message_dict_list:
            logger.warning(
                f"[ConvMemCellExtractor] æ²¡æœ‰æœ‰æ•ˆçš„æ–°æ¶ˆæ¯å¯å¤„ç†ï¼ˆå¯èƒ½éƒ½è¢«è¿‡æ»¤äº†ï¼‰"
            )
            status_control_result = StatusResult(should_wait=True)
            return (None, status_control_result)

        if request.smart_mask_flag:
            boundary_detection_result = await self._detect_boundary(
                conversation_history=history_message_dict_list[:-1],
                new_messages=new_message_dict_list,
            )
        else:
            boundary_detection_result = await self._detect_boundary(
                conversation_history=history_message_dict_list,
                new_messages=new_message_dict_list,
            )
        should_end = boundary_detection_result.should_end
        should_wait = boundary_detection_result.should_wait
        reason = boundary_detection_result.reasoning

        status_control_result = StatusResult(should_wait=should_wait)

        if should_end:
            # TODO é‡æ„ä¸“é¡¹ï¼šè½¬ä¸ºinté€»è¾‘ä¸å¯¹ åº”è¯¥ä¿æŒä¸ºdatetime
            ts_value = history_message_dict_list[-1].get("timestamp")
            
            if isinstance(ts_value, str):
                # ç»Ÿä¸€è§£æä¸ºå¸¦æ—¶åŒºçš„ datetime
                timestamp = dt_from_iso_format(ts_value.replace("Z", "+00:00"))
            elif isinstance(ts_value, (int, float)):
                timestamp = dt_from_timestamp(ts_value)
            else:
                timestamp = get_now_with_timezone()
        

            participants = self._extract_participant_ids(history_message_dict_list)
            # åˆ›å»º MemCell
            # ä¼˜å…ˆä½¿ç”¨è¾¹ç•Œæ£€æµ‹çš„ä¸»é¢˜æ‘˜è¦ï¼›è‹¥ä¸ºç©ºï¼Œå›é€€åˆ°æœ€åä¸€æ¡æ–°æ¶ˆæ¯çš„æ–‡æœ¬ï¼›å†ä¸è¡Œç”¨å ä½æ‘˜è¦
            fallback_text = ""
            if new_message_dict_list:
                last_msg = new_message_dict_list[-1]
                if isinstance(last_msg, dict):
                    fallback_text = last_msg.get("content") or ""
                elif isinstance(last_msg, str):
                    fallback_text = last_msg
            summary_text = boundary_detection_result.topic_summary or (fallback_text.strip()[:200] if fallback_text else "ä¼šè¯ç‰‡æ®µ")

            memcell = MemCell(
                event_id=str(uuid.uuid4()),
                user_id_list=request.user_id_list,
                original_data=history_message_dict_list,
                timestamp=timestamp,
                summary=summary_text,
                group_id=request.group_id,
                participants=participants,  # ä½¿ç”¨åˆå¹¶åçš„participants
                type=self.raw_data_type,
            )

            # è‡ªåŠ¨è§¦å‘æƒ…æ™¯è®°å¿†æå–
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    episode_request = EpisodeMemoryExtractRequest(
                        memcell_list=[memcell],
                        user_id_list=request.user_id_list,
                        participants=participants,
                        group_id=request.group_id,
                    )
                    logger.debug(
                        f"ğŸ“š è‡ªåŠ¨è§¦å‘æƒ…æ™¯è®°å¿†æå–å¼€å§‹: memcell_list={memcell}, user_id_list={request.user_id_list}, participants={participants}, group_id={request.group_id}"
                    )
                    now = time.time()
                    episode_result = await self.episode_extractor.extract_memory(
                        episode_request,
                        use_group_prompt=True,
                        use_semantic_extraction=use_semantic_extraction,
                    )
                    logger.debug(
                        f"ğŸ“š è‡ªåŠ¨è§¦å‘æƒ…æ™¯è®°å¿†æå–, è€—æ—¶: {time.time() - now}ç§’"
                    )
                    if episode_result and isinstance(episode_result, MemCell):
                        # GROUP_EPISODE_GENERATION_PROMPT æ¨¡å¼ï¼šè¿”å›åŒ…å«æƒ…æ™¯è®°å¿†çš„ MemCell
                        logger.info(f"âœ… æˆåŠŸç”Ÿæˆæƒ…æ™¯è®°å¿†å¹¶å­˜å‚¨åˆ° MemCell ä¸­")
                        # Attach embedding info to MemCell (episode preferred)
                        
                        text_for_embed = (
                            episode_result.episode or episode_result.summary or ""
                        )
                        if text_for_embed:
                            vs = get_vectorize_service()
                            vec = await vs.get_embedding(text_for_embed)
                            episode_result.extend = episode_result.extend or {}
                            episode_result.extend["embedding"] = (
                                vec.tolist()
                                if hasattr(vec, "tolist")
                                else list(vec)
                            )
                            episode_result.extend["vector_model"] = (
                                vs.get_model_name()
                            )

                        
                        
                        # æäº¤åˆ°èšç±»å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if hasattr(self, '_cluster_worker') and self._cluster_worker:
                            try:
                                self._cluster_worker.submit(
                                    request.group_id, episode_result.to_dict()
                                )
                            except Exception as e:
                                logger.debug(f"Failed to submit to cluster worker: {e}")
                        
                        return (episode_result, status_control_result)
                    else:
                        logger.warning(
                            f"âš ï¸ æƒ…æ™¯è®°å¿†æå–å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})"
                        )

                except Exception as e:
                    logger.error(
                        f"âŒ æƒ…æ™¯è®°å¿†æå–å‡ºé”™: {e} (å°è¯• {attempt + 1}/{max_retries})"
                    )

                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)
                else:
                    logger.error(f"âŒ æ‰€æœ‰é‡è¯•æ¬¡æ•°å‡å¤±è´¥ï¼Œæœªèƒ½æå–æƒ…æ™¯è®°å¿†")

            # Attach embedding info to MemCell if available
            try:
                text_for_embed = memcell.episode
                if text_for_embed:
                    vs = get_vectorize_service()
                    vec = await vs.get_embedding(text_for_embed)
                    memcell.extend = memcell.extend or {}
                    memcell.extend["embedding"] = (
                        vec.tolist() if hasattr(vec, "tolist") else list(vec)
                    )
                    memcell.extend["vector_model"] = vs.get_model_name()
            except Exception:
                logger.debug("Embedding attach failed; continue without it")
            
            # æäº¤åˆ°èšç±»å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(self, '_cluster_worker') and self._cluster_worker:
                try:
                    self._cluster_worker.submit(request.group_id, memcell.to_dict())
                except Exception as e:
                    logger.debug(f"Failed to submit to cluster worker: {e}")
            
            return (memcell, status_control_result)
        elif should_wait:
            logger.debug(f"â³ Waiting for more messages: {reason}")
        return (None, status_control_result)

    def _data_process(self, raw_data: RawData) -> Dict[str, Any]:
        """å¤„ç†åŸå§‹æ•°æ®ï¼ŒåŒ…æ‹¬æ¶ˆæ¯ç±»å‹è¿‡æ»¤å’Œé¢„å¤„ç†"""
        content = (
            raw_data.content.copy()
            if isinstance(raw_data.content, dict)
            else raw_data.content
        )

        # è·å–æ¶ˆæ¯ç±»å‹
        msg_type = content.get('msgType') if isinstance(content, dict) else None

        # å®šä¹‰æ”¯æŒçš„æ¶ˆæ¯ç±»å‹å’Œå¯¹åº”çš„å ä½ç¬¦
        SUPPORTED_MSG_TYPES = {
            1: None,  # TEXT - ä¿æŒåŸæ–‡æœ¬
            2: "[å›¾ç‰‡]",  # PICTURE
            3: "[è§†é¢‘]",  # VIDEO
            4: "[éŸ³é¢‘]",  # AUDIO
            5: "[æ–‡ä»¶]",  # FILE - ä¿æŒåŸæ–‡æœ¬ï¼ˆæ–‡æœ¬å’Œæ–‡ä»¶åœ¨åŒä¸€ä¸ªæ¶ˆæ¯é‡Œï¼‰
            6: "[æ–‡ä»¶]",  # FILES
        }

        if isinstance(content, dict) and msg_type is not None:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ¶ˆæ¯ç±»å‹
            if msg_type not in SUPPORTED_MSG_TYPES:
                # ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹ï¼Œç›´æ¥è·³è¿‡ï¼ˆè¿”å›Noneä¼šåœ¨ä¸Šå±‚å¤„ç†ï¼‰
                logger.warning(
                    f"[ConvMemCellExtractor] è·³è¿‡ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹: {msg_type}"
                )
                return None

            # å¯¹éæ–‡æœ¬æ¶ˆæ¯è¿›è¡Œé¢„å¤„ç†
            placeholder = SUPPORTED_MSG_TYPES[msg_type]
            if placeholder is not None:
                # æ›¿æ¢æ¶ˆæ¯å†…å®¹ä¸ºå ä½ç¬¦
                content = content.copy()
                content['content'] = placeholder
                logger.debug(
                    f"[ConvMemCellExtractor] æ¶ˆæ¯ç±»å‹ {msg_type} è½¬æ¢ä¸ºå ä½ç¬¦: {placeholder}"
                )

        return content
