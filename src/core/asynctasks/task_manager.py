import os
import uuid
import importlib
import pkgutil
from pathlib import Path
from typing import Any, Dict, Optional, List, Callable, Union
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass, field

from arq import create_pool, ArqRedis
from arq.connections import RedisSettings
from arq.jobs import Job
from arq.worker import Worker, Function, func as arq_func

from core.asynctasks.task_scan_registry import TaskScanDirectoriesRegistry
from core.context.context_manager import ContextManager
from core.context.context import get_current_user_info
from core.di.decorators import component
from core.observation.logger import get_logger
from core.authorize.enums import Role

logger = get_logger(__name__)


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""

    PENDING = "pending"  # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"  # æ­£åœ¨æ‰§è¡Œ
    SUCCESS = "success"  # æ‰§è¡ŒæˆåŠŸ
    FAILED = "failed"  # æ‰§è¡Œå¤±è´¥
    CANCELLED = "cancelled"  # å·²å–æ¶ˆ


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœ"""

    task_id: str
    status: TaskStatus
    result: Any = None
    error: Optional[str] = None
    created_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None
    retry_count: int = 0
    user_id: Optional[int] = None
    user_context: Optional[Dict[str, Any]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RetryConfig:
    """é‡è¯•é…ç½®"""

    max_retries: int = 1
    retry_delay: float = 1.0  # ç§’
    exponential_backoff: bool = True
    max_retry_delay: float = 60.0  # ç§’


@dataclass
class TaskFunction:
    """ä»»åŠ¡å‡½æ•°"""

    name: str
    coroutine: Callable  # åŒ…è£…å¤„ç†ç”¨æˆ·ä¸Šä¸‹æ–‡åçš„å‡½æ•°
    original_func: Callable  # åŸå§‹å‡½æ•°
    timeout: Optional[float] = None
    retry_config: Optional[RetryConfig] = None

    def to_arq_function(self) -> Function:
        """è½¬æ¢ä¸ºarqå‡½æ•°"""
        return arq_func(
            self.coroutine,
            name=self.name,
            max_tries=self.retry_config.max_retries,
            timeout=self.timeout,
        )

    def __call__(self, *args, **kwargs) -> Any:
        """è°ƒç”¨ä»»åŠ¡å‡½æ•°"""
        return self.original_func(*args, **kwargs)


@component(name="task_manager")
class TaskManager:
    """
    å¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨

    åŸºäºarqæ¡†æ¶å®ç°çš„å¼‚æ­¥ä»»åŠ¡ç®¡ç†ï¼Œæä¾›ä»»åŠ¡æ·»åŠ ã€è·å–ç»“æœã€åˆ é™¤ä»»åŠ¡ç­‰åŠŸèƒ½ã€‚
    ä½¿ç”¨ContextManagerè‡ªåŠ¨æ³¨å…¥æ•°æ®åº“ä¼šè¯å’Œç”¨æˆ·ä¸Šä¸‹æ–‡ã€‚
    """

    def __init__(self, context_manager: ContextManager):
        """åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨"""
        self._pool: Optional[ArqRedis] = None
        self._worker: Optional[Worker] = None
        self._redis_settings = self._get_redis_settings()
        self._context_manager = context_manager

        # ä»»åŠ¡å‡½æ•°æ³¨å†Œè¡¨
        self._task_registry: Dict[str, TaskFunction] = {}

        # é»˜è®¤é‡è¯•é…ç½®
        self._default_retry_config = RetryConfig()

        logger.info("ä»»åŠ¡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _get_current_user_info(self) -> Optional[Dict[str, Any]]:
        """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
        return get_current_user_info()

    def _get_current_user_id(self) -> Optional[int]:
        """è·å–å½“å‰ç”¨æˆ·ID"""
        user_info = self._get_current_user_info()
        return user_info.get("user_id") if user_info else None

    def _get_redis_settings(self) -> RedisSettings:
        """
        ä»ç¯å¢ƒå˜é‡è·å–Redisé…ç½®

        Returns:
            RedisSettings: Redisè¿æ¥é…ç½®
        """
        return RedisSettings(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", "6379")),
            database=int(os.getenv("REDIS_DB", "0")),
            password=os.getenv("REDIS_PASSWORD"),
            ssl=os.getenv("REDIS_SSL", "false").lower() == "true",
            username=os.getenv("REDIS_USERNAME"),
        )

    async def _get_pool(self) -> ArqRedis:
        """
        è·å–Redisè¿æ¥æ± 

        Returns:
            ArqRedis: Redisè¿æ¥æ± 
        """
        if self._pool is None:
            self._pool = await create_pool(self._redis_settings)
        return self._pool

    async def close(self) -> None:
        """å…³é—­è¿æ¥æ± """
        if self._pool is not None:
            await self._pool.close()
            self._pool = None
        logger.info("ä»»åŠ¡ç®¡ç†å™¨è¿æ¥å·²å…³é—­")

    def register_task(self, task_function: TaskFunction) -> None:
        """
        æ³¨å†Œä»»åŠ¡å‡½æ•°

        Args:
            name: ä»»åŠ¡åç§°
            func: ä»»åŠ¡å‡½æ•°
            retry_config: é‡è¯•é…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        self._task_registry[task_function.name] = task_function
        logger.info(f"å·²æ³¨å†Œä»»åŠ¡: {task_function.name}")

    def scan_and_register_tasks(self, registry: TaskScanDirectoriesRegistry) -> None:
        """
        æ‰«æä»»åŠ¡ç›®å½•å¹¶è‡ªåŠ¨æ³¨å†Œä»»åŠ¡

        Args:
            registry: ä»»åŠ¡æ‰«æç›®å½•æ³¨å†Œå™¨
        """
        for directory in registry.get_scan_directories():
            self._scan_directory_for_tasks(directory)

    def _scan_directory_for_tasks(self, directory: str) -> None:
        """
        æ‰«æå•ä¸ªç›®å½•ä¸­çš„ä»»åŠ¡

        Args:
            directory: è¦æ‰«æçš„ç›®å½•è·¯å¾„
        """
        try:
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            from common_utils.project_path import src_dir

            relative_path = Path(directory).resolve().relative_to(src_dir)
            package_name = ".".join(relative_path.parts)

            logger.info(f"æ‰«æä»»åŠ¡åŒ…: {package_name}")

            # å¯¼å…¥åŒ…å¹¶æ‰«æ
            try:
                package = importlib.import_module(package_name)

                # æ‰«æåŒ…ä¸­çš„æ‰€æœ‰æ¨¡å—
                if hasattr(package, '__path__'):
                    # è¿™æ˜¯ä¸€ä¸ªåŒ…ï¼Œé€’å½’æ‰«ææ‰€æœ‰å­æ¨¡å—
                    for _, module_name, _ in pkgutil.walk_packages(
                        package.__path__, prefix=f"{package_name}."
                    ):
                        try:
                            module = importlib.import_module(module_name)
                            self._scan_module_for_tasks(module)
                        except Exception as e:
                            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {module_name}, é”™è¯¯: {e}")
                else:
                    # è¿™æ˜¯ä¸€ä¸ªæ¨¡å—ï¼Œç›´æ¥æ‰«æ
                    self._scan_module_for_tasks(package)

            except Exception as e:
                logger.error(f"å¯¼å…¥åŒ…å¤±è´¥: {package_name}, é”™è¯¯: {e}")

        except Exception as e:
            logger.error(f"æ‰«æç›®å½•å¤±è´¥: {directory}, é”™è¯¯: {e}")

    def _scan_module_for_tasks(self, module: Any) -> None:
        """
        æ‰«ææ¨¡å—ä¸­çš„ä»»åŠ¡å‡½æ•°

        Args:
            module: è¦æ‰«æçš„æ¨¡å—å¯¹è±¡
        """
        try:
            # è·å–æ¨¡å—ä¸­çš„æ‰€æœ‰å±æ€§
            for attr_name in dir(module):
                # è·³è¿‡ç§æœ‰å±æ€§å’Œç‰¹æ®Šå±æ€§
                if attr_name.startswith('_'):
                    continue

                try:
                    attr = getattr(module, attr_name)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯TaskFunctionå®ä¾‹
                    if isinstance(attr, TaskFunction):
                        self.register_task(attr)
                        logger.info(f"åœ¨æ¨¡å— {module.__name__} ä¸­å‘ç°ä»»åŠ¡: {attr.name}")

                except Exception as e:
                    logger.debug(
                        f"è·å–æ¨¡å—å±æ€§å¤±è´¥: {module.__name__}.{attr_name}, é”™è¯¯: {e}"
                    )

        except Exception as e:
            logger.error(f"æ‰«ææ¨¡å—ä»»åŠ¡å¤±è´¥: {module.__name__}, é”™è¯¯: {e}")

    async def enqueue_task(
        self,
        task_name: Union[str, TaskFunction, Any],
        *args,
        task_id: Optional[str] = None,
        delay: Optional[float] = None,
        retry_config: Optional[RetryConfig] = None,
        user_id: Optional[int] = None,
        user_data: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs,
    ) -> str:
        """
        æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—

        Args:
            task_name: ä»»åŠ¡åç§°
            *args: ä»»åŠ¡å‚æ•°
            task_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
            delay: å»¶è¿Ÿæ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
            retry_config: é‡è¯•é…ç½®ï¼ˆå¯é€‰ï¼‰
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä»å½“å‰ä¸Šä¸‹æ–‡è·å–ï¼‰
            user_data: ç”¨æˆ·æ•°æ®ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä»å½“å‰ä¸Šä¸‹æ–‡è·å–ï¼‰
            metadata: ä»»åŠ¡å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            **kwargs: ä»»åŠ¡å…³é”®å­—å‚æ•°

        Returns:
            str: ä»»åŠ¡ID
        """
        if isinstance(task_name, TaskFunction):
            task_name = task_name.name
        elif isinstance(task_name, str):
            pass
        else:
            raise ValueError(f"ç±»å‹é”™è¯¯: {type(task_name)}")

        assert task_name in self._task_registry, f"æœªæ‰¾åˆ°ä»»åŠ¡: {task_name}"
        task_function = self._task_registry[task_name]
        current_retry_config = (
            retry_config or task_function.retry_config or self._default_retry_config
        )

        # ç”Ÿæˆä»»åŠ¡ID
        if task_id is None:
            task_id = str(uuid.uuid4())

        # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if user_data is None:
            current_user_context = self._get_current_user_info()
            if current_user_context is not None:
                user_data = current_user_context.copy()
            elif user_id is not None:
                user_data = {"user_id": user_id, "role": Role.USER}

        if user_data is None and user_id is None:
            # å°è¯•ä»å½“å‰ä¸Šä¸‹æ–‡è·å–user_id
            current_user_id = self._get_current_user_id()
            if current_user_id is not None:
                user_data = {"user_id": current_user_id, "role": Role.USER}

        # ğŸ”§ è·å–å½“å‰çš„ app_info_contextï¼ˆåŒ…å« task_id ç­‰ï¼‰
        from core.context.context import get_current_app_info

        current_app_info = get_current_app_info()

        # å‡†å¤‡ä»»åŠ¡ä¸Šä¸‹æ–‡
        task_context = {
            "user_data": user_data,
            "app_info": current_app_info,  # ğŸ”§ å¤åˆ¶ app_info_context
            "metadata": metadata or {},
            "task_id": task_id,
            "retry_config": current_retry_config,
        }

        # è·å–è¿æ¥æ± 
        pool = await self._get_pool()

        # è®¡ç®—å»¶è¿Ÿæ—¶é—´
        defer_until = None
        if delay is not None:
            from common_utils.datetime_utils import get_now_with_timezone

            defer_until = get_now_with_timezone() + timedelta(seconds=delay)

        # å…¥é˜Ÿä»»åŠ¡
        job = await pool.enqueue_job(
            task_name,
            task_context,
            *args,
            _job_id=task_id,
            _defer_until=defer_until,
            **kwargs,
        )

        user_id_for_log = user_data.get("user_id") if user_data else "unknown"
        logger.info(
            f"å·²æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—: {task_id}, ä»»åŠ¡åç§°: {task_name}, ç”¨æˆ·: {user_id_for_log}"
        )
        return task_id

    async def execute_task_with_context(
        self,
        task_func: Callable,
        context: Dict[str, Any],
        task_context: Dict[str, Any],
        *args,
        force_new_session: bool = False,
        **kwargs,
    ) -> Any:
        """
        åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œä»»åŠ¡

        Args:
            task_func: ä»»åŠ¡å‡½æ•°
            context: ä»»åŠ¡æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆredisã€job_idã€job_tryã€scoreã€enqueue_timeï¼‰
            task_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼ˆç”¨æˆ·æ•°æ®ã€ä»»åŠ¡IDç­‰ï¼‰
            *args: ä»»åŠ¡å‚æ•°
            force_new_session: æ˜¯å¦å¼ºåˆ¶åˆ›å»ºæ–°ä¼šè¯ï¼ˆé»˜è®¤Falseï¼Œé¿å…ä¸å¿…è¦çš„ä¼šè¯åˆ›å»ºï¼‰
            **kwargs: ä»»åŠ¡å…³é”®å­—å‚æ•°

        Returns:
            Any: ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        user_data = task_context.get("user_data")
        app_info = task_context.get("app_info")  # ğŸ”§ è·å–ä¿å­˜çš„ app_info_context

        # ğŸ”§ æ¢å¤ app_info_contextï¼ˆåŒ…å« task_id ç­‰ï¼‰
        if app_info:
            from core.context.context import set_current_app_info

            set_current_app_info(app_info)
            logger.debug(f"ğŸ”§ å·²æ¢å¤ app_info_context: {app_info}")

        # ä½¿ç”¨ContextManageræ‰§è¡Œä»»åŠ¡ï¼Œè‡ªåŠ¨æ³¨å…¥ç”¨æˆ·ä¸Šä¸‹æ–‡å’Œæ•°æ®åº“ä¼šè¯
        # ğŸ”§ å¯é…ç½®çš„ä¼šè¯éš”ç¦»ï¼šåªæœ‰åœ¨æ˜ç¡®éœ€è¦æ—¶æ‰å¼ºåˆ¶åˆ›å»ºæ–°ä¼šè¯
        result = await self._context_manager.run_with_full_context(
            task_func,
            *args,
            user_data=user_data,
            auto_inherit_user=False,
            auto_commit=True,
            force_new_session=force_new_session,  # ğŸ”‘ å…³é”®ï¼šå¯é…ç½®çš„ä¼šè¯éš”ç¦»
            **kwargs,
        )

        task_id = task_context.get("task_id")
        user_id = user_data.get("user_id") if user_data else "unknown"
        logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼ˆç‹¬ç«‹ä¼šè¯ï¼‰: {task_id}, ç”¨æˆ·: {user_id}")
        return result

    async def get_task_result(self, task_id: str) -> Optional[TaskResult]:
        """
        è·å–ä»»åŠ¡ç»“æœ

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            Optional[TaskResult]: ä»»åŠ¡ç»“æœï¼Œå¦‚æœä»»åŠ¡ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        pool = await self._get_pool()

        try:
            job = Job(task_id, pool)

            # è·å–ä»»åŠ¡ä¿¡æ¯
            info = await job.info()
            if info is None:
                return None

            # æ„é€ ä»»åŠ¡ç»“æœ
            status = self._map_arq_status_to_task_status(info.job_status)

            # å°è¯•ä»ä»»åŠ¡ä¸Šä¸‹æ–‡ä¸­è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆè¿™å¯èƒ½ä¸å¯ç”¨ï¼Œå› ä¸ºarqä¸ä¼šä¿å­˜æˆ‘ä»¬çš„è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ï¼‰
            user_id = None
            user_context_data = None

            result = TaskResult(
                task_id=task_id,
                status=status,
                result=info.result if status == TaskStatus.SUCCESS else None,
                error=str(info.result) if status == TaskStatus.FAILED else None,
                created_at=info.enqueue_time,
                started_at=info.start_time,
                finished_at=info.finish_time,
                retry_count=info.job_try or 0,
                user_id=user_id,
                user_context=user_context_data,
            )

            return result

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»“æœå¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
            return None

    def _map_arq_status_to_task_status(self, arq_status: str) -> TaskStatus:
        """
        æ˜ å°„arqçŠ¶æ€åˆ°ä»»åŠ¡çŠ¶æ€

        Args:
            arq_status: arqä»»åŠ¡çŠ¶æ€

        Returns:
            TaskStatus: ä»»åŠ¡çŠ¶æ€
        """
        mapping = {
            "queued": TaskStatus.PENDING,
            "deferred": TaskStatus.PENDING,
            "in_progress": TaskStatus.RUNNING,
            "complete": TaskStatus.SUCCESS,
            "failed": TaskStatus.FAILED,
            "cancelled": TaskStatus.CANCELLED,
        }
        return mapping.get(arq_status, TaskStatus.PENDING)

    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        pool = await self._get_pool()

        try:
            job = Job(task_id, pool)
            await job.abort()
            logger.info(f"å·²å–æ¶ˆä»»åŠ¡: {task_id}")
            return True
        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
            return False

    async def delete_task(self, task_id: str) -> bool:
        """
        åˆ é™¤ä»»åŠ¡è®°å½•

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        pool = await self._get_pool()

        try:
            # åˆ é™¤ä»»åŠ¡è®°å½•
            await pool.delete(f"arq:job:{task_id}")
            logger.info(f"å·²åˆ é™¤ä»»åŠ¡: {task_id}")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
            return False

    async def list_tasks(
        self,
        status: Optional[TaskStatus] = None,
        user_id: Optional[int] = None,
        limit: int = 100,
    ) -> List[TaskResult]:
        """
        åˆ—å‡ºä»»åŠ¡

        æ³¨æ„ï¼šç”±äºarqçš„é™åˆ¶ï¼Œæ— æ³•æœ‰æ•ˆåœ°æŒ‰ç”¨æˆ·IDè¿‡æ»¤ä»»åŠ¡ã€‚
        è¿™ä¸ªæ–¹æ³•ä¼šè¿”å›æ‰€æœ‰ä»»åŠ¡ï¼Œç„¶ååœ¨åº”ç”¨å±‚è¿‡æ»¤ã€‚
        åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®ä½¿ç”¨ä¸“é—¨çš„ä»»åŠ¡çŠ¶æ€å­˜å‚¨ç³»ç»Ÿã€‚

        Args:
            status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
            user_id: ç”¨æˆ·IDè¿‡æ»¤ï¼ˆå¯é€‰ï¼Œä½†ç”±äºarqé™åˆ¶å¯èƒ½æ— æ•ˆï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            List[TaskResult]: ä»»åŠ¡åˆ—è¡¨
        """
        pool = await self._get_pool()

        try:
            # è·å–æ‰€æœ‰ä»»åŠ¡é”®
            keys = await pool.keys("arq:job:*")
            tasks = []

            for key in keys[:limit]:
                task_id = key.decode().split(":")[-1]
                task_result = await self.get_task_result(task_id)

                if task_result is not None:
                    # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                    if status is not None and task_result.status != status:
                        continue

                    # æ³¨æ„ï¼šç”±äºarqçš„é™åˆ¶ï¼Œuser_idè¿‡æ»¤å¯èƒ½ä¸å‡†ç¡®
                    if user_id is not None and task_result.user_id != user_id:
                        continue

                    tasks.append(task_result)

            return tasks

        except Exception as e:
            logger.error(f"åˆ—å‡ºä»»åŠ¡å¤±è´¥: {str(e)}")
            return []

    async def get_task_count(self, status: Optional[TaskStatus] = None) -> int:
        """
        è·å–ä»»åŠ¡æ•°é‡

        Args:
            status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

        Returns:
            int: ä»»åŠ¡æ•°é‡
        """
        tasks = await self.list_tasks(status=status)
        return len(tasks)

    def get_worker_functions(self) -> List[Function]:
        """
        è·å–workerå‡½æ•°æ˜ å°„

        Returns:
            Dict[str, Callable]: workerå‡½æ•°æ˜ å°„
        """
        return [v.to_arq_function() for v in self._task_registry.values()]

    def list_registered_task_names(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å·²æ³¨å†Œçš„ä»»åŠ¡åç§°

        Returns:
            List[str]: ä»»åŠ¡åç§°åˆ—è¡¨
        """
        return list(self._task_registry.keys())


def task(retry_config: Optional[RetryConfig] = None, timeout: Optional[float] = 300):
    """
    ä»»åŠ¡è£…é¥°å™¨

    Args:
        name: ä»»åŠ¡åç§°ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨å‡½æ•°åï¼‰
        retry_config: é‡è¯•é…ç½®ï¼ˆå¯é€‰ï¼‰

    Returns:
        è£…é¥°åçš„å‡½æ•°
    """

    if not retry_config:
        retry_config = RetryConfig()

    task_manager = get_task_manager()

    def decorator(func: Callable) -> Callable:

        async def _task_wrapper(*args, **kwargs):
            return await task_manager.execute_task_with_context(func, *args, **kwargs)

        function_name = func.__name__

        # æœ‰äº›å±æ€§æ˜¯arq worker æ¡†æ¶éœ€è¦çš„
        return TaskFunction(
            name=function_name,
            coroutine=_task_wrapper,
            original_func=func,
            timeout=timeout,
            retry_config=retry_config,
        )

    return decorator


def get_task_manager() -> TaskManager:
    """
    è·å–ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹

    Returns:
        TaskManager: ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
    """
    from core.di.utils import get_bean_by_type

    return get_bean_by_type(TaskManager)
