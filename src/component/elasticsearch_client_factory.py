"""
Elasticsearch å®¢æˆ·ç«¯å·¥åŽ‚

åŸºäºŽçŽ¯å¢ƒå˜é‡æä¾› Elasticsearch å®¢æˆ·ç«¯ç¼“å­˜å’Œç®¡ç†åŠŸèƒ½ã€‚
"""

import os
import asyncio
from common_utils.datetime_utils import get_now_with_timezone
from typing import Dict, Optional, List, Type, Any
from hashlib import md5
from elasticsearch import AsyncElasticsearch
from elasticsearch.dsl.async_connections import connections as async_connections

from core.di.decorators import component
from core.observation.logger import get_logger
from core.oxm.es.doc_base import DocBase, generate_index_name

logger = get_logger(__name__)


def get_default_es_config() -> Dict[str, Any]:
    """
    åŸºäºŽçŽ¯å¢ƒå˜é‡èŽ·å–é»˜è®¤çš„ Elasticsearch é…ç½®

    çŽ¯å¢ƒå˜é‡ï¼š
    - ES_HOST: Elasticsearch ä¸»æœºï¼Œé»˜è®¤ localhost
    - ES_PORT: Elasticsearch ç«¯å£ï¼Œé»˜è®¤ 9200
    - ES_HOSTS: Elasticsearch ä¸»æœºåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œä¼˜å…ˆçº§é«˜äºŽ ES_HOST
    - ES_USERNAME: ç”¨æˆ·å
    - ES_PASSWORD: å¯†ç 
    - ES_API_KEY: APIå¯†é’¥
    - ES_TIMEOUT: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 120

    Returns:
        Dict[str, Any]: é…ç½®å­—å…¸
    """
    # èŽ·å–ä¸»æœºä¿¡æ¯
    es_hosts_str = os.getenv("ES_HOSTS")
    if es_hosts_str:
        # ES_HOSTS å·²ç»åŒ…å«å®Œæ•´çš„ URLï¼ˆhttps://host:portï¼‰ï¼Œç›´æŽ¥ä½¿ç”¨
        es_hosts = [host.strip() for host in es_hosts_str.split(",")]
    else:
        # å›žé€€åˆ°å•ä¸ªä¸»æœºé…ç½®
        es_host = os.getenv("ES_HOST", "localhost")
        es_port = int(os.getenv("ES_PORT", "9200"))
        es_hosts = [f"http://{es_host}:{es_port}"]

    # è®¤è¯ä¿¡æ¯
    es_username = os.getenv("ES_USERNAME")
    es_password = os.getenv("ES_PASSWORD")
    es_api_key = os.getenv("ES_API_KEY")

    # è¿žæŽ¥å‚æ•°
    es_timeout = int(os.getenv("ES_TIMEOUT", "120"))
    es_verify_certs = os.getenv("ES_VERIFY_CERTS", "false").lower() == "true"

    config = {
        "hosts": es_hosts,
        "timeout": es_timeout,
        "username": es_username,
        "password": es_password,
        "api_key": es_api_key,
        "verify_certs": es_verify_certs,
    }

    logger.info("èŽ·å–é»˜è®¤ Elasticsearch é…ç½®:")
    logger.info("  ä¸»æœº: %s", es_hosts)
    logger.info("  è¶…æ—¶: %s ç§’", es_timeout)
    logger.info(
        "  è®¤è¯: %s", "API Key" if es_api_key else ("Basic" if es_username else "æ— ")
    )

    return config


def get_cache_key(
    hosts: List[str],
    username: Optional[str] = None,
    password: Optional[str] = None,
    api_key: Optional[str] = None,
) -> str:
    """
    ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŒæ—¶ä½œä¸º elasticsearch-dsl connections çš„ aliasï¼‰
    åŸºäºŽ hostsã€è®¤è¯ä¿¡æ¯ç”Ÿæˆå”¯ä¸€æ ‡è¯†

    Args:
        hosts: Elasticsearchä¸»æœºåˆ—è¡¨
        username: ç”¨æˆ·å
        password: å¯†ç 
        api_key: APIå¯†é’¥

    Returns:
        str: ç¼“å­˜é”®
    """
    hosts_str = ",".join(sorted(hosts))
    auth_str = ""
    if api_key:
        # ä½¿ç”¨ api_key çš„å‰8ä½ä½œä¸ºæ ‡è¯†
        auth_str = f"api_key:{api_key[:8]}..."
    elif username and password:
        # ä½¿ç”¨ username å’Œ password çš„ md5 ä½œä¸ºæ ‡è¯†
        auth_str = f"basic:{username}:{md5(password.encode()).hexdigest()[:8]}"
    elif username:
        # åªæœ‰ username æ—¶ï¼Œä»…ä½¿ç”¨ username
        auth_str = f"basic:{username}"

    key_content = f"{hosts_str}:{auth_str}"
    return md5(key_content.encode()).hexdigest()


class ElasticsearchClientWrapper:
    """Elasticsearch å®¢æˆ·ç«¯åŒ…è£…å™¨"""

    def __init__(self, async_client: AsyncElasticsearch, hosts: List[str]):
        self.async_client = async_client
        self.hosts = hosts
        self._initialized = False
        self._document_classes: List[Type[DocBase]] = []

    async def initialize_indices(
        self, document_classes: Optional[List[Type[DocBase]]] = None
    ):
        """åˆå§‹åŒ–ç´¢å¼•"""
        if self._initialized:
            return

        if document_classes:
            try:
                logger.info(
                    "æ­£åœ¨åˆå§‹åŒ– Elasticsearch ç´¢å¼•ï¼Œå…± %d ä¸ªæ–‡æ¡£ç±»",
                    len(document_classes),
                )

                for doc_class in document_classes:
                    await self._init_document_index(doc_class)

                self._document_classes = document_classes
                self._initialized = True
                logger.info(
                    "âœ… Elasticsearch ç´¢å¼•åˆå§‹åŒ–æˆåŠŸï¼Œå¤„ç†äº† %d ä¸ªæ–‡æ¡£ç±»",
                    len(document_classes),
                )

                for doc_class in document_classes:
                    logger.info(
                        "ðŸ“‹ åˆå§‹åŒ–ç´¢å¼•: class=%s -> index=%s",
                        doc_class.__name__,
                        doc_class.get_index_name(),
                    )

            except Exception as e:
                logger.error("âŒ Elasticsearch ç´¢å¼•åˆå§‹åŒ–å¤±è´¥: %s", e)
                raise

    async def _init_document_index(self, doc_class: Type[DocBase]):
        """åˆå§‹åŒ–å•ä¸ªæ–‡æ¡£ç±»çš„ç´¢å¼•"""
        try:
            # èŽ·å–åˆ«ååç§°
            alias = doc_class.get_index_name()

            if not alias:
                logger.info("æ–‡æ¡£ç±»æ²¡æœ‰ç´¢å¼•åˆ«åï¼Œè·³è¿‡åˆå§‹åŒ– %s", doc_class.__name__)
                return

            # æ£€æŸ¥åˆ«åæ˜¯å¦å­˜åœ¨
            logger.info("æ­£åœ¨æ£€æŸ¥ç´¢å¼•åˆ«å: %s (æ–‡æ¡£ç±»: %s)", alias, doc_class.__name__)
            alias_exists = await self.async_client.indices.exists(index=alias)

            if not alias_exists:
                # ç”Ÿæˆç›®æ ‡ç´¢å¼•å
                dst = doc_class.dest()

                # åˆ›å»ºç´¢å¼•
                await doc_class.init(index=dst, using=self.async_client)

                # åˆ›å»ºåˆ«å
                await self.async_client.indices.update_aliases(
                    body={
                        "actions": [
                            {
                                "add": {
                                    "index": dst,
                                    "alias": alias,
                                    "is_write_index": True,
                                }
                            }
                        ]
                    }
                )
                logger.info("âœ… åˆ›å»ºç´¢å¼•å’Œåˆ«å: %s -> %s", dst, alias)
            else:
                logger.info("ðŸ“‹ ç´¢å¼•åˆ«åå·²å­˜åœ¨: %s", alias)

        except Exception as e:
            logger.error("âŒ åˆå§‹åŒ–æ–‡æ¡£ç±» %s çš„ç´¢å¼•å¤±è´¥: %s", doc_class.__name__, e)
            import traceback

            traceback.print_exc()
            raise

    async def test_connection(self) -> bool:
        """æµ‹è¯•è¿žæŽ¥"""
        try:
            await self.async_client.ping()
            logger.info("âœ… Elasticsearch è¿žæŽ¥æµ‹è¯•æˆåŠŸ: %s", self.hosts)
            return True
        except Exception as e:
            logger.error("âŒ Elasticsearch è¿žæŽ¥æµ‹è¯•å¤±è´¥: %s, é”™è¯¯: %s", self.hosts, e)
            return False

    async def close(self):
        """å…³é—­è¿žæŽ¥"""
        try:
            if self.async_client:
                await self.async_client.close()
            logger.info("ðŸ”Œ Elasticsearch è¿žæŽ¥å·²å…³é—­: %s", self.hosts)
        except Exception as e:
            logger.error("å…³é—­ Elasticsearch è¿žæŽ¥æ—¶å‡ºé”™: %s", e)

    @property
    def is_initialized(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–ç´¢å¼•"""
        return self._initialized


@component(name="elasticsearch_client_factory")
class ElasticsearchClientFactory:
    """
    Elasticsearch å®¢æˆ·ç«¯å·¥åŽ‚
    ### AsyncElasticsearch æ˜¯æœ‰çŠ¶æ€çš„ï¼Œå› æ­¤å¯ä»¥åœ¨å¤šä¸ªåœ°æ–¹ä½¿ç”¨åŒä¸€ä¸ªå®žä¾‹ ###

    æä¾›åŸºäºŽé…ç½®çš„ Elasticsearch å®¢æˆ·ç«¯ç¼“å­˜å’Œç®¡ç†åŠŸèƒ½
    """

    def __init__(self):
        """åˆå§‹åŒ– Elasticsearch å®¢æˆ·ç«¯å·¥åŽ‚"""
        self._clients: Dict[str, ElasticsearchClientWrapper] = {}
        self._lock = asyncio.Lock()
        self._default_config: Optional[Dict[str, Any]] = None
        logger.info("ElasticsearchClientFactory initialized")

    async def _create_client(
        self,
        hosts: List[str],
        username: Optional[str] = None,
        password: Optional[str] = None,
        api_key: Optional[str] = None,
        timeout: int = 120,
        **kwargs,
    ) -> ElasticsearchClientWrapper:
        """
        åˆ›å»º Elasticsearch å®¢æˆ·ç«¯å®žä¾‹

        Args:
            hosts: Elasticsearchä¸»æœºåˆ—è¡¨
            username: ç”¨æˆ·å
            password: å¯†ç 
            api_key: APIå¯†é’¥
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            **kwargs: å…¶ä»–è¿žæŽ¥å‚æ•°

        Returns:
            ElasticsearchClientWrapper å®žä¾‹
        """
        # æž„å»ºè¿žæŽ¥å‚æ•°
        conn_params = {
            "hosts": hosts,
            "timeout": timeout,
            "max_retries": 3,
            "retry_on_timeout": True,
            "verify_certs": False,  # ç¦ç”¨ SSL è¯ä¹¦éªŒè¯
            "ssl_show_warn": False,  # ç¦ç”¨ SSL è­¦å‘Š
            **kwargs,
        }

        # æ·»åŠ è®¤è¯ä¿¡æ¯
        if api_key:
            conn_params["api_key"] = api_key
        elif username and password:
            conn_params["basic_auth"] = (username, password)

        # ç”Ÿæˆè¿žæŽ¥åˆ«åï¼ˆç”¨äºŽ elasticsearch-dsl connections ç®¡ç†ï¼‰
        alias = get_cache_key(hosts, username, password, api_key)

        # é€šè¿‡ async_connections.create_connection åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯
        async_client = async_connections.create_connection(alias=alias, **conn_params)

        client_wrapper = ElasticsearchClientWrapper(async_client, hosts)

        logger.info("Created Elasticsearch client for %s with alias %s", hosts, alias)
        return client_wrapper

    async def _get_client(
        self,
        hosts: List[str],
        username: Optional[str] = None,
        password: Optional[str] = None,
        api_key: Optional[str] = None,
        **kwargs,
    ) -> ElasticsearchClientWrapper:
        """
        èŽ·å– Elasticsearch å®¢æˆ·ç«¯å®žä¾‹

        Args:
            hosts: Elasticsearchä¸»æœºåˆ—è¡¨
            username: ç”¨æˆ·å
            password: å¯†ç 
            api_key: APIå¯†é’¥
            **kwargs: å…¶ä»–é…ç½®å‚æ•°

        Returns:
            ElasticsearchClientWrapper å®žä¾‹
        """
        cache_key = get_cache_key(hosts, username, password, api_key)

        async with self._lock:
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self._clients:
                logger.debug("Using cached Elasticsearch client for %s", hosts)
                return self._clients[cache_key]

            # åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯å®žä¾‹
            logger.info("Creating new Elasticsearch client for %s", hosts)

            client_wrapper = await self._create_client(
                hosts=hosts,
                username=username,
                password=password,
                api_key=api_key,
                **kwargs,
            )

            # æµ‹è¯•è¿žæŽ¥
            if not await client_wrapper.test_connection():
                await client_wrapper.close()
                raise RuntimeError(f"Elasticsearch è¿žæŽ¥æµ‹è¯•å¤±è´¥: {hosts}")

            self._clients[cache_key] = client_wrapper
            logger.info(
                "Elasticsearch client %s created and cached with key %s",
                hosts,
                cache_key,
            )

        return client_wrapper

    async def get_default_client(self) -> ElasticsearchClientWrapper:
        """
        èŽ·å–åŸºäºŽçŽ¯å¢ƒå˜é‡é…ç½®çš„é»˜è®¤ Elasticsearch å®¢æˆ·ç«¯å®žä¾‹

        Returns:
            ElasticsearchClientWrapper å®žä¾‹
        """
        # èŽ·å–æˆ–åˆ›å»ºé»˜è®¤é…ç½®
        if self._default_config is None:
            self._default_config = get_default_es_config()

        config = self._default_config
        default_client = await self._get_client(
            hosts=config["hosts"],
            username=config.get("username"),
            password=config.get("password"),
            api_key=config.get("api_key"),
            timeout=config.get("timeout", 120),
        )

        # æ³¨å†Œä¸€ä¸ªé»˜è®¤çš„å®¢æˆ·ç«¯
        async_connections.add_connection(
            alias="default", conn=default_client.async_client
        )
        return default_client

    async def remove_client(
        self,
        hosts: List[str],
        username: Optional[str] = None,
        password: Optional[str] = None,
        api_key: Optional[str] = None,
    ) -> bool:
        """
        ç§»é™¤æŒ‡å®šçš„å®¢æˆ·ç«¯

        Args:
            hosts: Elasticsearchä¸»æœºåˆ—è¡¨
            username: ç”¨æˆ·å
            password: å¯†ç 
            api_key: APIå¯†é’¥

        Returns:
            bool: æ˜¯å¦æˆåŠŸç§»é™¤
        """
        cache_key = get_cache_key(hosts, username, password, api_key)

        async with self._lock:
            if cache_key in self._clients:
                client_wrapper = self._clients[cache_key]
                try:
                    await client_wrapper.close()
                except Exception as e:
                    logger.error(
                        "Error closing Elasticsearch client during removal: %s", e
                    )

                del self._clients[cache_key]
                logger.info("Elasticsearch client %s removed from cache", hosts)
                return True
            else:
                logger.warning("Elasticsearch client %s not found in cache", hosts)
                return False

    async def close_all_clients(self) -> None:
        """å…³é—­æ‰€æœ‰ç¼“å­˜çš„å®¢æˆ·ç«¯"""
        async with self._lock:
            for cache_key, client_wrapper in self._clients.items():
                try:
                    await client_wrapper.close()
                except Exception as e:
                    logger.error(
                        "Error closing Elasticsearch client %s: %s", cache_key, e
                    )

            self._clients.clear()
            logger.info("All Elasticsearch clients closed and cleared from cache")
