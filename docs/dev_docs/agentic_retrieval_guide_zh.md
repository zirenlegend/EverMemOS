# Agentic æ£€ç´¢ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

Agentic æ£€ç´¢æ˜¯ä¸€ç§ LLM å¼•å¯¼çš„å¤šè½®æ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡æ™ºèƒ½åˆ¤æ–­å’ŒæŸ¥è¯¢ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡å¤æ‚æŸ¥è¯¢çš„æ£€ç´¢è´¨é‡ã€‚

## æ ¸å¿ƒç‰¹æ€§

âœ… **æ™ºèƒ½åˆ¤æ–­**ï¼šLLM è‡ªåŠ¨åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦å……åˆ†  
âœ… **å¤šè½®æ£€ç´¢**ï¼šä¸å……åˆ†æ—¶è‡ªåŠ¨è¿›è¡Œç¬¬äºŒè½®æ£€ç´¢  
âœ… **å¤šæŸ¥è¯¢ç­–ç•¥**ï¼šç”Ÿæˆ 2-3 ä¸ªäº’è¡¥æŸ¥è¯¢ï¼Œæå‡å¬å›ç‡  
âœ… **è‡ªåŠ¨é™çº§**ï¼šå¤±è´¥æ—¶å›é€€åˆ° Lightweight æ£€ç´¢  
âœ… **å®Œæ•´å…ƒæ•°æ®**ï¼šè¿”å›è¯¦ç»†çš„æ£€ç´¢è¿‡ç¨‹ä¿¡æ¯  

## å¿«é€Ÿå¼€å§‹

### 1. åœ¨å¯¹è¯ç•Œé¢ä½¿ç”¨

è¿è¡Œ `chat_with_memory.py` æ—¶é€‰æ‹©æ£€ç´¢æ¨¡å¼ï¼š

```bash
uv run python src/bootstrap.py demo/chat_with_memory.py
```

é€‰æ‹©ç¬¬ 4 ä¸ªé€‰é¡¹ï¼š`Agentic æ£€ç´¢ - LLM å¼•å¯¼çš„å¤šè½®æ£€ç´¢ï¼ˆå®éªŒæ€§ï¼‰`

### 2. åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from agentic_layer.memory_manager import MemoryManager
from memory_layer.llm.llm_provider import LLMProvider
from agentic_layer.agentic_utils import AgenticConfig

# åˆå§‹åŒ– LLM Provider
llm = LLMProvider(
    provider_type="openai",
    model="gpt-4",
    api_key="your_api_key",
    base_url="https://api.openai.com/v1",
    temperature=0.0,
)

# åˆå§‹åŒ– Memory Manager
memory_manager = MemoryManager()

# æ‰§è¡Œ Agentic æ£€ç´¢
result = await memory_manager.retrieve_agentic(
    query="ç”¨æˆ·å–œæ¬¢åƒä»€ä¹ˆï¼Ÿ",
    group_id="ç¾é£Ÿçˆ±å¥½è€…ç¾¤",
    llm_provider=llm,
    top_k=20,
)

# æŸ¥çœ‹ç»“æœ
print(f"æ£€ç´¢åˆ° {result['count']} æ¡è®°å¿†")
print(f"æ˜¯å¦å……åˆ†: {result['metadata']['is_sufficient']}")

if result['metadata']['is_multi_round']:
    print(f"æ”¹è¿›æŸ¥è¯¢: {result['metadata']['refined_queries']}")
```

## é«˜çº§é…ç½®

### è‡ªå®šä¹‰ Agentic é…ç½®

```python
from agentic_layer.agentic_utils import AgenticConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
config = AgenticConfig(
    # Round 1 é…ç½®
    round1_emb_top_n=50,        # Embedding å€™é€‰æ•°
    round1_bm25_top_n=50,       # BM25 å€™é€‰æ•°
    round1_top_n=20,            # RRF èåˆåè¿”å›æ•°
    round1_rerank_top_n=5,      # Rerank åç”¨äº LLM åˆ¤æ–­
    
    # LLM é…ç½®
    llm_temperature=0.0,        # åˆ¤æ–­ç”¨ä½æ¸©åº¦
    llm_max_tokens=500,
    
    # Round 2 é…ç½®
    enable_multi_query=True,    # æ˜¯å¦å¯ç”¨å¤šæŸ¥è¯¢
    num_queries=3,              # æœŸæœ›ç”ŸæˆæŸ¥è¯¢æ•°é‡
    round2_per_query_top_n=50,  # æ¯ä¸ªæŸ¥è¯¢å¬å›æ•°
    
    # èåˆé…ç½®
    combined_total=40,          # åˆå¹¶åæ€»æ•°
    final_top_n=20,             # æœ€ç»ˆè¿”å›æ•°
    
    # Rerank é…ç½®
    use_reranker=True,
    reranker_instruction="æ ¹æ®æŸ¥è¯¢ä¸è®°å¿†çš„ç›¸å…³æ€§è¿›è¡Œæ’åº",
)

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
result = await memory_manager.retrieve_agentic(
    query="ç”¨æˆ·å–œæ¬¢åƒä»€ä¹ˆï¼Ÿ",
    group_id="ç¾é£Ÿçˆ±å¥½è€…ç¾¤",
    llm_provider=llm,
    agentic_config=config,
)
```

## è¿”å›æ ¼å¼

```python
{
    "memories": [
        {
            "event_id": "...",
            "user_id": "...",
            "group_id": "...",
            "timestamp": "2024-01-15T10:30:00",
            "episode": "ç”¨æˆ·è¯´ä»–æœ€å–œæ¬¢åƒå·èœï¼Œå°¤å…¶æ˜¯éº»å©†è±†è…",
            "summary": "ç”¨æˆ·çš„èœç³»åå¥½",
            "subject": "é¥®é£Ÿä¹ æƒ¯",
            "score": 0.95
        },
        # ... æ›´å¤šè®°å¿†
    ],
    "count": 20,
    "metadata": {
        # åŸºæœ¬ä¿¡æ¯
        "retrieval_mode": "agentic",
        "is_multi_round": True,  # æ˜¯å¦è¿›è¡Œäº†å¤šè½®æ£€ç´¢
        
        # Round 1 ç»Ÿè®¡
        "round1_count": 20,
        "round1_reranked_count": 5,
        "round1_latency_ms": 800,
        
        # LLM åˆ¤æ–­
        "is_sufficient": False,
        "reasoning": "ç¼ºå°‘ç”¨æˆ·çš„å…·ä½“èœç³»åå¥½å’Œå£å‘³ä¿¡æ¯",
        "missing_info": ["èœç³»åå¥½", "å£å‘³ä¹ æƒ¯", "å¿Œå£ä¿¡æ¯"],
        
        # Round 2 ç»Ÿè®¡ï¼ˆä»…åœ¨å¤šè½®æ—¶å­˜åœ¨ï¼‰
        "refined_queries": [
            "ç”¨æˆ·æœ€å–œæ¬¢çš„èœç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç”¨æˆ·å–œæ¬¢ä»€ä¹ˆå£å‘³ï¼Ÿ",
            "ç”¨æˆ·æœ‰ä»€ä¹ˆé¥®é£Ÿç¦å¿Œï¼Ÿ"
        ],
        "query_strategy": "å°†åŸæŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå…·ä½“å­é—®é¢˜",
        "num_queries": 3,
        "round2_count": 40,
        "round2_latency_ms": 600,
        "multi_query_total_docs": 120,
        
        # æœ€ç»ˆç»Ÿè®¡
        "final_count": 20,
        "total_latency_ms": 3500
    }
}
```

## å·¥ä½œæµç¨‹

```
ç”¨æˆ·æŸ¥è¯¢
  â†“
Round 1: Hybrid Search (Embedding + BM25 + RRF)
  â†“
RRF èåˆ â†’ Top 20
  â†“
Rerank â†’ Top 5
  â†“
LLM åˆ¤æ–­å……åˆ†æ€§
  â†“
â”œâ”€ å……åˆ† â†’ è¿”å› Round 1 çš„ Top 20 âœ…
â”‚
â””â”€ ä¸å……åˆ† â†’ LLM ç”Ÿæˆå¤šæŸ¥è¯¢ï¼ˆ2-3ä¸ªï¼‰
              â†“
          Round 2: å¹¶è¡Œæ£€ç´¢æ‰€æœ‰æŸ¥è¯¢
              â†“
          å¤šæŸ¥è¯¢ RRF èåˆ
              â†“
          å»é‡ + åˆå¹¶åˆ° 40 ä¸ª
              â†“
          Rerank â†’ Top 20 âœ…
```

## æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å•è½®ï¼ˆå……åˆ†ï¼‰ | å¤šè½®ï¼ˆä¸å……åˆ†ï¼‰ |
|------|-------------|---------------|
| å»¶è¿Ÿ | 2-5 ç§’ | 5-10 ç§’ |
| LLM è°ƒç”¨ | 1 æ¬¡ | 2 æ¬¡ |
| Token æ¶ˆè€— | ~500 | ~1500 |
| API è´¹ç”¨ | ~$0.001 | ~$0.003 |

*åŸºäº GPT-4 çš„ä¼°ç®—å€¼*

## é€‚ç”¨åœºæ™¯

### âœ… é€‚åˆä½¿ç”¨ Agentic æ£€ç´¢

1. **å¤æ‚æŸ¥è¯¢**ï¼šéœ€è¦å¤šä¸ªè§’åº¦çš„ä¿¡æ¯
   - âŒ "ç”¨æˆ·å–œæ¬¢åƒä»€ä¹ˆï¼Ÿ"ï¼ˆå¤ªå®½æ³›ï¼‰
   - âœ… "ç”¨æˆ·æœ€å–œæ¬¢çš„å·èœæ˜¯ä»€ä¹ˆï¼Œä»¥åŠå£å‘³åå¥½ï¼Ÿ"

2. **ä¿¡æ¯åˆ†æ•£**ï¼šç›¸å…³è®°å¿†åˆ†å¸ƒåœ¨ä¸åŒæ—¶é—´ç‚¹

3. **é«˜è´¨é‡è¦æ±‚**ï¼šå¯¹å¬å›ç‡å’Œç²¾åº¦è¦æ±‚é«˜çš„åœºæ™¯

### âŒ ä¸é€‚åˆä½¿ç”¨ Agentic æ£€ç´¢

1. **ç®€å•æŸ¥è¯¢**ï¼šå¯ä»¥ç›´æ¥å›ç­”çš„é—®é¢˜
   - "ä»Šå¤©æ˜¯æ˜ŸæœŸå‡ ï¼Ÿ"
   - "ç”¨æˆ·çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ"

2. **å¯¹å»¶è¿Ÿæ•æ„Ÿ**ï¼šè¦æ±‚ < 1 ç§’å“åº”çš„åœºæ™¯

3. **æˆæœ¬æ•æ„Ÿ**ï¼šæ— æ³•æ‰¿æ‹… LLM API è´¹ç”¨

## é™çº§ç­–ç•¥

Agentic æ£€ç´¢åœ¨ä»¥ä¸‹æƒ…å†µä¼šè‡ªåŠ¨é™çº§åˆ° Lightweight æ£€ç´¢ï¼š

1. âŒ LLM API è°ƒç”¨å¤±è´¥
2. âŒ è¶…æ—¶ï¼ˆé»˜è®¤ 60 ç§’ï¼‰
3. âŒ æœªæä¾› `llm_provider`
4. âŒ å€™é€‰è®°å¿†ä¸ºç©º

é™çº§æ—¶ä¼šåœ¨å…ƒæ•°æ®ä¸­æ ‡è®°ï¼š

```python
{
    "metadata": {
        "retrieval_mode": "agentic_fallback",
        "fallback_reason": "LLM API timeout"
    }
}
```

## æˆæœ¬ä¼˜åŒ–

### 1. è°ƒæ•´ LLM æ¨¡å‹

```python
# ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
llm = LLMProvider(
    provider_type="openai",
    model="gpt-4o-mini",  # æ›´ä¾¿å®œ
    # model="gpt-4",      # æ›´å‡†ç¡®ä½†æ›´è´µ
)
```

### 2. ç¦ç”¨å¤šæŸ¥è¯¢

```python
config = AgenticConfig(
    enable_multi_query=False,  # åªç”Ÿæˆ 1 ä¸ªæŸ¥è¯¢ï¼ˆé™ä½æˆæœ¬ï¼‰
)
```

### 3. ç¦ç”¨ Reranker

```python
config = AgenticConfig(
    use_reranker=False,  # ä¸ä½¿ç”¨ Rerankerï¼ˆé™ä½å»¶è¿Ÿå’Œæˆæœ¬ï¼‰
)
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šLLM API è°ƒç”¨å¤±è´¥

**åŸå› **ï¼š
- API Key é”™è¯¯
- ç½‘ç»œé—®é¢˜
- API é™æµ

**è§£å†³**ï¼š
1. æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API Key
2. ç¡®è®¤ç½‘ç»œè¿æ¥
3. æŸ¥çœ‹æ—¥å¿—ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯

### é—®é¢˜ï¼šå»¶è¿Ÿè¿‡é«˜ï¼ˆ> 10 ç§’ï¼‰

**åŸå› **ï¼š
- LLM å“åº”æ…¢
- å€™é€‰è®°å¿†è¿‡å¤š
- Reranker è¶…æ—¶

**è§£å†³**ï¼š
1. å‡å°‘ `time_range_days`ï¼ˆå‡å°‘å€™é€‰æ•°ï¼‰
2. ç¦ç”¨ Reranker
3. ä½¿ç”¨æ›´å¿«çš„ LLM æ¨¡å‹

### é—®é¢˜ï¼šæ£€ç´¢è´¨é‡ä¸ä½³

**åŸå› **ï¼š
- LLM åˆ¤æ–­ä¸å‡†ç¡®
- æŸ¥è¯¢ç”Ÿæˆä¸åˆç†
- Prompt ä¸é€‚é…

**è§£å†³**ï¼š
1. ä½¿ç”¨æ›´å¼ºçš„ LLM æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰
2. è°ƒæ•´ Prompt æ¨¡æ¿ï¼ˆåœ¨ `agentic_utils.py`ï¼‰
3. å¢åŠ  `round1_rerank_top_n`ï¼ˆç»™ LLM æ›´å¤šæ ·æœ¬ï¼‰

## ä¸å…¶ä»–æ£€ç´¢æ¨¡å¼å¯¹æ¯”

| ç‰¹æ€§ | Lightweight | Agentic |
|------|------------|---------|
| å»¶è¿Ÿ | 0.5-2s | 5-10s |
| LLM è°ƒç”¨ | âŒ æ—  | âœ… 1-2æ¬¡ |
| å¤šè½®æ£€ç´¢ | âŒ å¦ | âœ… æ˜¯ |
| å¬å›ç‡ | ä¸­ | é«˜ |
| ç²¾åº¦ | ä¸­ | é«˜ |
| æˆæœ¬ | ä½ | ä¸­ |
| é€‚ç”¨åœºæ™¯ | ç®€å•æŸ¥è¯¢ | å¤æ‚æŸ¥è¯¢ |

## æœ€ä½³å®è·µ

1. âœ… **ä¼˜å…ˆä½¿ç”¨ Lightweight**ï¼šå¯¹äºç®€å•æŸ¥è¯¢ï¼ŒLightweight è¶³å¤Ÿå¥½
2. âœ… **å¤æ‚æŸ¥è¯¢ç”¨ Agentic**ï¼šåªåœ¨éœ€è¦æ—¶ä½¿ç”¨
3. âœ… **ç›‘æ§æˆæœ¬**ï¼šè®°å½• LLM Token æ¶ˆè€—
4. âœ… **æ—¥å¿—åˆ†æ**ï¼šå®šæœŸæŸ¥çœ‹ LLM åˆ¤æ–­æ˜¯å¦åˆç†
5. âœ… **A/B æµ‹è¯•**ï¼šå¯¹æ¯”ä¸åŒæ¨¡å¼çš„æ•ˆæœ

## ç¤ºä¾‹ï¼šå®Œæ•´å¯¹è¯æµç¨‹

```python
import asyncio
from agentic_layer.memory_manager import MemoryManager
from memory_layer.llm.llm_provider import LLMProvider

async def main():
    # åˆå§‹åŒ–
    llm = LLMProvider("openai", model="gpt-4", api_key="...")
    memory_manager = MemoryManager()
    
    # ç”¨æˆ·æŸ¥è¯¢
    query = "ç”¨æˆ·å–œæ¬¢åƒä»€ä¹ˆï¼Ÿæœ‰ä»€ä¹ˆå¿Œå£å—ï¼Ÿ"
    
    # æ‰§è¡Œæ£€ç´¢
    result = await memory_manager.retrieve_agentic(
        query=query,
        group_id="ç¾é£Ÿçˆ±å¥½è€…ç¾¤",
        llm_provider=llm,
    )
    
    # å±•ç¤ºç»“æœ
    print(f"\n{'='*60}")
    print(f"æŸ¥è¯¢: {query}")
    print(f"{'='*60}\n")
    
    print(f"æ£€ç´¢æ¨¡å¼: {result['metadata']['retrieval_mode']}")
    print(f"æ£€ç´¢åˆ° {result['count']} æ¡è®°å¿†")
    print(f"æ€»å»¶è¿Ÿ: {result['metadata']['total_latency_ms']:.0f}ms\n")
    
    # LLM åˆ¤æ–­
    print(f"LLM åˆ¤æ–­: {'âœ… å……åˆ†' if result['metadata']['is_sufficient'] else 'âŒ ä¸å……åˆ†'}")
    print(f"ç†ç”±: {result['metadata']['reasoning']}\n")
    
    # å¤šè½®ä¿¡æ¯
    if result['metadata']['is_multi_round']:
        print(f"ğŸ“ è¿›å…¥ Round 2")
        print(f"ç”ŸæˆæŸ¥è¯¢:")
        for i, q in enumerate(result['metadata']['refined_queries'], 1):
            print(f"  {i}. {q}")
        print()
    
    # å±•ç¤ºè®°å¿†
    print(f"Top 5 è®°å¿†:")
    for i, mem in enumerate(result['memories'][:5], 1):
        print(f"\n[{i}] {mem['timestamp'][:10]}")
        print(f"    {mem['episode'][:100]}...")
        print(f"    åˆ†æ•°: {mem['score']:.3f}")

if __name__ == "__main__":
    asyncio.run(main())
```

## æ›´å¤šèµ„æº

- ğŸ“– [Memory Manager API æ–‡æ¡£](../docs/api_docs/agentic_v3_api.md)
- ğŸ”¬ [æ£€ç´¢è¯„ä¼°](../../evaluation/locomo_evaluation/README.md)
- ğŸ’¡ [æœ€ä½³å®è·µ](../docs/dev_docs/getting_started.md)

---

**æ³¨æ„äº‹é¡¹**ï¼š
- Agentic æ£€ç´¢æ˜¯å®éªŒæ€§åŠŸèƒ½ï¼Œå¯èƒ½åœ¨æœªæ¥ç‰ˆæœ¬ä¸­è°ƒæ•´
- ä½¿ç”¨å‰è¯·ç¡®ä¿ç†è§£ LLM API çš„æˆæœ¬å’Œé™åˆ¶
- å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å…ˆè¿›è¡Œå……åˆ†æµ‹è¯•

