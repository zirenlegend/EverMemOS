# Demo - EverMemOS Interactive Examples

[English](README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh.md)

This directory contains interactive demos showcasing the core functionality of EverMemOS.

## üåè Multi-language Support

The system supports **Chinese and English** language modes with fully automatic binding:

| Config | Data File | Output Directory |
|--------|-----------|------------------|
| `language="zh"` | `data/group_chat_zh.json` | `memcell_outputs/group_chat_zh/` |
| `language="en"` | `data/group_chat_en.json` | `memcell_outputs/group_chat_en/` |

**Core Mechanism**:
- Set the `language` parameter in `extract_memory.py` (`"zh"` or `"en"`)
- System automatically matches corresponding data files and output directories
- Select the same language during chat to properly load memories and profiles

> üí° **Tip**: Extraction and chat languages must match, otherwise Profile files won't be found

## üìÇ Directory Structure

```
demo/
‚îú‚îÄ‚îÄ chat_with_memory.py          # üéØ Main: Interactive chat with memory
‚îú‚îÄ‚îÄ extract_memory.py            # üéØ Main: Memory extraction from conversations
‚îÇ
‚îú‚îÄ‚îÄ chat/                        # Chat system components
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py         # Chat application orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ session.py              # Session management
‚îÇ   ‚îú‚îÄ‚îÄ ui.py                   # User interface
‚îÇ   ‚îî‚îÄ‚îÄ selectors.py            # Language/scenario/group selectors
‚îÇ
‚îú‚îÄ‚îÄ extract/                     # Memory extraction components
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py            # Memory extraction logic
‚îÇ   ‚îî‚îÄ‚îÄ validator.py            # Result validation
‚îÇ
‚îú‚îÄ‚îÄ memory_config.py             # Configuration for both scripts
‚îú‚îÄ‚îÄ memory_utils.py              # Shared utility functions
‚îú‚îÄ‚îÄ i18n_texts.py                # Internationalization texts
‚îÇ
‚îú‚îÄ‚îÄ chat_history/                # üìÅ Output: Chat conversation logs (auto-generated)
‚îú‚îÄ‚îÄ memcell_outputs/             # üìÅ Output: Extracted memories (auto-generated)
‚îÇ
‚îú‚îÄ‚îÄ README.md                    # üìñ Documentation (English)
‚îî‚îÄ‚îÄ README_zh.md                 # üìñ Documentation (Chinese)
```

## üéØ Core Scripts

### 1. `simple_demo.py` - Quick Start Example ‚≠ê

**The simplest way to experience EverMemOS!** Just 67 lines of code demonstrating the complete memory workflow.

**What it demonstrates:**
- üíæ **Store**: Save conversation messages via HTTP API
- ‚è≥ **Index**: Wait for data to be indexed (MongoDB, Elasticsearch, Milvus)
- üîç **Search**: Retrieve relevant memories with natural language queries

**Code example:**
```python
from demo.simple_memory_manager import SimpleMemoryManager

# Create memory manager
memory = SimpleMemoryManager()

# Store conversations
await memory.store("I love playing soccer, often go to the field on weekends")
await memory.store("Soccer is a great sport! Which team do you like?", sender="Assistant")
await memory.store("I love Barcelona the most, Messi is my idol")

# Wait for indexing
await memory.wait_for_index(seconds=10)

# Search memories
await memory.search("What sports does the user like?")
await memory.search("What is the user's favorite team?")
```

**How to run:**

‚ö†Ô∏è **Important**: You must start the API server first!

```bash
# Terminal 1: Start the API server
uv run python src/bootstrap.py start_server.py

# Terminal 2: Run the simple demo
uv run python src/bootstrap.py demo/simple_demo.py
```

**Why this demo?**
- ‚úÖ Minimal code - understand core concepts in seconds
- ‚úÖ Complete workflow - storage ‚Üí indexing ‚Üí retrieval
- ‚úÖ Friendly output - explanations for every step
- ‚úÖ Real HTTP API - uses the same API as production

**Dependencies**: `simple_memory_manager.py` (HTTP API wrapper)

### 2. `extract_memory.py` - Memory Extraction
- Processes conversation files from the `data/` directory
- Extracts MemCells and generates user profiles
- Saves results to configured database (MongoDB) and local outputs
- **Dependencies**: `extract/` module, `memory_config.py`, `memory_utils.py`

### 3. `chat_with_memory.py` - Memory-Enhanced Chat
- Command-line interface for conversing with AI agents
- Leverages extracted memories for context-aware responses
- Demonstrates end-to-end memory retrieval and usage
- **Dependencies**: `chat/` module, `memory_config.py`, `memory_utils.py`, `i18n_texts.py`

## üì¶ Supporting Modules

### Configuration Files
- **`memory_config.py`** - Shared configuration for extraction and chat
- **`memory_utils.py`** - Common utility functions (MongoDB, serialization)
- **`i18n_texts.py`** - Bilingual text resources (Chinese/English)

### Modular Components
- **`chat/`** - Chat system implementation (orchestrator, session, UI, selectors)
- **`extract/`** - Memory extraction implementation (extractor, validator)

## üöÄ Quick Start

### Option A: Super Simple Mode (Recommended for Beginners) ‚≠ê

The fastest way to experience EverMemOS! Just 2 terminals:

```bash
# Terminal 1: Start the API server (required)
uv run python src/bootstrap.py start_server.py

# Terminal 2: Run the simple demo
uv run python src/bootstrap.py demo/simple_demo.py
```

**What happens:**
1. üìù Stores 4 conversation messages
2. ‚è≥ Waits 10 seconds for indexing (MongoDB ‚Üí Elasticsearch ‚Üí Milvus)
3. üîç Searches memories with 3 different queries
4. üìä Shows results with relevance scores and explanations

**Note**: The API server (`start_server.py`) must be running in a separate terminal for the demo to work.

---

### Option B: Full Feature Mode

### Step 1: Configure Language and Scenario

#### Option A: Use Sample Data (Recommended for Beginners)

Edit `extract_memory.py` and use the default configuration:

```python
# üí° Use sample data (default):
EXTRACT_CONFIG = ExtractModeConfig(
    scenario_type=ScenarioType.GROUP_CHAT,  # Scenario: GROUP_CHAT or ASSISTANT
    language="zh",  # üåè Language: zh (Chinese) or en (English)
    enable_profile_extraction=True,
)
```

The system will automatically use the corresponding sample data file (e.g., `data/group_chat_zh.json`).

#### Option B: Use Custom Data

If you have your own conversation data, follow these steps:

**1. Prepare Data File**

Create a JSON file following our data format. For format details, refer to:
- [Group Chat Format Specification](../data_format/group_chat/group_chat_format.md)
- Files in [Sample Data](../data/) as reference

**2. Modify Configuration**

Uncomment and modify the custom data configuration in `extract_memory.py`:

```python
# üí° Use custom data:
EXTRACT_CONFIG = ExtractModeConfig(
    scenario_type=ScenarioType.GROUP_CHAT,
    language="zh",
    data_file=Path("/path/to/your/data.json"),  # üîß Specify your data file path
    output_dir=Path(__file__).parent / "memcell_outputs",  # üîß Output directory (optional)
    group_id="my_custom_group",  # üîß Group ID (optional)
    group_name="My Custom Group",  # üîß Group name (optional)
    enable_profile_extraction=True,
)
```

> üí° **Tip**: Use absolute or relative path to specify your data file location.

### Step 2: Extract Memories

Run the extraction script to extract memories from conversation data:

```bash
# Recommended: Use uv (from project root)
uv run python src/bootstrap.py demo/extract_memory.py

# Alternative: Direct execution (from demo directory)
cd demo
python extract_memory.py
```

The system will automatically:
- Read the corresponding data file (e.g., `data/group_chat_zh.json`)
- Extract MemCells
- Generate user Profiles
- Save to MongoDB and local directory (e.g., `memcell_outputs/group_chat_zh/`)

### Step 3: Start Conversation

Run the chat script to start conversing with AI:

```bash
# Recommended: Use uv (from project root)
uv run python src/bootstrap.py demo/chat_with_memory.py

# Alternative: Direct execution (from demo directory)
cd demo
python chat_with_memory.py
```

**Interactive Selection**:
1. **Language**: Choose `[1] ‰∏≠Êñá` or `[2] English` (should match Step 1 config)
2. **Scenario**: Choose `[1] Assistant Mode` or `[2] Group Chat Mode`

**Chat Features**:
- üí¨ Natural language conversation with memory-based context
- üîç Automatic retrieval of relevant memories (shows retrieval results)
- üìù Auto-save conversation history
- üß† View reasoning process (type `reasoning`)

### üí° Example Use Cases

#### Case 1: Chinese Group Chat (Default, Recommended for Beginners)

```python
# extract_memory.py - No modification needed, use default config
scenario_type=ScenarioType.GROUP_CHAT,
language="zh",
```

**Try asking**: "What did Alex do in the emotion recognition project?"

#### Case 2: English Assistant

```python
# extract_memory.py - Modify config
EXTRACT_CONFIG = ExtractModeConfig(
    data_file=PROJECT_ROOT / "data" / "assistant_chat_en.json",
    prompt_language="en",
    scenario_type=ScenarioType.ASSISTANT,
    output_dir=Path(__file__).parent / "memcell_outputs" / "assistant_en",
)
```

Run extraction ‚Üí Start chat ‚Üí Select `[2] English` + `[1] Assistant Mode`

**Try asking**: "What foods might I like?"

## üìÅ Data Files and Output Directories

### Data Files (Auto-binding)

The system automatically selects the corresponding data file based on configuration:

| Scenario | Language | Data File |
|----------|----------|-----------|
| Group Chat | Chinese | `data/group_chat_zh.json` |
| Group Chat | English | `data/group_chat_en.json` |
| Assistant | Chinese | `data/assistant_chat_zh.json` |
| Assistant | English | `data/assistant_chat_en.json` |

All data files follow the [GroupChatFormat](../data_format/group_chat/group_chat_format.md) specification. See [data documentation](../data/README.md) for details.

### Output Directories (Auto-created)

Extracted files are saved under `memcell_outputs/`:

```
demo/memcell_outputs/
‚îú‚îÄ‚îÄ group_chat_zh/          # Chinese Group Chat
‚îÇ   ‚îú‚îÄ‚îÄ profiles/           # User Profiles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profile_user_101.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ memcell_*.json      # MemCells
‚îú‚îÄ‚îÄ group_chat_en/          # English Group Chat
‚îú‚îÄ‚îÄ assistant_zh/           # Chinese Assistant
‚îÇ   ‚îî‚îÄ‚îÄ profiles_companion/ # Companion Profiles
‚îî‚îÄ‚îÄ assistant_en/           # English Assistant
```

## üí¨ Chat Commands

During chat sessions, the following commands are supported:

- **Normal Input**: Type questions directly, AI will answer based on memories
- `help` - Show help information
- `reasoning` - View complete reasoning process of last response
- `clear` - Clear current conversation history
- `reload` - Reload memories and profiles
- `exit` - Save conversation history and exit
- `Ctrl+C` - Interrupt and save

## ‚öôÔ∏è Configuration

### Quick Configuration (Recommended)

All configuration is done in `extract_memory.py`. Simply modify these parameters:

```python
# Get project root directory
PROJECT_ROOT = Path(__file__).resolve().parents[1]

EXTRACT_CONFIG = ExtractModeConfig(
    # üìÅ Data file path (Required)
    data_file=PROJECT_ROOT / "data" / "assistant_chat_zh.json",
    
    # üåè Prompt language (Required: "zh" or "en")
    prompt_language="zh",
    
    # üéØ Scenario type
    scenario_type=ScenarioType.ASSISTANT,  # or ScenarioType.GROUP_CHAT
    
    # üìÇ Output directory (Optional, defaults to demo/memcell_outputs/)
    output_dir=Path(__file__).parent / "memcell_outputs" / "assistant_zh",
    
    # Other settings
    enable_profile_extraction=False,  # V4: Profile extraction not yet supported
)
```

**üåè Prompt Language Parameter - Critical**

The `prompt_language` parameter controls which language prompts are used during extraction:
- `prompt_language="zh"` ‚Üí Uses prompts from `src/memory_layer/prompts/zh/`
- `prompt_language="en"` ‚Üí Uses prompts from `src/memory_layer/prompts/en/`

This ensures MemCell, Profile, Episode, and Semantic memory extraction all use the correct language prompts.

> üí° **Best Practice**: Match your prompt language with your data language. For Chinese conversations, use `"zh"`. For English conversations, use `"en"`.

**Example Configurations:**

```python
# Example 1: Chinese data with Chinese prompts
EXTRACT_CONFIG = ExtractModeConfig(
    data_file=PROJECT_ROOT / "data" / "group_chat_zh.json",
    prompt_language="zh",
    scenario_type=ScenarioType.GROUP_CHAT,
    output_dir=Path(__file__).parent / "memcell_outputs" / "group_chat_zh",
)

# Example 2: English data with English prompts
EXTRACT_CONFIG = ExtractModeConfig(
    data_file=PROJECT_ROOT / "data" / "assistant_chat_en.json",
    prompt_language="en",
    scenario_type=ScenarioType.ASSISTANT,
    output_dir=Path(__file__).parent / "memcell_outputs" / "assistant_en",
)
```

### Advanced Configuration

Edit `memory_config.py` to customize:
- **LLM Config**: Model selection, API Key, temperature
- **Embedding Config**: Vectorization service URL and model
- **MongoDB Config**: Database connection settings
- **Extraction Parameters**: Batch size, concurrency, performance optimization
- **Chat Parameters**: History window size, retrieval count, display options

### Environment Variables

Create a `.env` file in the project root (refer to `env.template`):

```bash
# LLM Configuration
LLM_MODEL=your_model
LLM_API_KEY=your_api_key
LLM_BASE_URL=your_base_url

# Embedding Model Configuration
EMB_BASE_URL=http://localhost:11000/v1/embeddings
EMB_MODEL=Qwen3-Embedding-4B

# MongoDB Configuration
MONGODB_URI=mongodb://localhost:27017/memsys
```

## üîó Related Documentation

- [Group Chat Format Specification](../data_format/group_chat/group_chat_format.md)
- [API Documentation](../docs/api_docs/agentic_v3_api.md)
- [Data Documentation](../data/README.md)
- [Internationalization Guide](../docs/dev_docs/chat_i18n_usage.md)

## üìñ Demo Data Overview

### Group Chat Scenario (group_chat_en.json / group_chat_zh.json)

**Project Context:** AI product work group documenting the complete development journey of "Smart Sales Assistant"

**Key Contents:**
- MVP development phase: RAG-based Q&A system
- Advanced feature iteration: Emotion recognition, memory system
- Team collaboration practices: Complete workflow from requirements to delivery

**Available in:** English and Chinese versions

**Good for exploring:** Team collaboration patterns, project management, technical solution evolution

### Assistant Scenario (assistant_chat_en.json / assistant_chat_zh.json)

**Conversation Context:** Personal health & lifestyle assistant documenting nearly 2 months of continuous interaction

**Key Contents:**
- Travel planning: Food recommendations, itinerary suggestions
- Health management: Weight monitoring, dietary guidance
- Exercise recovery: Training advice, post-injury rehabilitation

**Available in:** English and Chinese versions

**Good for exploring:** Personalized services, long-term memory accumulation, contextual understanding

## ‚ùì Recommended Questions

**Group Chat AI Scenario Examples:**
- What did Alex/Betty/... do in the emotion recognition project?
- Based on the emotion recognition project, what work capabilities does Alex/Betty/... demonstrate?
- What are the deliverable results of the emotion recognition project?
- How is the memory system project progressing?

**Assistant AI Scenario Examples:**
- Please recommend sports suitable for me.
- Please recommend food I might like.
- How is my health condition?


## üîó Related Documentation

- üìã [Group Chat Format Specification](../data_format/group_chat/group_chat_format.md) - Data file format
- üîå [API Documentation](../docs/api_docs/agentic_v3_api.md) - API reference
- üì¶ [Data Documentation](../data/README.md) - Sample data details
- üè† [Project Home](../README.md) - Project overview and architecture
- üìò [Batch Memorization Guide](../docs/dev_docs/run_memorize_usage.md) - Advanced usage

## ‚ùì FAQ

### Q: Can't find Profile files?
**A**: Ensure the `language` parameter used during extraction matches the language selected during chat. For example: extraction with `language="zh"` ‚Üí chat with `[1] ‰∏≠Êñá`

### Q: How to switch languages?
**A**: Modify the `language` parameter in `extract_memory.py`, re-run the extraction script, then select the corresponding language during chat.

### Q: What scenarios are supported?
**A**: Two scenarios are supported:
- **Group Chat Mode (GROUP_CHAT)**: Multi-person conversations, extracts group memories and user profiles
- **Assistant Mode (ASSISTANT)**: One-on-one conversations, extracts personalized companion profiles

### Q: What's the data file format?
**A**: JSON format following the [GroupChatFormat](../data_format/group_chat/group_chat_format.md) specification. We provide 4 example files for reference.

### Q: How to use my own data?
**A**: Three simple steps:
1. Prepare your JSON data file following the [Data Format Specification](../data_format/group_chat/group_chat_format.md)
2. Uncomment the "Use custom data" configuration section in `extract_memory.py`
3. Modify the `data_file` parameter to point to your data file path

### Q: What format is required for custom data?
**A**: Basic requirements:
- JSON format file
- Contains `conversation_list` array, or is directly a message array
- Each message must include at least: `sender_name` (sender), `content` (content), `create_time` (timestamp)
- Detailed specification: [GroupChatFormat](../data_format/group_chat/group_chat_format.md)

## üí° Need Help?

- üè† See the main [README](../README.md) for project setup and architecture
- üí¨ Open an issue on GitHub
- üìß Contact project maintainers

---

**Happy exploring! üß†‚ú®**

