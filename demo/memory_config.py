"""å…±äº«é…ç½®æ¨¡å— - ç”¨äºè®°å¿†æå–å’Œå¯¹è¯ç³»ç»Ÿ

æœ¬æ¨¡å—å®šä¹‰äº†æ‰€æœ‰é…ç½®ç±»ï¼Œä¾› extract_memory.py å’Œ chat_with_memory.py å…±åŒä½¿ç”¨ã€‚

é…ç½®ç±»ï¼š
- ScenarioType: åœºæ™¯ç±»å‹æšä¸¾
- RunMode: è¿è¡Œæ¨¡å¼æšä¸¾ï¼ˆç”¨äºæå–è„šæœ¬ï¼‰
- LLMConfig: LLM é…ç½®
- EmbeddingConfig: åµŒå…¥æ¨¡å‹é…ç½®
- MongoDBConfig: MongoDB é…ç½®
- ExtractModeConfig: æå–æ¨¡å¼é…ç½®
- ChatModeConfig: å¯¹è¯æ¨¡å¼é…ç½®
"""

import os
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum
from typing import Optional, Set


class ScenarioType(Enum):
    """åœºæ™¯ç±»å‹æšä¸¾"""

    ASSISTANT = "assistant"  # åŠ©æ‰‹åœºæ™¯ï¼šå•äººå¯¹è¯
    GROUP_CHAT = "group_chat"  # ç¾¤èŠåœºæ™¯ï¼šå¤šäººå¯¹è¯


class RunMode(Enum):
    """è¿è¡Œæ¨¡å¼æšä¸¾ï¼ˆç”¨äºæå–è„šæœ¬ï¼‰"""

    EXTRACT_ALL = "extract_all"  # å®Œæ•´æå–ï¼šMemCell + Profile
    EXTRACT_MEMCELL_ONLY = "extract_memcell"  # ä»…æå– MemCell
    EXTRACT_PROFILE_ONLY = "extract_profile"  # ä»…æå– Profileï¼ˆä»å·²æœ‰ MemCellï¼‰

    # å‘åå…¼å®¹
    EXTRACT = "extract_all"


@dataclass
class LLMConfig:
    """LLM é…ç½®

    ç”¨äºé…ç½®å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°ï¼ŒåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€API é…ç½®å’Œç”Ÿæˆå‚æ•°ã€‚
    """

    provider: str = "openai"
    model: Optional[str] = None
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.3
    max_tokens: int = 16384

    def __post_init__(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        self.model = self.model or os.getenv("LLM_MODEL")
        self.api_key = self.api_key or os.getenv("LLM_API_KEY")
        self.base_url = self.base_url or os.getenv("LLM_BASE_URL")


@dataclass
class EmbeddingConfig:
    """åµŒå…¥æ¨¡å‹é…ç½®

    ç”¨äºé…ç½®å‘é‡åµŒå…¥æœåŠ¡çš„å‚æ•°ã€‚
    """

    base_url: Optional[str] = None
    model: Optional[str] = None

    def __post_init__(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        self.base_url = (
            self.base_url
            or os.getenv("EMB_BASE_URL")
            or "http://0.0.0.0:11000/v1/embeddings"
        )
        self.model = self.model or os.getenv("EMB_MODEL") or "Qwen3-Embedding-4B"


@dataclass
class MongoDBConfig:
    """MongoDB é…ç½®

    ç”¨äºé…ç½® MongoDB æ•°æ®åº“è¿æ¥å‚æ•°ã€‚
    """
    uri: Optional[str] = None
    host: str = "localhost"
    port: str = "27017"
    database: str = "memsys"
    username: Optional[str] = None
    password: Optional[str] = None
    
    def __post_init__(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®å¹¶æ„å»º URI"""
        if not os.getenv("MONGODB_URI"):
            self.host = os.getenv("MONGODB_HOST", self.host)
            self.port = os.getenv("MONGODB_PORT", self.port)
            self.database = os.getenv("MONGODB_DATABASE", self.database)
            self.username = os.getenv("MONGODB_USERNAME")
            self.password = os.getenv("MONGODB_PASSWORD")
            
            if self.username and self.password:
                from urllib.parse import quote_plus
                self.uri = f"mongodb://{quote_plus(self.username)}:{quote_plus(self.password)}@{self.host}:{self.port}/{self.database}"
            else:
                self.uri = f"mongodb://{self.host}:{self.port}/{self.database}"
            uri_params = os.getenv("MONGODB_URI_PARAMS", "").strip()
            if uri_params:
                separator = '&' if ('?' in self.uri) else '?'
                self.uri = f"{self.uri}{separator}{uri_params}"

        else:
            self.uri = os.getenv("MONGODB_URI")
            self.database = os.getenv("MONGODB_DATABASE", self.database)

@dataclass
class ExtractModeConfig:
    """æå–æ¨¡å¼é…ç½®

    ç”¨äºé…ç½®è®°å¿†æå–è„šæœ¬çš„å‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®æºã€è¾“å‡ºè·¯å¾„ã€å¤„ç†ç­–ç•¥ç­‰ã€‚
    """

    # ============================================================================
    # ğŸŒ æ ¸å¿ƒé…ç½®ï¼ˆç”¨æˆ·å¿…é¡»é…ç½®çš„å‚æ•°ï¼‰
    # ============================================================================
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    data_file: Path = field(default=None)
    
    # Prompt è¯­è¨€ï¼ˆå¿…å¡«ï¼š"zh" æˆ– "en"ï¼‰
    # ğŸ’¡ æ­¤å‚æ•°æ§åˆ¶æå–æ—¶ä½¿ç”¨çš„ Prompt è¯­è¨€ï¼ˆä¸­æ–‡ Prompt æˆ–è‹±æ–‡ Promptï¼‰
    prompt_language: str = "zh"
    
    # åœºæ™¯ç±»å‹ï¼ˆå†³å®šä½¿ç”¨å“ªç§ Profile æå–å™¨ï¼‰
    scenario_type: ScenarioType = ScenarioType.GROUP_CHAT

    # ============================================================================
    # è¾“å‡ºé…ç½®
    # ============================================================================
    
    # è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º memcell_outputs/ï¼‰
    output_dir: Optional[Path] = None

    # ç¾¤ç»„ IDï¼ˆç”¨äºæ ‡è¯†å¯¹è¯æ¥æºï¼‰
    group_id: str = "ai_group"

    # ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼Œç”¨äº Profile æå–ï¼‰
    group_name: Optional[str] = None

    # æ”¯æŒçš„æ¶ˆæ¯ç±»å‹ï¼ˆtext/image/file/audio/video/link/system ç­‰å­—ç¬¦ä¸²ç±»å‹ï¼‰
    supported_msg_types: Optional[Set[str]] = None

    # å†å²æ¶ˆæ¯çª—å£å¤§å°ï¼ˆæ§åˆ¶å†…å­˜ä½¿ç”¨ï¼‰
    history_window_size: int = 20

    # Profile æå–é…ç½®
    profile_extract_batch_size: int = 10  # æ¯ç§¯ç´¯ N ä¸ª MemCell è§¦å‘ä¸€æ¬¡ Profile æå–
    enable_profile_extraction: bool = True  # æ˜¯å¦å¯ç”¨ Profile æå–

    # ğŸ¯ Profile æå–ä¼˜åŒ–é…ç½®ï¼ˆè§£å†³ MemCell æ•°é‡è¿‡å¤šå¯¼è‡´çš„é—®é¢˜ï¼‰
    max_memcells_per_profile_batch: int = (
        50  # å•æ¬¡ Profile æå–æœ€å¤šä½¿ç”¨å¤šå°‘ä¸ª MemCellï¼ˆé¿å…è¶…å‡º LLM token é™åˆ¶ï¼‰
    )
    profile_batch_strategy: str = (
        "latest_first"  # åˆ†æ‰¹ç­–ç•¥ï¼š"latest_first"ï¼ˆæœ€æ–°ä¼˜å…ˆï¼‰, "distributed"ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰, "sequential"ï¼ˆé¡ºåºåˆ†æ‰¹ï¼‰
    )
    enable_token_estimation: bool = True  # å¯ç”¨ Token é¢„ä¼°ï¼ˆæä¾›è­¦å‘Šï¼‰
    max_estimated_tokens: int = 100000  # Token é¢„ä¼°ä¸Šé™ï¼ˆè¶…å‡ºæ—¶å¼ºåˆ¶åˆ†æ‰¹ï¼‰

    # MemCell æ¥æºé…ç½®ï¼ˆä»…åœ¨ EXTRACT_PROFILE_ONLY æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
    memcell_source: str = "file"  # "file": ä» JSON æ–‡ä»¶åŠ è½½, "mongodb": ä» MongoDB åŠ è½½
    memcell_input_dir: Optional[Path] = None  # MemCell è¾“å…¥ç›®å½•ï¼ˆç”¨äº file æ¨¡å¼ï¼‰

    # å¹¶è¡Œå¤„ç†é…ç½®
    max_concurrent_profiles: int = 4  # Profile æå–çš„æœ€å¤§å¹¶å‘æ•°
    max_concurrent_memcells: int = 8  # MemCell æå–çš„æœ€å¤§å¹¶å‘æ•°

    # ğŸš€ æ€§èƒ½ä¼˜åŒ–é…ç½®
    mongo_batch_size: int = 20  # MongoDB æ‰¹é‡å†™å…¥å¤§å°
    embedding_batch_size: int = 32  # å‘é‡åŒ–æ‰¹é‡å¤§å°
    enable_progress_bar: bool = True  # å¯ç”¨è¿›åº¦æ¡
    enable_performance_metrics: bool = True  # å¯ç”¨æ€§èƒ½æŒ‡æ ‡è¿½è¸ª

    enable_semantic_extraction: Optional[bool] = None

    def __post_init__(self):
        """åˆå§‹åŒ–é…ç½®ï¼Œè®¾ç½®é»˜è®¤å€¼"""
        # éªŒè¯å¿…å¡«å‚æ•°
        if self.data_file is None:
            raise ValueError("data_file æ˜¯å¿…å¡«å‚æ•°ï¼Œè¯·æŒ‡å®šæ•°æ®æ–‡ä»¶è·¯å¾„")
        
        # éªŒè¯ Prompt è¯­è¨€
        if self.prompt_language not in ["zh", "en"]:
            raise ValueError(f"prompt_language å¿…é¡»æ˜¯ 'zh' æˆ– 'en'ï¼Œå½“å‰å€¼: {self.prompt_language}")
        
        # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
        if self.output_dir is None:
            self.output_dir = Path(__file__).parent / "memcell_outputs"
        
        # è®¾ç½®é»˜è®¤æ¶ˆæ¯ç±»å‹
        if self.supported_msg_types is None:
            self.supported_msg_types = {
                "text",
                "image",
                "file",
                "audio",
                "video",
                "link",
                "system",
            }
        
        # æ ¹æ®åœºæ™¯ç±»å‹è®¾ç½®è¯­ä¹‰æå–é€‰é¡¹
        if self.enable_semantic_extraction is None:
            if self.scenario_type == ScenarioType.ASSISTANT:
                self.enable_semantic_extraction = True
            elif self.scenario_type == ScenarioType.GROUP_CHAT:
                self.enable_semantic_extraction = False

        # æ ¹æ®åœºæ™¯ç±»å‹è‡ªåŠ¨è°ƒæ•´é»˜è®¤é…ç½®
        if self.scenario_type == ScenarioType.GROUP_CHAT:
            if self.group_id == "ai_group":
                self.group_id = "group_chat_001"
            if self.group_name is None:
                self.group_name = "Project Discussion Group"
        elif self.scenario_type == ScenarioType.ASSISTANT:
            if self.group_id == "ai_group":
                self.group_id = "assistant"
            if self.group_name is None:
                self.group_name = "Personal Assistant"

        # è®¾ç½®é»˜è®¤çš„ MemCell è¾“å…¥ç›®å½•
        if self.memcell_input_dir is None:
            self.memcell_input_dir = self.output_dir


class RetrievalMode(Enum):
    """æ£€ç´¢æ¨¡å¼æšä¸¾"""
    
    LIGHTWEIGHT = "lightweight"  # è½»é‡çº§æ£€ç´¢ï¼šå¿«é€Ÿä½†è´¨é‡ç•¥ä½
    AGENTIC = "agentic"  # Agentic æ£€ç´¢ï¼šæ…¢ä½†è´¨é‡é«˜


@dataclass
class ChatModeConfig:
    """å¯¹è¯æ¨¡å¼é…ç½®

    ç”¨äºé…ç½®è®°å¿†å¢å¼ºå¯¹è¯ç³»ç»Ÿçš„å‚æ•°ï¼ŒåŒ…æ‹¬å¯¹è¯å†å²ã€è®°å¿†æ£€ç´¢ã€æ˜¾ç¤ºé€‰é¡¹ç­‰ã€‚
    
    æ³¨æ„ï¼šscenario_type å’Œ language åº”è¯¥åœ¨è¿è¡Œæ—¶ç”±ç”¨æˆ·é€‰æ‹©åŠ¨æ€è®¾ç½®ï¼Œ
    ä¸å»ºè®®åœ¨é…ç½®ä¸­ç¡¬ç¼–ç ã€‚è·¯å¾„ä¼šåœ¨ ChatSession åˆå§‹åŒ–æ—¶æ ¹æ®è¿è¡Œæ—¶å‚æ•°åŠ¨æ€ç¡®å®šã€‚
    """

    # API é…ç½®
    api_base_url: Optional[str] = None  # V3 API åŸºç¡€ URLï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰

    # å¯¹è¯å†å²é…ç½®
    conversation_history_size: int = 10  # ä¿ç•™æœ€è¿‘ N è½®å¯¹è¯

    # è®°å¿†æ£€ç´¢é…ç½®
    top_k_memories: int = 20  # æ¯æ¬¡æ£€ç´¢ N æ¡è®°å¿†
    time_range_days: int = 365  # è®°å¿†æ£€ç´¢çš„æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰
    retrieval_strategy: str = "vector_similarity"  # æ£€ç´¢ç­–ç•¥ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰
    
    # ğŸ”¥ æ–°å¢ï¼šæ£€ç´¢æ¨¡å¼é…ç½®
    retrieval_mode: RetrievalMode = RetrievalMode.LIGHTWEIGHT  # æ£€ç´¢æ¨¡å¼ï¼ˆè¿è¡Œæ—¶å¯è¦†ç›–ï¼‰
    
    # ğŸ”¥ è½»é‡çº§æ£€ç´¢å‚æ•°
    lightweight_emb_top_n: int = 50  # Embedding æ£€ç´¢çš„å€™é€‰æ•°
    lightweight_bm25_top_n: int = 50  # BM25 æ£€ç´¢çš„å€™é€‰æ•°
    lightweight_final_top_n: int = 20  # RRF èåˆåçš„æœ€ç»ˆç»“æœæ•°
    
    # ğŸ”¥ Agentic æ£€ç´¢å‚æ•°
    hybrid_emb_candidates: int = 100  # Embedding å€™é€‰æ•°
    hybrid_bm25_candidates: int = 100  # BM25 å€™é€‰æ•°
    hybrid_rrf_k: int = 60  # RRF èåˆå‚æ•° k
    use_reranker: bool = True  # æ˜¯å¦ä½¿ç”¨ Reranker
    reranker_instruction: str = "Given a user query and a memory, rate the relevance of the memory to the query."
    reranker_batch_size: int = 10  # Reranker æ‰¹æ¬¡å¤§å°
    reranker_max_retries: int = 3  # Reranker æœ€å¤§é‡è¯•æ¬¡æ•°
    reranker_retry_delay: float = 2.0  # Reranker é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    reranker_timeout: float = 30.0  # Reranker è¶…æ—¶ï¼ˆç§’ï¼‰
    reranker_fallback_threshold: float = 0.3  # Reranker é™çº§é˜ˆå€¼
    reranker_concurrent_batches: int = 2  # Reranker å¹¶å‘æ‰¹æ¬¡æ•°
    use_multi_query: bool = True  # æ˜¯å¦ä½¿ç”¨å¤šæŸ¥è¯¢ç­–ç•¥
    num_queries: int = 3  # ç”Ÿæˆçš„æŸ¥è¯¢æ•°é‡

    # æ˜¾ç¤ºé…ç½®
    show_retrieved_memories: bool = True  # æ˜¯å¦æ˜¾ç¤ºæ£€ç´¢åˆ°çš„è®°å¿†
    show_profile_info: bool = True  # æ˜¯å¦æ˜¾ç¤ºä½¿ç”¨çš„ Profile
    verbose_memory_display: bool = False  # æ˜¯å¦è¯¦ç»†æ˜¾ç¤ºè®°å¿†ï¼ˆFalse=ç®€æ´ç‰ˆï¼‰
    show_reasoning_metadata: bool = True  # æ˜¯å¦æ˜¾ç¤ºæ¨ç†å…ƒæ•°æ®ï¼ˆç½®ä¿¡åº¦ã€å¼•ç”¨ç­‰ï¼‰

    # è·¯å¾„é…ç½®ï¼ˆåŸºç¡€ç›®å½•ï¼‰
    chat_history_dir: Path = field(
        default_factory=lambda: Path(__file__).parent / "chat_history"
    )
    memcell_output_dir: Path = field(
        default_factory=lambda: Path(__file__).parent / "memcell_outputs"
    )

    def __post_init__(self):
        """åˆå§‹åŒ–é…ç½®ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨"""
        # ä»ç¯å¢ƒå˜é‡åŠ è½½ API é…ç½®
        if self.api_base_url is None:
            self.api_base_url = os.getenv("API_BASE_URL", "http://localhost:8001")
        
        # ç¡®ä¿å¯¹è¯å†å²ç›®å½•å­˜åœ¨
        self.chat_history_dir.mkdir(parents=True, exist_ok=True)
        # memcell_output_dir ä¸åœ¨è¿™é‡Œè°ƒæ•´ï¼Œç”± ChatSession æ ¹æ®è¿è¡Œæ—¶å‚æ•°åŠ¨æ€ç¡®å®š
