"""Agentic æ£€ç´¢å®Œæ•´æµ‹è¯•è„šæœ¬

å®Œå…¨æŒ‰ç…§ test_retrieval_comprehensive.py çš„æ€è·¯ï¼š
- å¤šåœºæ™¯æµ‹è¯•ï¼ˆä¸ªäººã€ç¾¤ç»„ã€å¤šç»´åº¦ï¼‰
- ç»Ÿè®¡æ±‡æ€»ï¼ˆæˆåŠŸç‡ã€multi-round æ¯”ä¾‹ã€å¹³å‡è€—æ—¶ï¼‰
- ç»“æœå¯¼å‡ºåˆ° JSON

ä½¿ç”¨æ–¹æ³•ï¼š
    # ç¡®ä¿ API æœåŠ¡å™¨å·²å¯åŠ¨
    uv run python src/bootstrap.py src/run.py --port 8001
    
    # åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œæµ‹è¯•
    uv run python src/bootstrap.py demo/tools/test_agentic_retrieve.py
    
    # æˆ–ä½¿ç”¨ Mock LLMï¼ˆä¸éœ€è¦çœŸå® API Keyï¼‰
    uv run python src/bootstrap.py demo/tools/test_agentic_retrieve.py --mock-llm
"""

import asyncio
import httpx
import os
from typing import List, Dict, Any, Optional
from datetime import datetime

try:
    from aiohttp import web
except ImportError:
    web = None


class AgenticRetrievalTester:
    """Agentic æ£€ç´¢æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8001"):
        """åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            base_url: API æœåŠ¡å™¨åœ°å€
        """
        self.base_url = base_url
        self.retrieve_url = f"{base_url}/api/v3/agentic/retrieve_agentic"
        
        # æµ‹è¯•ç»“æœç»Ÿè®¡
        self.total_tests = 0
        self.successful_tests = 0
        self.failed_tests = 0
        self.test_results = []
        
        # Agentic ç‰¹æœ‰ç»Ÿè®¡
        self.multi_round_count = 0
        self.sufficient_count = 0
        
    async def test_agentic(
        self,
        query: str,
        user_id: str,
        group_id: str = None,
        top_k: int = 10,
        time_range_days: int = 365,
        llm_config: Dict[str, Any] = None,
        test_name: str = None,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡ Agentic æ£€ç´¢æµ‹è¯•
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            user_id: ç”¨æˆ·ID
            group_id: ç¾¤ç»„ID
            top_k: è¿”å›ç»“æœæ•°é‡
            time_range_days: æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰
            llm_config: LLM é…ç½®
            test_name: æµ‹è¯•åç§°
            
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        self.total_tests += 1
        
        if test_name is None:
            test_name = f"agentic_{self.total_tests}"
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        payload = {
            "query": query,
            "user_id": user_id,
            "top_k": top_k,
            "time_range_days": time_range_days,
            "llm_config": llm_config or {},
        }
        
        if group_id:
            payload["group_id"] = group_id
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(self.retrieve_url, json=payload)
                response.raise_for_status()
                result = response.json()
                
                if result.get("status") == "ok":
                    memories = result.get("result", {}).get("memories", [])
                    metadata = result.get("result", {}).get("metadata", {})
                    
                    # æå– Agentic ç‰¹æœ‰ä¿¡æ¯
                    is_multi_round = metadata.get("is_multi_round", False)
                    is_sufficient = metadata.get("is_sufficient", None)
                    reasoning = metadata.get("reasoning", "")
                    missing_info = metadata.get("missing_info", [])
                    refined_queries = metadata.get("refined_queries", [])
                    round1_count = metadata.get("round1_count", 0)
                    round2_count = metadata.get("round2_count", 0)
                    final_count = metadata.get("final_count", len(memories))
                    latency = metadata.get("total_latency_ms", 0)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    if is_multi_round:
                        self.multi_round_count += 1
                    if is_sufficient:
                        self.sufficient_count += 1
                    
                    self.successful_tests += 1
                    test_result = {
                        "test_name": test_name,
                        "status": "âœ… æˆåŠŸ",
                        "query": query,
                        "user_id": user_id,
                        "group_id": group_id,
                        "count": len(memories),
                        "latency_ms": latency,
                        "is_multi_round": is_multi_round,
                        "is_sufficient": is_sufficient,
                        "reasoning": reasoning,
                        "missing_info": missing_info,
                        "refined_queries": refined_queries,
                        "round1_count": round1_count,
                        "round2_count": round2_count,
                        "final_count": final_count,
                        "metadata": metadata,
                        "memories": memories[:3],  # åªä¿å­˜å‰3æ¡
                    }
                    
                    # æ‰“å°è¯¦ç»†ä¿¡æ¯
                    print(f"\n  âœ… {test_name}: æ‰¾åˆ° {len(memories)} æ¡è®°å¿†")
                    print(f"     æŸ¥è¯¢: {query[:50]}{'...' if len(query) > 50 else ''}")
                    print(f"     è€—æ—¶: {latency:.2f}ms")
                    print(f"     å¤šè½®: {'æ˜¯' if is_multi_round else 'å¦'}")
                    print(f"     å……åˆ†: {'æ˜¯' if is_sufficient else 'å¦'}")
                    if reasoning:
                        print(f"     LLM åˆ¤æ–­: {reasoning[:60]}{'...' if len(reasoning) > 60 else ''}")
                    if refined_queries:
                        print(f"     æ”¹è¿›æŸ¥è¯¢: {refined_queries}")
                    print(f"     Round1: {round1_count} æ¡ â†’ Round2: {round2_count} æ¡ â†’ æœ€ç»ˆ: {final_count} æ¡")
                    
                    # æ‰“å°å‰3æ¡è®°å¿†çš„æ‘˜è¦
                    if memories:
                        print(f"\n     ğŸ¯ Top 3 è®°å¿†æ‘˜è¦:")
                        for i, mem in enumerate(memories[:3], 1):
                            score = mem.get('score', 0)
                            subject = mem.get('subject', '')
                            summary = mem.get('summary', '')
                            episode = mem.get('episode', '')
                            content = subject or summary or episode[:60]
                            print(f"       [{i}] åˆ†æ•°: {score:.4f} | {content[:50]}{'...' if len(content) > 50 else ''}")
                    
                    return test_result
                else:
                    self.failed_tests += 1
                    error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                    print(f"  âŒ {test_name}: æ£€ç´¢å¤±è´¥ - {error_msg}")
                    return {
                        "test_name": test_name,
                        "status": "âŒ å¤±è´¥",
                        "error": error_msg,
                    }
                    
        except httpx.ConnectError:
            self.failed_tests += 1
            print(f"  âŒ {test_name}: æ— æ³•è¿æ¥åˆ° API æœåŠ¡å™¨")
            return {
                "test_name": test_name,
                "status": "âŒ è¿æ¥å¤±è´¥",
                "error": "æ— æ³•è¿æ¥åˆ° API æœåŠ¡å™¨",
            }
        except Exception as e:
            self.failed_tests += 1
            print(f"  âŒ {test_name}: å¼‚å¸¸ - {e}")
            return {
                "test_name": test_name,
                "status": "âŒ å¼‚å¸¸",
                "error": str(e),
            }
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*80)
        print("ğŸ“Š Agentic æ£€ç´¢æµ‹è¯•æ€»ç»“")
        print("="*80)
        print(f"æ€»æµ‹è¯•æ•°: {self.total_tests}")
        print(f"æˆåŠŸ: {self.successful_tests} âœ…")
        print(f"å¤±è´¥: {self.failed_tests} âŒ")
        if self.total_tests > 0:
            print(f"æˆåŠŸç‡: {(self.successful_tests/self.total_tests*100):.1f}%")
        
        # Agentic ç‰¹æœ‰ç»Ÿè®¡
        print(f"\nğŸ” Agentic ç‰¹æ€§ç»Ÿè®¡:")
        if self.successful_tests > 0:
            print(f"  å¤šè½®æ£€ç´¢: {self.multi_round_count}/{self.successful_tests} ({(self.multi_round_count/self.successful_tests*100):.1f}%)")
            print(f"  LLM åˆ¤å®šå……åˆ†: {self.sufficient_count}/{self.successful_tests} ({(self.sufficient_count/self.successful_tests*100):.1f}%)")
        
        # å¹³å‡è€—æ—¶
        successful_results = [r for r in self.test_results if r.get("status") == "âœ… æˆåŠŸ"]
        if successful_results:
            avg_latency = sum(r.get("latency_ms", 0) for r in successful_results) / len(successful_results)
            avg_count = sum(r.get("count", 0) for r in successful_results) / len(successful_results)
            print(f"\nğŸ“ˆ å¹³å‡æŒ‡æ ‡:")
            print(f"  å¹³å‡è€—æ—¶: {avg_latency:.2f}ms")
            print(f"  å¹³å‡å¬å›: {avg_count:.1f} æ¡")
        
        # å¤±è´¥çš„æµ‹è¯•è¯¦æƒ…
        failed_results = [r for r in self.test_results if r.get("status") != "âœ… æˆåŠŸ"]
        if failed_results:
            print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
            for r in failed_results:
                print(f"  - {r.get('test_name')}: {r.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    def export_results(self, output_file: str = "demo/results/agentic_test_results.json"):
        """å¯¼å‡ºæµ‹è¯•ç»“æœåˆ° JSON æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import json
        from pathlib import Path
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºå¯¼å‡ºæ•°æ®
        export_data = {
            "test_time": datetime.now().isoformat(),
            "summary": {
                "total_tests": self.total_tests,
                "successful_tests": self.successful_tests,
                "failed_tests": self.failed_tests,
                "success_rate": f"{(self.successful_tests/self.total_tests*100):.1f}%" if self.total_tests > 0 else "0%",
                "multi_round_count": self.multi_round_count,
                "sufficient_count": self.sufficient_count,
            },
            "test_results": self.test_results,
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


async def start_mock_llm(port: int = 9001) -> Optional["web.AppRunner"]:
    """å¯åŠ¨ Mock LLM æœåŠ¡å™¨"""
    if web is None:
        raise RuntimeError("éœ€è¦ aiohttp æ‰èƒ½å¯ç”¨ Mock LLMï¼Œè¯·å…ˆ: uv add aiohttp")
    
    import json
    
    async def handle(request: web.Request) -> web.Response:
        data = await request.json()
        prompt = data.get("messages", [{}])[0].get("content", "")
        
        # æ ¹æ® prompt å†…å®¹è¿”å›ä¸åŒå“åº”
        if "æ”¹è¿›æŸ¥è¯¢" in prompt:
            # Multi-query generation
            content = json.dumps(
                {
                    "queries": [
                        "ç”¨æˆ·å–œæ¬¢çš„é¤å…æœ‰å“ªäº›ï¼Ÿ",
                        "robot_001 çš„å£å‘³åå¥½ï¼Ÿ",
                        "ç”¨æˆ·çš„é¥®é£Ÿä¹ æƒ¯å’Œç¦å¿Œï¼Ÿ"
                    ],
                    "reasoning": "mock refinement: ç”Ÿæˆå¤šä¸ªäº’è¡¥æŸ¥è¯¢"
                },
                ensure_ascii=False,
            )
        else:
            # Sufficiency check
            content = json.dumps(
                {
                    "is_sufficient": True,
                    "reasoning": "mock sufficient: æ£€ç´¢ç»“æœå……åˆ†",
                    "missing_information": []
                },
                ensure_ascii=False,
            )
        
        return web.json_response(
            {
                "choices": [
                    {"message": {"content": content}, "finish_reason": "stop"}
                ],
                "usage": {
                    "prompt_tokens": 50,
                    "completion_tokens": 15,
                    "total_tokens": 65,
                },
            }
        )
    
    app = web.Application()
    app.router.add_post("/chat/completions", handle)
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, "127.0.0.1", port)
    await site.start()
    print(f"âœ… Mock LLM å·²å¯åŠ¨: http://127.0.0.1:{port}/chat/completions")
    return runner


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    print("="*80)
    print("ğŸ§ª Agentic æ£€ç´¢å®Œæ•´æµ‹è¯•")
    print("="*80)
    print("\næœ¬æµ‹è¯•å°†ç³»ç»Ÿåœ°æµ‹è¯• Agentic æ£€ç´¢çš„å¤šä¸ªåœºæ™¯ï¼š")
    print("  1. ä¸ªäººè®°å¿†æŸ¥è¯¢ï¼ˆæ—  group_idï¼‰")
    print("  2. ç¾¤ç»„è®°å¿†æŸ¥è¯¢ï¼ˆæœ‰ group_idï¼‰")
    print("  3. å¤šç»´åº¦æ·±æŒ–æŸ¥è¯¢ï¼ˆå¤æ‚é—®é¢˜ï¼‰")
    print("\nâš ï¸  è¯·ç¡®ä¿ API æœåŠ¡å™¨å·²å¯åŠ¨: uv run python src/bootstrap.py src/run.py --port 8001")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ LLM API Key
    api_key = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY") or os.getenv("LLM_API_KEY")
    base_url = os.getenv("OPENROUTER_BASE_URL") or os.getenv("LLM_BASE_URL") or "https://openrouter.ai/api/v1"
    model = os.getenv("LLM_MODEL") or "qwen/qwen3-235b-a22b-2507"
    
    use_mock = False
    mock_runner = None
    
    if not api_key:
        print("\nâš ï¸  æœªæ£€æµ‹åˆ° LLM API Key (OPENROUTER_API_KEY/OPENAI_API_KEY/LLM_API_KEY)")
        print("   å°†ä½¿ç”¨ Mock LLM è¿›è¡Œæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿ LLM å“åº”ï¼‰")
        use_mock = True
    else:
        print(f"\nâœ… æ£€æµ‹åˆ° LLM é…ç½®:")
        print(f"   Base URL: {base_url}")
        print(f"   Model: {model}")
        print(f"   API Key: {api_key[:10]}...")
    
    print("\nâ³ å¼€å§‹æµ‹è¯•...")
    
    # å¯åŠ¨ Mock LLMï¼ˆå¦‚æœéœ€è¦ï¼‰
    if use_mock:
        try:
            mock_runner = await start_mock_llm(port=9001)
            api_key = "mock-key"
            base_url = "http://127.0.0.1:9001"
            model = "mock-llm"
            await asyncio.sleep(0.2)  # ç­‰å¾…æœåŠ¡å¯åŠ¨
        except Exception as e:
            print(f"âŒ å¯åŠ¨ Mock LLM å¤±è´¥: {e}")
            print("   æç¤º: å¦‚éœ€ä½¿ç”¨ Mock LLMï¼Œè¯·å…ˆå®‰è£…: uv add aiohttp")
            return
    
    # LLM é…ç½®
    llm_config = {
        "api_key": api_key,
        "base_url": base_url,
        "model": model,
    }
    
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = AgenticRetrievalTester()
        
        # ========== æµ‹è¯•åœºæ™¯ 1: ä¸ªäººè®°å¿†æŸ¥è¯¢ ==========
        print("\n" + "ğŸ”¬"*40)
        print("æµ‹è¯•åœºæ™¯ 1: ä¸ªäººè®°å¿†æŸ¥è¯¢ï¼ˆæ—  group_idï¼‰")
        print("ğŸ”¬"*40)
        
        result1 = await tester.test_agentic(
            query="åŒ—äº¬æ—…æ¸¸ç¾é£Ÿæ¨è",
            user_id="robot_001",
            group_id=None,
            top_k=10,
            time_range_days=365,
            llm_config=llm_config,
            test_name="åœºæ™¯1_ä¸ªäººè®°å¿†",
        )
        tester.test_results.append(result1)
        await asyncio.sleep(1)
        
        # ========== æµ‹è¯•åœºæ™¯ 2: ç¾¤ç»„è®°å¿†æŸ¥è¯¢ ==========
        print("\n" + "ğŸ”¬"*40)
        print("æµ‹è¯•åœºæ™¯ 2: ç¾¤ç»„è®°å¿†æŸ¥è¯¢ï¼ˆæœ‰ group_idï¼‰")
        print("ğŸ”¬"*40)
        
        result2 = await tester.test_agentic(
            query="åŒ—äº¬ç¾é£Ÿå’Œæ—…æ¸¸æ¨è",
            user_id="robot_001",
            group_id="chat_user_001_assistant",
            top_k=15,
            time_range_days=365,
            llm_config=llm_config,
            test_name="åœºæ™¯2_ç¾¤ç»„è®°å¿†",
        )
        tester.test_results.append(result2)
        await asyncio.sleep(1)
        
        # ========== æµ‹è¯•åœºæ™¯ 3: å¤šç»´åº¦æ·±æŒ– ==========
        print("\n" + "ğŸ”¬"*40)
        print("æµ‹è¯•åœºæ™¯ 3: å¤šç»´åº¦æ·±æŒ–ï¼ˆå¤æ‚é—®é¢˜ï¼‰")
        print("ğŸ”¬"*40)
        
        result3 = await tester.test_agentic(
            query="ç”¨æˆ·çš„æ€§æ ¼ç‰¹ç‚¹ã€å…´è¶£çˆ±å¥½ã€é¥®é£Ÿåå¥½å’Œæ—…è¡Œä¹ æƒ¯æ˜¯ä»€ä¹ˆï¼Ÿ",
            user_id="robot_001",
            group_id="chat_user_001_assistant",
            top_k=20,
            time_range_days=365,
            llm_config=llm_config,
            test_name="åœºæ™¯3_å¤šç»´åº¦",
        )
        tester.test_results.append(result3)
        await asyncio.sleep(1)
        
        # ========== æµ‹è¯•åœºæ™¯ 4: çŸ­å‘¨æœŸæŸ¥è¯¢ ==========
        print("\n" + "ğŸ”¬"*40)
        print("æµ‹è¯•åœºæ™¯ 4: çŸ­å‘¨æœŸæŸ¥è¯¢ï¼ˆ30å¤©å†…ï¼‰")
        print("ğŸ”¬"*40)
        
        result4 = await tester.test_agentic(
            query="æœ€è¿‘çš„åŒ—äº¬æ—…æ¸¸è®¡åˆ’",
            user_id="robot_001",
            group_id="chat_user_001_assistant",
            top_k=10,
            time_range_days=30,
            llm_config=llm_config,
            test_name="åœºæ™¯4_çŸ­å‘¨æœŸ",
        )
        tester.test_results.append(result4)
        
        # ========== æ‰“å°æ€»ç»“ ==========
        tester.print_summary()
        
        # ========== å¯¼å‡ºç»“æœ ==========
        tester.export_results()
        
        print("\n" + "="*80)
        print("âœ… Agentic æ£€ç´¢æµ‹è¯•å®Œæˆï¼")
        print("="*80)
        
    finally:
        # æ¸…ç† Mock LLM
        if mock_runner:
            await mock_runner.cleanup()
            print("\nâœ… Mock LLM å·²å…³é—­")


if __name__ == "__main__":
    asyncio.run(main())
