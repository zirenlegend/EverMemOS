"""æ¸…ç©ºæ‰€æœ‰è®°å¿†æ•°æ®çš„å·¥å…·å‡½æ•°

å¯ä»¥è¢«å…¶ä»–æµ‹è¯•è„šæœ¬å¯¼å…¥ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ç‹¬ç«‹è¿è¡Œ
"""

import asyncio
import time
from typing import Dict, Any, List

from pymilvus import utility, Collection

from infra_layer.adapters.out.search.milvus.memory.episodic_memory_collection import (
    EpisodicMemoryCollection,
)
from infra_layer.adapters.out.search.milvus.memory.semantic_memory_collection import (
    SemanticMemoryCollection,
)
from infra_layer.adapters.out.search.milvus.memory.event_log_collection import (
    EventLogCollection,
)
from infra_layer.adapters.out.search.elasticsearch.memory.episodic_memory import (
    EpisodicMemoryDoc,
)
from infra_layer.adapters.out.search.elasticsearch.memory.semantic_memory import (
    SemanticMemoryDoc,
)
from infra_layer.adapters.out.search.elasticsearch.memory.event_log import EventLogDoc
from core.di import get_bean_by_type
from component.redis_provider import RedisProvider
from component.mongodb_client_factory import MongoDBClientFactory
from component.elasticsearch_client_factory import ElasticsearchClientFactory


async def _clear_mongodb(verbose: bool = True) -> Dict[str, Any]:
    """åˆ é™¤ MongoDB ä¸­æ‰€æœ‰æ–‡æ¡£ï¼Œä¿ç•™é›†åˆå’Œç´¢å¼•"""
    result: Dict[str, Any] = {
        "database": None,
        "collections": {},
        "deleted": {},
        "errors": [],
    }
    try:
        mongo_factory = get_bean_by_type(MongoDBClientFactory)
        client_wrapper = await mongo_factory.get_default_client()
        db = client_wrapper.database
        db_name = db.name
        result["database"] = db_name

        collection_names = await db.list_collection_names()
        for coll_name in collection_names:
            if coll_name.startswith("system."):
                continue
            collection = db[coll_name]
            count = await collection.count_documents({})
            if count == 0:
                continue
            delete_result = await collection.delete_many({})
            deleted = delete_result.deleted_count if delete_result else 0
            result["collections"][coll_name] = count
            result["deleted"][coll_name] = deleted

        if verbose:
            total_deleted = sum(result["deleted"].values())
            print(
                f"      âœ… MongoDB '{db_name}': åˆ é™¤ {total_deleted} æ¡æ–‡æ¡£ï¼ˆ{len(result['deleted'])} ä¸ªé›†åˆï¼‰"
            )
    except Exception as exc:
        result["errors"].append(str(exc))
        if verbose:
            print(f"      âš ï¸  MongoDB æ¸…ç†å¤±è´¥: {exc}")

    return result


def _get_milvus_row_count(name: str, coll: Collection) -> int:
    """è·å– Milvus å®æ—¶è¡Œæ•°ï¼ˆä¼˜å…ˆ row_countï¼Œå…¶æ¬¡ segmentï¼Œå†å…œåº• num_entitiesï¼‰"""
    get_stats = getattr(utility, "get_collection_stats", None)
    if callable(get_stats):
        stats_info = get_stats(name)
        if isinstance(stats_info, dict):
            try:
                return int(stats_info.get("row_count", 0))
            except (ValueError, TypeError):
                pass

    try:
        segment_infos = utility.get_query_segment_info(name)
        if segment_infos:
            total = 0
            for seg in segment_infos:
                seg_rows = getattr(seg, "num_rows", None)
                if seg_rows is None:
                    seg_rows = getattr(seg, "row_count", 0)
                total += int(seg_rows or 0)
            return total
    except Exception:
        pass

    try:
        return int(coll.num_entities)
    except Exception:
        return 0


def _clear_milvus(
    verbose: bool = True, drop_collections: bool = False
) -> Dict[str, Any]:
    """åˆ é™¤ Milvus é›†åˆä¸­çš„æ‰€æœ‰å‘é‡

    Args:
        verbose: æ˜¯å¦è¾“å‡ºæ—¥å¿—
        drop_collections: æ˜¯å¦ç›´æ¥åˆ é™¤ç‰©ç†é›†åˆå¹¶é‡å»ºï¼ˆå½»åº•æ¸…ç©ºï¼‰
    """
    stats: Dict[str, Any] = {"cleared": [], "errors": []}
    collection_classes = [
        EpisodicMemoryCollection,
        SemanticMemoryCollection,
        EventLogCollection,
    ]
    for cls in collection_classes:
        collection = cls()
        alias = collection.name
        try:
            related_collections: List[str] = []
            all_collections = utility.list_collections(using=collection.using)
            prefix = f"{alias}_"
            for real_name in all_collections:
                if real_name == alias or real_name.startswith(prefix):
                    related_collections.append(real_name)

            if not related_collections:
                continue

            if not drop_collections:
                for real_name in related_collections:
                    coll = Collection(name=real_name, using=collection.using)
                    coll.load()
                    before_count = coll.num_entities
                    if before_count == 0:
                        continue
                    coll.delete(expr="id != ''")
                    coll.flush()

            # åˆ é™¤ aliasï¼Œé˜²æ­¢ drop collection æ—¶æŠ¥é”™
            try:
                utility.drop_alias(alias, using=collection.using)
            except Exception:
                pass

            for real_name in related_collections:
                before_count = 0
                try:
                    coll = Collection(name=real_name, using=collection.using)
                    coll.load()
                    before_count = coll.num_entities
                except Exception:
                    before_count = 0

                utility.drop_collection(real_name, using=collection.using)
                stats["cleared"].append(
                    {"collection": real_name, "deleted": before_count, "dropped": True}
                )
                if verbose:
                    print(
                        f"      âœ… Milvus åˆ é™¤é›†åˆ {real_name}ï¼ˆ{before_count} æ¡å‘é‡ï¼‰"
                    )

            # æ¸…ç©ºç±»çº§åˆ«çš„ collection ç¼“å­˜ï¼Œç¡®ä¿é‡æ–°åˆ›å»ºæ—¶ä¸ä¼šä½¿ç”¨æ—§çš„å®ä¾‹
            cls._collection_instance = None

            # é‡æ–°åˆ›å»ºç©ºé›†åˆå¹¶å…³è” aliasï¼Œé¿å…åç»­ä¾èµ–å¤±è´¥
            try:
                collection.ensure_all()
            except Exception as ensure_exc:
                if verbose:
                    print(f"      âš ï¸  é‡æ–°åˆ›å»º Milvus é›†åˆ {alias} å¤±è´¥: {ensure_exc}")
        except Exception as exc:  # pylint: disable=broad-except
            stats["errors"].append(str(exc))
            if verbose:
                print(f"      âš ï¸  æ— æ³•æ¸…ç©º Milvus é›†åˆ {alias}: {exc}")

    return stats


async def _clear_elasticsearch(
    verbose: bool = True, rebuild_index: bool = False
) -> Dict[str, Any]:
    """åˆ é™¤ä¸è®°å¿†ç›¸å…³çš„ Elasticsearch æ–‡æ¡£ï¼Œå¿…è¦æ—¶é‡å»ºç´¢å¼•"""
    stats: Dict[str, Any] = {"cleared": [], "errors": [], "recreated": False}
    try:
        es_factory = get_bean_by_type(ElasticsearchClientFactory)
        es_client_wrapper = await es_factory.get_default_client()
        es_client = es_client_wrapper.async_client

        alias_names = [
            EpisodicMemoryDoc.get_index_name(),
            SemanticMemoryDoc.get_index_name(),
            EventLogDoc.get_index_name(),
        ]

        if rebuild_index:
            for alias in alias_names:
                try:
                    existing = await es_client.indices.get_alias(
                        name=alias, ignore=[404]
                    )
                    if isinstance(existing, dict):
                        for index_name in existing.keys():
                            await es_client.indices.delete(
                                index=index_name, ignore=[400, 404]
                            )
                            stats["cleared"].append(
                                {"alias": alias, "deleted_index": index_name}
                            )
                            if verbose:
                                print(f"      âœ… åˆ é™¤ç´¢å¼•: {index_name}")
                except Exception as inner_exc:
                    stats["errors"].append(str(inner_exc))
                    if verbose:
                        print(f"      âš ï¸ åˆ é™¤ç´¢å¼•å¤±è´¥ {alias}: {inner_exc}")
            for alias in alias_names:
                await es_client.indices.delete_alias(
                    index="*", name=alias, ignore=[404]
                )
            es_client_wrapper._initialized = False
            await es_client_wrapper.initialize_indices(
                [EpisodicMemoryDoc, SemanticMemoryDoc, EventLogDoc]
            )
            stats["recreated"] = True
            if verbose:
                print("      âœ… Elasticsearch ç´¢å¼•ä¸åˆ«åå·²é‡æ–°åˆ›å»º")
            return stats

        for alias in alias_names:
            try:
                exists = await es_client.indices.exists_alias(name=alias)
                if not exists:
                    continue
                count_resp = await es_client.count(index=alias, query={"match_all": {}})
                total_docs = count_resp.get("count", 0)
                if total_docs == 0:
                    continue
                await es_client.delete_by_query(
                    index=alias,
                    query={"match_all": {}},
                    refresh=True,
                    conflicts="proceed",
                )
                stats["cleared"].append({"alias": alias, "deleted": total_docs})
                if verbose:
                    print(f"      âœ… Elasticsearch {alias}: åˆ é™¤ {total_docs} æ¡æ–‡æ¡£")
            except Exception as inner_exc:  # pylint: disable=broad-except
                stats["errors"].append(str(inner_exc))
                if verbose:
                    print(f"      âš ï¸  æ— æ³•æ¸…ç©º ES {alias}: {inner_exc}")

    except Exception as exc:  # pylint: disable=broad-except
        stats["errors"].append(str(exc))
        if verbose:
            print(f"      âš ï¸  Elasticsearch æ¸…ç†å¤±è´¥: {exc}")

    return stats


async def _clear_redis(verbose: bool = True) -> Dict[str, Any]:
    """æ¸…ç©º Redis å½“å‰æ•°æ®åº“"""
    stats: Dict[str, Any] = {}
    try:
        redis_provider = get_bean_by_type(RedisProvider)
        client = await redis_provider.get_client()
        await client.flushdb()
        stats["flushed_db"] = redis_provider.redis_db
        if verbose:
            print(f"      âœ… Redis DB {redis_provider.redis_db} å·²æ¸…ç©º")
    except Exception as exc:  # pylint: disable=broad-except
        stats["error"] = str(exc)
        if verbose:
            print(f"      âš ï¸  Redis æ¸…ç†å¤±è´¥: {exc}")
    return stats


async def clear_all_memories(
    verbose: bool = True, rebuild_es: bool = False, drop_milvus: bool = False
):
    """æ¸…ç©ºæ‰€æœ‰è®°å¿†æ•°æ®ï¼ˆMongoDBã€Milvusã€Elasticsearchã€Redisï¼‰

    Args:
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        rebuild_es: æ˜¯å¦åˆ é™¤å¹¶é‡å»º Elasticsearch ç´¢å¼• (é»˜è®¤: False)
        drop_milvus: æ˜¯å¦åˆ é™¤å¹¶é‡å»º Milvus ç‰©ç†é›†åˆ (é»˜è®¤: False)
    """
    if verbose:
        print("\nğŸ—‘ï¸  æ¸…ç©ºæ‰€æœ‰è®°å¿†æ•°æ®...")

    try:
        if verbose:
            print("   ğŸ“¦ æ¸…ç©º MongoDB...")
        mongo_stats = await _clear_mongodb(verbose)

        if verbose:
            print("   ğŸ” æ¸…ç©º Milvus...")
        milvus_stats = _clear_milvus(verbose, drop_collections=drop_milvus)

        if verbose:
            print("   ğŸ” æ¸…ç©º Elasticsearch...")
        es_stats = await _clear_elasticsearch(verbose, rebuild_index=rebuild_es)

        if verbose:
            print("   ğŸ’¾ æ¸…ç©º Redis...")
        redis_stats = await _clear_redis(verbose)

        if verbose:
            print("âœ… æ‰€æœ‰è®°å¿†æ•°æ®å·²æ¸…ç©ºï¼\n")
            print("ğŸ“Š ç®€è¦ç»Ÿè®¡ï¼š")
            total_mongo_deleted = sum(mongo_stats.get("deleted", {}).values())
            print(
                f"   - MongoDB åˆ é™¤æ–‡æ¡£: {total_mongo_deleted} æ¡ï¼ˆæ•°æ®åº“: {mongo_stats.get('database')}ï¼‰"
            )
            total_milvus_deleted = sum(
                item["deleted"] for item in milvus_stats.get("cleared", [])
            )
            print(f"   - Milvus åˆ é™¤å‘é‡: {total_milvus_deleted} æ¡")
            if es_stats.get("recreated"):
                print("   - Elasticsearch: ç´¢å¼•ä¸åˆ«åå·²é‡æ–°åˆ›å»º")
            else:
                total_es_deleted = sum(
                    item["deleted"] for item in es_stats.get("cleared", [])
                )
                print(f"   - Elasticsearch åˆ é™¤æ–‡æ¡£: {total_es_deleted} æ¡")
            print(f"   - Redis æ¸…ç©º DB: {redis_stats.get('flushed_db')}")

        return {
            "mongodb": mongo_stats,
            "milvus": milvus_stats,
            "elasticsearch": es_stats,
            "redis": redis_stats,
        }

    except Exception as e:
        print(f"âŒ æ¸…ç©ºæ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
        raise


async def main():
    """ç‹¬ç«‹è¿è¡Œæ—¶çš„å…¥å£å‡½æ•°"""
    print("=" * 100)
    print("ğŸ—‘ï¸  æ¸…ç©ºæ‰€æœ‰è®°å¿†æ•°æ®å·¥å…·")
    print("=" * 100)

    # ç¡®ä¿ bootstrap åˆå§‹åŒ–ï¼Œä»¥ä¾¿ get_bean_by_type èƒ½æ­£å¸¸å·¥ä½œ
    import sys
    import os
    from bootstrap import setup_project_context

    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
    sys.path.append(os.getcwd())

    await setup_project_context()

    result = await clear_all_memories(verbose=True, rebuild_es=False)

    print("\nğŸ“Š æ¸…ç©ºç»Ÿè®¡:")
    mongo_total = sum(result["mongodb"].get("deleted", {}).values())
    print(f"   MongoDB åˆ é™¤æ–‡æ¡£: {mongo_total} æ¡")
    milvus_total = sum(item["deleted"] for item in result["milvus"].get("cleared", []))
    print(f"   Milvus åˆ é™¤å‘é‡: {milvus_total} æ¡")
    if result["elasticsearch"].get("recreated"):
        print("   Elasticsearch: ç´¢å¼•ä¸åˆ«åå·²é‡æ–°åˆ›å»º")
    else:
        es_total = sum(
            item["deleted"] for item in result["elasticsearch"].get("cleared", [])
        )
        print(f"   Elasticsearch åˆ é™¤æ–‡æ¡£: {es_total} æ¡")
    print(f"   Redis æ¸…ç©º DB: {result['redis'].get('flushed_db')}")
    print("=" * 100)


if __name__ == "__main__":
    asyncio.run(main())
