# LoCoMo Dataset Configuration

name: "evermembench"
version: "1.0"
description: "Long-Context Modeling benchmark for conversational memory"

# Data configuration
data:
  path: "evermembench/evermembench.json"  # Fixed format to match PersonaMem
  format: "locomo"  # Native format, no conversion needed

# Evaluation configuration
evaluation:
  type: "hybrid"  # Use hybrid evaluator: Exact Match for multiple-choice, LLM Judge for open-ended
  
  # Exact match settings (for multiple-choice questions)
  case_sensitive: false  # Case insensitive
  normalize_whitespace: true  # Normalize whitespace
  extract_choice: true  # Extract options from the generated answer (like (a), (b))
  
  # LLM Judge settings (for open-ended questions)
  llm:
    provider: "openai"
    model: "gpt-4o-mini"
    api_key: "${LLM_API_KEY}"
    base_url: "${LLM_BASE_URL:https://openrouter.ai/api/v1}"
  
  num_runs: 3  # Number of judging runs per question (for LLM Judge)
  
  # Filter settings
  # Categories: "1", "2", "3", "3.1", "3.2" (multiple types)
  filter_category: []  # Can use integers or strings, like [3.2] or ["3.2"]

