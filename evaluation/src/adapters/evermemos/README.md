# LoCoMo Evaluation Pipeline

<p align="center">
  <a href="README.md">English</a> | <a href="README_zh.md">ç®€ä½“ä¸­æ–‡</a>
</p>

LoCoMo (Long-Context Modeling) evaluation system for testing memory system performance in long conversation scenarios, including retrieval and question-answering capabilities.

---

## ğŸ“‹ Directory Structure

```
locomo_evaluation/
â”œâ”€â”€ config.py                          # Configuration file
â”œâ”€â”€ data/
â”‚   â””â”€â”€ locomo10.json                  # Test dataset
â”œâ”€â”€ prompts/                           # Prompt templates
â”‚   â”œâ”€â”€ sufficiency_check.txt          # Sufficiency check
â”‚   â”œâ”€â”€ refined_query.txt              # Query refinement
â”‚   â”œâ”€â”€ multi_query_generation.txt     # Multi-query generation
â”‚   â””â”€â”€ answer_prompts.py              # Answer generation
â”œâ”€â”€ stage1_memcells_extraction.py      # Stage 1: Extract MemCells
â”œâ”€â”€ stage2_index_building.py           # Stage 2: Build indexes
â”œâ”€â”€ stage3_memory_retrivel.py          # Stage 3: Retrieve memories
â”œâ”€â”€ stage4_response.py                 # Stage 4: Generate responses
â”œâ”€â”€ stage5_eval.py                     # Stage 5: Evaluate results
â””â”€â”€ tools/                             # Utility tools
    â”œâ”€â”€ agentic_utils.py               # Agentic retrieval utilities
    â”œâ”€â”€ benchmark_embedding.py         # Embedding performance testing
    â””â”€â”€ ...
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

Ensure the `.env` file in the project root directory is configured:

```bash
# Required environment variables
LLM_API_KEY=your_llm_api_key           # LLM API key
DEEPINFRA_API_KEY=your_deepinfra_key   # Embedding/Reranker API key
```

### 2. Modify Configuration

Edit `config.py`:

```python
class ExperimentConfig:
    experiment_name: str = "locomo_evaluation"  # Experiment name
    retrieval_mode: str = "lightweight"         # 'agentic' or 'lightweight'
    # ... other configurations
```

**Key Configuration Options**:
- **Concurrency**: Set concurrent requests based on API limits
- **Embedding Parameters**: Choose appropriate embedding model and parameters
- **Reranker Parameters**: Configure reranker model (only for agentic mode)
- **Retrieval Mode**:
  - `agentic`: Complex multi-round retrieval, high quality but slower
  - `lightweight`: Fast hybrid retrieval, faster but slightly lower quality

### 3. Run Complete Pipeline

```bash
# Stage 1: Extract MemCells
python evaluation/locomo_evaluation/stage1_memcells_extraction.py

# Stage 2: Build indexes
python evaluation/locomo_evaluation/stage2_index_building.py

# Stage 3: Retrieve memories
python evaluation/locomo_evaluation/stage3_memory_retrivel.py

# Stage 4: Generate responses
python evaluation/locomo_evaluation/stage4_response.py

# Stage 5: Evaluate results
python evaluation/locomo_evaluation/stage5_eval.py
```

### 4. View Results

```bash
# View final evaluation results
cat results/locomo_evaluation/judged.json

# View accuracy statistics
python evaluation/locomo_evaluation/tools/compute_acc.py
```

---

## ğŸ“Š Results Overview

### Output Directory Structure

```
results/locomo_evaluation/
â”œâ”€â”€ memcells/                  # MemCell extraction results
â”‚   â”œâ”€â”€ memcell_list_conv_0.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ bm25_index/                # BM25 indexes
â”‚   â””â”€â”€ *.pkl
â”œâ”€â”€ vectors/                   # Embedding indexes
â”‚   â””â”€â”€ *.pkl
â”œâ”€â”€ search_results.json        # Retrieval results
â”œâ”€â”€ responses.json             # Generated responses
â””â”€â”€ judged.json                # Final evaluation results
```

---

## âš™ï¸ Configuration Guide

### Switch Retrieval Mode

Modify in `config.py`:

```python
# Lightweight retrieval (fast)
retrieval_mode: str = "lightweight"

# Agentic retrieval (high quality)
retrieval_mode: str = "agentic"
```

### Switch LLM Service

Modify `config.py`:

```python
llm_service: str = "openai"  # or "openrouter", "deepseek"

llm_config: dict = {
    "openai": {
        "model": "openai/gpt-4o-mini",
        "api_key": os.getenv("LLM_API_KEY"),
        "base_url": "https://openrouter.ai/api/v1",
        "temperature": 0.3,
        "max_tokens": 16384,
    }
}
```

---

## ğŸ”— Related Documentation

- [Project Root README](../../README.md)
- [Development Guide](../../docs/dev_docs/getting_started.md)
- [API Documentation](../../docs/api_docs/)
