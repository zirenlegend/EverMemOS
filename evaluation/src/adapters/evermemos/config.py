import os
from dotenv import load_dotenv

load_dotenv()


class ExperimentConfig:
    experiment_name: str = "locomo_evaluation"
    datase_path: str = "data/locomo10.json"
    use_emb: bool = True
    use_reranker: bool = True  # å¯ç”¨ Reranker
    use_agentic_retrieval: bool = True
    use_multi_query: bool = True  #  å¯ç”¨å¤šæŸ¥è¯¢ç”Ÿæˆ
    num_conv: int = 10
    
    # ğŸ”¥ æ–°å¢ï¼šMemCell æå–åŠŸèƒ½å¼€å…³
    enable_semantic_extraction: bool = False  # æ˜¯å¦å¯ç”¨è¯­ä¹‰è®°å¿†æå–
    enable_clustering: bool = True            # æ˜¯å¦å¯ç”¨èšç±»
    enable_profile_extraction: bool = False    # æ˜¯å¦å¯ç”¨ Profile æå–
    
    # ğŸ”¥ èšç±»é…ç½®
    cluster_similarity_threshold: float = 0.65  # èšç±»ç›¸ä¼¼åº¦é˜ˆå€¼
    cluster_max_time_gap_days: float = 7.0     # èšç±»æœ€å¤§æ—¶é—´é—´éš”ï¼ˆå¤©ï¼‰
    
    # ğŸ”¥ Profile é…ç½®
    profile_scenario: str = "assistant"       # Profile åœºæ™¯ï¼šgroup_chat æˆ– assistant
    profile_min_confidence: float = 0.6        # Profile ä»·å€¼åˆ¤åˆ«é˜ˆå€¼
    profile_min_memcells: int = 1              # Profile æå–æœ€å° MemCells æ•°é‡
    
    # ğŸ”¥ æ£€ç´¢æ¨¡å¼é€‰æ‹©ï¼š'agentic' æˆ– 'lightweight'
    # - agentic: å¤æ‚çš„å¤šè½®æ£€ç´¢ï¼ŒLLMå¼•å¯¼ï¼Œè´¨é‡é«˜ä½†é€Ÿåº¦æ…¢
    # - lightweight: å¿«é€Ÿæ··åˆæ£€ç´¢ï¼ŒBM25+Embeddingæ··æ’ï¼Œé€Ÿåº¦å¿«ä½†è´¨é‡ç•¥ä½
    retrieval_mode: str = "agentic"  # 'agentic' | 'lightweight'
    
    #  æ£€ç´¢é…ç½®
    use_hybrid_search: bool = True  # æ˜¯å¦ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆEmbedding + BM25 + RRFï¼‰
    emb_recall_top_n: int = 40      # Embedding/æ··åˆæ£€ç´¢å¬å›æ•°é‡
    reranker_top_n: int = 20        # Reranker é‡æ’åºè¿”å›æ•°é‡
    
    # è½»é‡çº§æ£€ç´¢å‚æ•°ï¼ˆä»…åœ¨ retrieval_mode='lightweight' æ—¶ç”Ÿæ•ˆï¼‰
    lightweight_bm25_top_n: int = 50   # BM25 å¬å›æ•°é‡
    lightweight_emb_top_n: int = 50    # Embedding å¬å›æ•°é‡
    lightweight_final_top_n: int = 20  # æ··æ’åæœ€ç»ˆè¿”å›æ•°é‡
    
    # æ··åˆæ£€ç´¢å‚æ•°ï¼ˆä»…åœ¨ use_hybrid_search=True æ—¶ç”Ÿæ•ˆï¼‰
    hybrid_emb_candidates: int = 50   # Embedding å€™é€‰æ•°é‡
    hybrid_bm25_candidates: int = 50  # BM25 å€™é€‰æ•°é‡
    hybrid_rrf_k: int = 40             # RRF å‚æ•° k
    
    #  å¤šæŸ¥è¯¢æ£€ç´¢å‚æ•°ï¼ˆä»…åœ¨ use_multi_query=True æ—¶ç”Ÿæ•ˆï¼‰
    multi_query_num: int = 3           # æœŸæœ›ç”Ÿæˆçš„æŸ¥è¯¢æ•°é‡
    multi_query_top_n: int = 50        # æ¯ä¸ªæŸ¥è¯¢å¬å›çš„æ–‡æ¡£æ•°
    
    # Reranker ä¼˜åŒ–å‚æ•°ï¼ˆé«˜æ€§èƒ½é…ç½®ï¼‰
    reranker_batch_size: int = 20      # Reranker æ‰¹æ¬¡å¤§å°
    reranker_max_retries: int = 3      # æ¯ä¸ªæ‰¹æ¬¡çš„æœ€å¤§é‡è¯•æ¬¡æ•°
    reranker_retry_delay: float = 0.8  # é‡è¯•é—´éš”ï¼ŒæŒ‡æ•°é€€é¿
    reranker_timeout: float = 60.0     # å•ä¸ªæ‰¹æ¬¡è¶…æ—¶æ—¶é—´
    reranker_fallback_threshold: float = 0.3  # æˆåŠŸç‡ä½äºæ­¤å€¼æ—¶é™çº§åˆ°åŸå§‹æ’åº
    reranker_concurrent_batches: int = 5  #  å¢åŠ å¹¶å‘ï¼š5 ä¸ªæ‰¹æ¬¡å¹¶å‘
    
    reranker_instruction: str = (
    "Determine if the passage contains specific facts, entities (names, dates, locations), "
    "or details that directly answer the question.")
    
    llm_service: str = "openai"  # openai, vllm
    llm_config: dict = {
        "openai": {
            "llm_provider": "openai",
            "model": "openai/gpt-4.1-mini",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("LLM_API_KEY"),
            "temperature": 0.3,
            "max_tokens": 32768,
        },
        "vllm": {
            "llm_provider": "openai",
            "model": "Qwen3-30B",
            "base_url": "http://0.0.0.0:8000/v1",
            "api_key": "123",
            "temperature": 0,
            "max_tokens": 32768,
        },
    }
    max_retries: int = 5
    max_concurrent_requests: int = 10