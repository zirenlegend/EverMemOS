#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• ConversationStatusRawRepository çš„åŠŸèƒ½

æµ‹è¯•å†…å®¹åŒ…æ‹¬:
1. åŸºäºgroup_idçš„æŸ¥è¯¢å’Œæ›´æ–°æ“ä½œ
2. ç»Ÿè®¡æ–¹æ³•
"""

import asyncio
from datetime import datetime
from zoneinfo import ZoneInfo

from core.di import get_bean_by_type
from common_utils.datetime_utils import get_now_with_timezone, to_iso_format
from infra_layer.adapters.out.persistence.repository.conversation_status_raw_repository import (
    ConversationStatusRawRepository,
)
from core.observation.logger import get_logger

logger = get_logger(__name__)


def compare_datetime(dt1: datetime, dt2: datetime) -> bool:
    """æ¯”è¾ƒä¸¤ä¸ªdatetimeå¯¹è±¡ï¼Œåªæ¯”è¾ƒåˆ°ç§’çº§ç²¾åº¦"""
    return dt1.replace(microsecond=0) == dt2.replace(microsecond=0)


async def test_group_operations():
    """æµ‹è¯•ç¾¤ç»„ç›¸å…³æ“ä½œ"""
    logger.info("å¼€å§‹æµ‹è¯•ç¾¤ç»„ç›¸å…³æ“ä½œ...")

    repo = get_bean_by_type(ConversationStatusRawRepository)
    group_id = "test_group_001"
    current_time = get_now_with_timezone()

    try:
        # æµ‹è¯• upsert (åˆ›å»ºæ–°è®°å½•)
        update_data = {
            "old_msg_start_time": current_time,
            "new_msg_start_time": current_time,
            "last_memcell_time": current_time,
        }

        result = await repo.upsert_by_group_id(group_id, update_data)
        assert result is not None
        assert result.group_id == group_id
        logger.info("âœ… æµ‹è¯•upsertåˆ›å»ºæ–°è®°å½•æˆåŠŸ")

        # æµ‹è¯•æ ¹æ®group_idæŸ¥è¯¢
        queried = await repo.get_by_group_id(group_id)
        assert queried is not None
        assert queried.group_id == group_id
        assert compare_datetime(queried.old_msg_start_time, current_time)
        assert compare_datetime(queried.new_msg_start_time, current_time)
        logger.info("âœ… æµ‹è¯•æ ¹æ®group_idæŸ¥è¯¢æˆåŠŸ")

        # æµ‹è¯• upsert (æ›´æ–°ç°æœ‰è®°å½•)
        new_time = get_now_with_timezone()
        update_data = {"old_msg_start_time": new_time, "new_msg_start_time": new_time}

        updated = await repo.upsert_by_group_id(group_id, update_data)
        assert updated is not None
        assert compare_datetime(updated.old_msg_start_time, new_time)
        assert compare_datetime(updated.new_msg_start_time, new_time)
        assert compare_datetime(
            updated.last_memcell_time, current_time
        )  # æœªæ›´æ–°çš„å­—æ®µåº”ä¿æŒåŸå€¼
        logger.info("âœ… æµ‹è¯•upsertæ›´æ–°ç°æœ‰è®°å½•æˆåŠŸ")

        # å†æ¬¡æŸ¥è¯¢éªŒè¯æ›´æ–°
        queried_again = await repo.get_by_group_id(group_id)
        assert queried_again is not None
        assert compare_datetime(queried_again.old_msg_start_time, new_time)
        assert compare_datetime(queried_again.new_msg_start_time, new_time)
        assert compare_datetime(queried_again.last_memcell_time, current_time)
        logger.info("âœ… éªŒè¯æ›´æ–°ç»“æœæˆåŠŸ")

        # æ¸…ç†æµ‹è¯•æ•°æ®
        await queried_again.delete()
        logger.info("âœ… æ¸…ç†æµ‹è¯•æ•°æ®æˆåŠŸ")

        # éªŒè¯åˆ é™¤
        final_check = await repo.get_by_group_id(group_id)
        assert final_check is None, "è®°å½•åº”è¯¥å·²è¢«åˆ é™¤"
        logger.info("âœ… éªŒè¯åˆ é™¤æˆåŠŸ")

    except Exception as e:
        logger.error("âŒ æµ‹è¯•ç¾¤ç»„ç›¸å…³æ“ä½œå¤±è´¥: %s", e)
        raise

    logger.info("âœ… ç¾¤ç»„ç›¸å…³æ“ä½œæµ‹è¯•å®Œæˆ")


async def test_statistics():
    """æµ‹è¯•ç»Ÿè®¡æ–¹æ³•"""
    logger.info("å¼€å§‹æµ‹è¯•ç»Ÿè®¡æ–¹æ³•...")

    repo = get_bean_by_type(ConversationStatusRawRepository)
    base_group_id = "test_group_stats"
    current_time = get_now_with_timezone()

    try:
        # åˆ›å»ºå¤šæ¡æµ‹è¯•è®°å½•
        test_records = []
        for i in range(3):
            group_id = f"{base_group_id}_{i}"
            result = await repo.upsert_by_group_id(
                group_id=group_id,
                update_data={
                    "old_msg_start_time": current_time,
                    "new_msg_start_time": current_time,
                    "last_memcell_time": current_time,
                },
            )
            test_records.append(result)
        logger.info("âœ… åˆ›å»ºæµ‹è¯•è®°å½•æˆåŠŸ")

        # æµ‹è¯•ç¾¤ç»„è®°å½•è®¡æ•°
        count = await repo.count_by_group_id(
            f"{base_group_id}_0"
        )  # æµ‹è¯•ç¬¬ä¸€ä¸ªç¾¤ç»„çš„è®¡æ•°
        assert count == 1, "åº”è¯¥æœ‰1æ¡è®°å½•ï¼Œå®é™…æœ‰%dæ¡" % count
        logger.info("âœ… æµ‹è¯•ç¾¤ç»„è®°å½•è®¡æ•°æˆåŠŸ")

        # æµ‹è¯•æ€»è®°å½•è®¡æ•°
        total = await repo.count_all()
        assert total >= 3, "æ€»è®°å½•æ•°åº”è¯¥è‡³å°‘ä¸º3ï¼Œå®é™…ä¸º%d" % total
        logger.info("âœ… æµ‹è¯•æ€»è®°å½•è®¡æ•°æˆåŠŸ")

        # æ¸…ç†æµ‹è¯•æ•°æ®
        for record in test_records:
            await record.delete()
        logger.info("âœ… æ¸…ç†æµ‹è¯•æ•°æ®æˆåŠŸ")

    except Exception as e:
        logger.error("âŒ æµ‹è¯•ç»Ÿè®¡æ–¹æ³•å¤±è´¥: %s", e)
        raise

    logger.info("âœ… ç»Ÿè®¡æ–¹æ³•æµ‹è¯•å®Œæˆ")


async def test_timezone_handling():
    """æµ‹è¯•ä¸åŒæ—¶åŒºçš„datetimeå¤„ç†"""
    logger.info("å¼€å§‹æµ‹è¯•æ—¶åŒºå¤„ç†...")

    repo = get_bean_by_type(ConversationStatusRawRepository)
    group_id = "test_timezone_001"

    try:
        # åˆ›å»ºUTCæ—¶é—´
        utc_time = datetime.now(ZoneInfo("UTC"))
        # åˆ›å»ºä¸œäº¬æ—¶é—´
        tokyo_time = datetime.now(ZoneInfo("Asia/Tokyo"))

        shanghai_time = datetime.now()

        # ä½¿ç”¨ä¸¤ä¸ªä¸åŒæ—¶åŒºçš„æ—¶é—´åˆ›å»ºè®°å½•
        update_data = {
            "old_msg_start_time": utc_time,
            "new_msg_start_time": tokyo_time,
            "last_memcell_time": shanghai_time,  # ä½¿ç”¨é»˜è®¤çš„ä¸Šæµ·æ—¶åŒº
        }

        # è®°å½•åŸå§‹æ—¶é—´çš„ISOæ ¼å¼ï¼Œç”¨äºæ¯”è¾ƒ
        logger.info("åŸå§‹UTCæ—¶é—´: %s", to_iso_format(utc_time))
        logger.info("åŸå§‹ä¸œäº¬æ—¶é—´: %s", to_iso_format(tokyo_time))
        logger.info("åŸå§‹ä¸Šæµ·æ—¶é—´: %s", to_iso_format(shanghai_time))

        # æ’å…¥æ•°æ®åº“
        result = await repo.upsert_by_group_id(group_id, update_data)
        assert result is not None
        logger.info("âœ… æ’å…¥ä¸åŒæ—¶åŒºçš„æ—¶é—´è®°å½•æˆåŠŸ")

        # ä»æ•°æ®åº“è·å–å¹¶éªŒè¯
        queried = await repo.get_by_group_id(group_id)
        assert queried is not None

        # è¾“å‡ºè·å–çš„æ—¶é—´ä¿¡æ¯
        logger.info("ä»æ•°æ®åº“è·å–çš„æ—¶é—´:")
        logger.info(
            "old_msg_start_time (åŸUTC): %s", to_iso_format(queried.old_msg_start_time)
        )
        logger.info(
            "new_msg_start_time (åŸTokyo): %s",
            to_iso_format(queried.new_msg_start_time),
        )
        logger.info(
            "last_memcell_time (åŸShanghai): %s",
            to_iso_format(queried.last_memcell_time),
        )

        # éªŒè¯æ—¶é—´æ˜¯å¦æ­£ç¡®ï¼ˆè½¬æ¢åˆ°åŒä¸€æ—¶åŒºååº”è¯¥ç›¸ç­‰ï¼‰
        assert queried.old_msg_start_time.astimezone(ZoneInfo("UTC")).replace(
            microsecond=0
        ) == utc_time.replace(microsecond=0)
        assert queried.new_msg_start_time.astimezone(ZoneInfo("Asia/Tokyo")).replace(
            microsecond=0
        ) == tokyo_time.replace(microsecond=0)
        assert queried.last_memcell_time.replace(tzinfo=None).replace(
            microsecond=0
        ) == shanghai_time.replace(microsecond=0)
        logger.info("âœ… æ—¶åŒºéªŒè¯æˆåŠŸ")

        # æ¸…ç†æµ‹è¯•æ•°æ®
        # await queried.delete()
        logger.info("âœ… æ¸…ç†æµ‹è¯•æ•°æ®æˆåŠŸ")

    except Exception as e:
        logger.error("âŒ æµ‹è¯•æ—¶åŒºå¤„ç†å¤±è´¥: %s", e)
        raise

    logger.info("âœ… æ—¶åŒºå¤„ç†æµ‹è¯•å®Œæˆ")


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰æµ‹è¯•...")

    try:
        await test_group_operations()
        await test_statistics()
        await test_timezone_handling()
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    except Exception as e:
        logger.error("âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: %s", e)
        raise


if __name__ == "__main__":
    asyncio.run(run_all_tests())
