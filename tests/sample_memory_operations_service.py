from core.di import get_bean_by_type, enable_mock_mode, scan_packages
from infra_layer.adapters.out.persistence.repository.semantic_memory_raw_repository import (
    SemanticMemoryRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.semantic_memory import (
    SemanticMemory,
)
from infra_layer.adapters.out.persistence.repository.episodic_memory_raw_repository import (
    EpisodicMemoryRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.episodic_memory import (
    EpisodicMemory,
)
from infra_layer.adapters.out.persistence.repository.core_memory_raw_repository import (
    CoreMemoryRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.core_memory import CoreMemory
from infra_layer.adapters.out.persistence.repository.entity_raw_repository import (
    EntityRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.entity import Entity
from infra_layer.adapters.out.persistence.repository.relationship_raw_repository import (
    RelationshipRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.relationship import (
    Relationship,
)
from infra_layer.adapters.out.persistence.repository.behavior_history_raw_repository import (
    BehaviorHistoryRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.behavior_history import (
    BehaviorHistory,
)
from infra_layer.adapters.out.persistence.repository.memcell_raw_repository import (
    MemCellRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.memcell import (
    MemCell,
    DataTypeEnum,
    RawData,
    Message,
)
from infra_layer.adapters.out.persistence.repository.conversation_status_raw_repository import (
    ConversationStatusRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.conversation_status import (
    ConversationStatus,
)
from infra_layer.adapters.out.persistence.repository.employee_organization_raw_repository import (
    EmployeeOrganizationRawRepository,
)
from infra_layer.adapters.out.persistence.document.memory.employee_organization import (
    EmployeeOrganization,
)
import uuid
from datetime import datetime
import os
import logging

# é…ç½®logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# å¦‚æœæ²¡æœ‰å¤„ç†å™¨ï¼Œæ·»åŠ ä¸€ä¸ªæ§åˆ¶å°å¤„ç†å™¨
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)


async def test_semantic_memory_operations():
    """
    æµ‹è¯•è¯­ä¹‰è®°å¿†çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ SemanticMemoryRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•è¯­ä¹‰è®°å¿†æ“ä½œ...")

        # è·å–è¯­ä¹‰è®°å¿†ä»“åº“
        repository = get_bean_by_type(SemanticMemoryRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– SemanticMemoryRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_user_id = f"test_user_{uuid.uuid4().hex[:8]}"
        test_subject = "æµ‹è¯•ä¸»é¢˜ï¼šPythonç¼–ç¨‹"
        test_description = "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´ï¼Œé€‚åˆæ•°æ®ç§‘å­¦å’ŒWebå¼€å‘"
        test_links = ["evt_test_001", "raw_data_test_001"]

        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")

        # 1. æµ‹è¯•åˆ›å»ºè¯­ä¹‰è®°å¿†
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºè¯­ä¹‰è®°å¿†...")
        semantic_memory = SemanticMemory(
            user_id=test_user_id,
            subject=test_subject,
            description=test_description,
            link=test_links,
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await semantic_memory.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºè¯­ä¹‰è®°å¿†: {test_subject}")

        # 2. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢...")
        found_memory = await repository.get_by_user_id(test_user_id)
        if found_memory:
            logger.debug(
                f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_memory.subject} - {found_memory.description}"
            )
            logger.debug(f"   æ¥æºé“¾æ¥: {found_memory.link}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°è¯­ä¹‰è®°å¿†")
            return

        # 3. æµ‹è¯•æ›´æ–°æ“ä½œ
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ›´æ–°æ“ä½œ...")
        update_data = {
            "description": "Pythonæ˜¯ä¸€ç§åŠŸèƒ½å¼ºå¤§çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´ä¼˜é›…ï¼Œå¹¿æ³›åº”ç”¨äºæ•°æ®ç§‘å­¦ã€Webå¼€å‘å’Œäººå·¥æ™ºèƒ½é¢†åŸŸ",
            "link": ["evt_test_001", "raw_data_test_001", "evt_test_002"],
        }

        updated_memory = await repository.update_by_user_id(test_user_id, update_data)
        if updated_memory:
            logger.debug(f"âœ… æ›´æ–°æˆåŠŸ: {updated_memory.description}")
            logger.debug(f"   æ›´æ–°åçš„æ¥æºé“¾æ¥: {updated_memory.link}")
        else:
            logger.error("âŒ æ›´æ–°å¤±è´¥")

        # 4. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("4ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # deleted = await repository.delete_by_user_id(test_user_id)
        # if deleted:
        #     logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        # else:
        #     logger.debug("âŒ æ¸…ç†å¤±è´¥")

        logger.debug("ğŸ‰ è¯­ä¹‰è®°å¿†æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ è¯­ä¹‰è®°å¿†æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_episodic_memory_operations():
    """
    æµ‹è¯•æƒ…æ™¯è®°å¿†çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ EpisodicMemoryRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•æƒ…æ™¯è®°å¿†æ“ä½œ...")

        # è·å–æƒ…æ™¯è®°å¿†ä»“åº“
        repository = get_bean_by_type(EpisodicMemoryRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– EpisodicMemoryRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_event_id = f"evt_test_{uuid.uuid4().hex[:8]}"
        test_user_id = f"user_test_{uuid.uuid4().hex[:8]}"
        test_group_id = "group_test"
        test_timestamp = int(datetime.now().timestamp())
        test_participants = ["å¼ ä¸‰", "æå››"]
        test_summary = "æµ‹è¯•è®°å¿†å•å…ƒï¼šé¡¹ç›®è¿›åº¦è®¨è®º"
        test_subject = "é¡¹ç›®ä¼šè®®"
        test_episode = "åœ¨ä¼šè®®å®¤è¿›è¡Œäº†é¡¹ç›®è¿›åº¦è®¨è®ºï¼Œç¡®å®šäº†ä¸‹å‘¨çš„å¼€å‘ä»»åŠ¡åˆ†é…ï¼Œè®¨è®ºäº†æŠ€æœ¯éš¾ç‚¹å’Œè§£å†³æ–¹æ¡ˆ"
        test_type = "Conversation"
        test_keywords = ["é¡¹ç›®", "è¿›åº¦", "ä¼šè®®", "å¼€å‘"]
        test_linked_entities = ["proj_001", "task_123", "user_456"]
        test_extend = {"priority": "high", "location": "ä¼šè®®å®¤A", "duration": 60}

        logger.debug(f"ğŸ“ æµ‹è¯•äº‹ä»¶ID: {test_event_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")

        # 1. æµ‹è¯•åˆ›å»ºæƒ…æ™¯è®°å¿†
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºæƒ…æ™¯è®°å¿†...")
        episodic_memory = EpisodicMemory(
            user_id=test_user_id,
            group_id=test_group_id,
            timestamp=test_timestamp,
            participants=test_participants,
            summary=test_summary,
            subject=test_subject,
            episode=test_episode,
            type=test_type,
            keywords=test_keywords,
            linked_entities=test_linked_entities,
            extend=test_extend,
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await episodic_memory.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºæƒ…æ™¯è®°å¿†: {test_subject}")

        # è·å–ç”Ÿæˆçš„äº‹ä»¶ID
        actual_event_id = str(episodic_memory.id)
        logger.debug(f"ğŸ“ ç”Ÿæˆçš„äº‹ä»¶ID: {actual_event_id}")

        # 2. æµ‹è¯•æ ¹æ®äº‹ä»¶IDå’Œç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®äº‹ä»¶IDå’Œç”¨æˆ·IDæŸ¥è¯¢...")
        found_memory = await repository.get_by_event_id(actual_event_id, test_user_id)
        if found_memory:
            logger.debug(
                f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_memory.subject} - {found_memory.summary}"
            )
            logger.debug(f"   å‚ä¸è€…: {found_memory.participants}")
            logger.debug(f"   æƒ…æ™¯: {found_memory.episode[:50]}...")
            logger.debug(f"   ç±»å‹: {found_memory.type}")
            logger.debug(f"   å…³é”®è¯: {found_memory.keywords}")
            logger.debug(f"   å…³è”å®ä½“: {found_memory.linked_entities}")
            logger.debug(f"   æ‰©å±•å­—æ®µ: {found_memory.extend}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°æƒ…æ™¯è®°å¿†")
            return

        # 3. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢åˆ—è¡¨
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢åˆ—è¡¨...")
        user_memories = await repository.get_by_user_id(test_user_id)
        logger.debug(f"âœ… ç”¨æˆ· {test_user_id} æœ‰ {len(user_memories)} æ¡æƒ…æ™¯è®°å¿†")
        for i, memory in enumerate(user_memories[:3]):  # åªæ˜¾ç¤ºå‰3æ¡
            logger.debug(f"   {i+1}. {memory.subject}: {memory.summary}")

        # 4. æµ‹è¯•è¿½åŠ æ“ä½œ
        logger.debug("4ï¸âƒ£ æµ‹è¯•è¿½åŠ æ“ä½œ...")
        additional_memory = EpisodicMemory(
            user_id=test_user_id,
            group_id=test_group_id,
            timestamp=test_timestamp + 3600,  # 1å°æ—¶å
            participants=["å¼ ä¸‰", "æå››", "ç‹äº”"],  # ä¸åŒçš„å‚ä¸è€…
            summary="è¿½åŠ çš„è®°å¿†å•å…ƒï¼šæŠ€æœ¯æ–¹æ¡ˆè®¨è®º",
            subject="æŠ€æœ¯ä¼šè®®",
            episode="åœ¨ä¼šè®®å®¤è¿›è¡Œäº†æŠ€æœ¯æ–¹æ¡ˆè®¨è®ºï¼Œç¡®å®šäº†æ¶æ„è®¾è®¡æ–¹å‘ï¼Œè®¨è®ºäº†æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å’Œä»£ç è§„èŒƒ",
            type="Conversation",  # ä¿®å¤ï¼šä½¿ç”¨å­—ç¬¦ä¸²è€Œä¸æ˜¯åˆ—è¡¨
            keywords=["æŠ€æœ¯", "æ¶æ„", "æ€§èƒ½", "ä¼˜åŒ–"],
            linked_entities=["proj_002", "tech_001"],
            extend={"priority": "medium", "location": "ä¼šè®®å®¤B", "duration": 45},
        )

        appended_memory = await repository.append_episodic_memory(additional_memory)
        if appended_memory:
            logger.debug(f"âœ… è¿½åŠ æˆåŠŸ: {appended_memory.summary}")
            logger.debug(f"   è¿½åŠ çš„äº‹ä»¶ID: {appended_memory.event_id}")
            logger.debug(f"   è¿½åŠ çš„å‚ä¸è€…: {appended_memory.participants}")
        else:
            logger.error("âŒ è¿½åŠ å¤±è´¥")

        # 5. æµ‹è¯•åˆ›å»ºæ›´å¤šæƒ…æ™¯è®°å¿†
        logger.debug("5ï¸âƒ£ æµ‹è¯•åˆ›å»ºæ›´å¤šæƒ…æ™¯è®°å¿†...")
        for i in range(2):
            additional_memory = EpisodicMemory(
                user_id=test_user_id,
                group_id=test_group_id,
                timestamp=test_timestamp + i * 3600,  # æ¯å°æ—¶ä¸€ä¸ª
                participants=test_participants,
                summary=f"æµ‹è¯•è®°å¿†å•å…ƒ {i+2}ï¼šæŠ€æœ¯è®¨è®º",
                subject=f"æŠ€æœ¯ä¼šè®® {i+2}",
                episode=f"è¿™æ˜¯ç¬¬ {i+2} ä¸ªæµ‹è¯•æƒ…æ™¯è®°å¿†ï¼Œç”¨äºéªŒè¯æ‰¹é‡æŸ¥è¯¢åŠŸèƒ½",
                type="Conversation",  # ä¿®å¤ï¼šä½¿ç”¨å­—ç¬¦ä¸²è€Œä¸æ˜¯åˆ—è¡¨
                keywords=["æŠ€æœ¯", "è®¨è®º", f"æµ‹è¯•{i+2}"],
                linked_entities=[f"entity_{i+2}"],
                extend={"test_id": i + 2, "priority": "medium"},
            )
            await additional_memory.insert()
            logger.debug(f"   âœ… åˆ›å»ºç¬¬ {i+2} ä¸ªæƒ…æ™¯è®°å¿†")

        # 6. æµ‹è¯•æ‰¹é‡æŸ¥è¯¢
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ‰¹é‡æŸ¥è¯¢...")
        all_user_memories = await repository.get_by_user_id(test_user_id)
        logger.debug(
            f"âœ… ç”¨æˆ· {test_user_id} æ€»å…±æœ‰ {len(all_user_memories)} æ¡æƒ…æ™¯è®°å¿†"
        )

        # æŒ‰æ—¶é—´æˆ³æ’åºæ˜¾ç¤º
        sorted_memories = sorted(
            all_user_memories, key=lambda x: x.timestamp, reverse=True
        )
        for i, memory in enumerate(sorted_memories[:5]):  # æ˜¾ç¤ºå‰5æ¡
            logger.debug(
                f"   {i+1}. [{memory.timestamp}] {memory.subject}: {memory.summary}"
            )

        # 7. æµ‹è¯•é™åˆ¶æŸ¥è¯¢
        logger.debug("7ï¸âƒ£ æµ‹è¯•é™åˆ¶æŸ¥è¯¢...")
        limited_memories = await repository.get_by_user_id(test_user_id, limit=2)
        logger.debug(f"âœ… é™åˆ¶æŸ¥è¯¢è¿”å› {len(limited_memories)} æ¡è®°å½•")

        # # 8. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("8ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # # åˆ é™¤æ‰€æœ‰æµ‹è¯•æ•°æ®
        # deleted_count = await repository.delete_by_user_id(test_user_id)
        # logger.debug(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} æ¡æµ‹è¯•æ•°æ®")

        # # éªŒè¯æ¸…ç†ç»“æœ
        # remaining_memories = await repository.get_by_user_id(test_user_id)
        # logger.debug(f"âœ… éªŒè¯æ¸…ç†ç»“æœï¼šå‰©ä½™ {len(remaining_memories)} æ¡è®°å½•")

        logger.debug("ğŸ‰ æƒ…æ™¯è®°å¿†æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ æƒ…æ™¯è®°å¿†æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_core_memory_operations():
    """
    æµ‹è¯•æ ¸å¿ƒè®°å¿†çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ CoreMemoryRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•æ ¸å¿ƒè®°å¿†æ“ä½œ...")

        # è·å–æ ¸å¿ƒè®°å¿†ä»“åº“
        repository = get_bean_by_type(CoreMemoryRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– CoreMemoryRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_user_id = f"user_core_{uuid.uuid4().hex[:8]}"

        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")

        # 1. æµ‹è¯•åˆ›å»ºæ ¸å¿ƒè®°å¿†ï¼ˆåŒ…å«æ‰€æœ‰ä¸‰ç§ç±»å‹çš„æ•°æ®ï¼‰
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºæ ¸å¿ƒè®°å¿†...")
        core_memory = CoreMemory(
            user_id=test_user_id,
            # åŸºç¡€ä¿¡æ¯å­—æ®µ
            user_name="å¼ ä¸‰",
            gender="ç”·",
            position="é«˜çº§å·¥ç¨‹å¸ˆ",
            supervisor_user_id="supervisor_001",
            team_members=["user_002", "user_003"],
            okr=[
                {"objective": "æå‡ç³»ç»Ÿæ€§èƒ½", "key_result": "å“åº”æ—¶é—´å‡å°‘50%"},
                {"objective": "å›¢é˜Ÿåä½œ", "key_result": "å®Œæˆ3ä¸ªé‡è¦é¡¹ç›®"},
            ],
            base_location="åŒ—äº¬",
            hiredate="2022-01-15",
            age=30,
            department="æŠ€æœ¯éƒ¨",
            # ä¸ªäººæ¡£æ¡ˆå­—æ®µ
            personality=["å†…å‘ä½†å–„äºæ²Ÿé€š", "å–œæ¬¢æ·±åº¦æ€è€ƒ", "æ³¨é‡ç»†èŠ‚"],
            hard_skills={"Python": "é«˜çº§", "SQL": "ä¸“å®¶", "äº§å“è®¾è®¡": "ä¸­çº§"},
            soft_skills={
                "æ²Ÿé€šèƒ½åŠ›": "æ¸…æ™°è¡¨è¾¾æƒ³æ³•ï¼Œæœ‰æ•ˆå€¾å¬ä»–äººæ„è§",
                "å›¢é˜Ÿåˆä½œ": "ä¸ä»–äººåä½œå®ç°å…±åŒç›®æ ‡ï¼Œå¢å¼ºå›¢é˜Ÿå‡èšåŠ›",
            },
            projects_participated=[
                {
                    "project_id": "PROJ_A",
                    "project_name": "ç”µå•†å¹³å°é‡æ„",
                    "role": "æŠ€æœ¯è´Ÿè´£äºº",
                    "è´¡çŒ®": "è´Ÿè´£æ•´ä½“æ¶æ„è®¾è®¡å’ŒæŠ€æœ¯é€‰å‹",
                    "è¿›å…¥é¡¹ç›®æ—¥æœŸ": "2023-01-01",
                }
            ],
            # ä¸ªäººåå¥½å­—æ®µ
            working_habit_preference=["è¿œç¨‹å·¥ä½œ", "å¼¹æ€§æ—¶é—´", "æŠ€æœ¯æŒ‘æˆ˜"],
            interests=["ç¼–ç¨‹", "é˜…è¯»", "è¿åŠ¨"],
            tendency=["æŠ€æœ¯å¯¼å‘", "è´¨é‡ä¼˜å…ˆ", "æŒç»­å­¦ä¹ "],
            user_goal=["æˆä¸ºæŠ€æœ¯ä¸“å®¶", "æå‡é¢†å¯¼åŠ›", "å¼€æºè´¡çŒ®"],
            # é€šç”¨å­—æ®µ
            extend={"priority": "high", "level": "senior", "expertise": "å¾®æœåŠ¡æ¶æ„"},
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await core_memory.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºæ ¸å¿ƒè®°å¿†: {core_memory.user_name}")

        # 2. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢...")
        found_memory = await repository.get_by_user_id(test_user_id)
        if found_memory:
            logger.debug(
                f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_memory.user_name} - {found_memory.position}"
            )
            logger.debug(f"   éƒ¨é—¨: {found_memory.department}")
            logger.debug(f"   æ€§æ ¼: {found_memory.personality}")
            logger.debug(f"   ç¡¬æŠ€èƒ½æ•°é‡: {len(found_memory.hard_skills or {})}")
            logger.debug(f"   å·¥ä½œåå¥½: {found_memory.working_habit_preference}")
            logger.debug(f"   ä¸ªäººç›®æ ‡: {found_memory.user_goal}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°æ ¸å¿ƒè®°å¿†")
            return

        # 3. æµ‹è¯•å­—æ®µæå–æ–¹æ³•
        logger.debug("3ï¸âƒ£ æµ‹è¯•å­—æ®µæå–æ–¹æ³•...")
        base_info = repository.get_base(found_memory)
        profile_info = repository.get_profile(found_memory)

        logger.debug(
            f"âœ… åŸºç¡€ä¿¡æ¯æå–: {base_info['user_name']} - {base_info['position']}"
        )
        logger.debug(f"âœ… ä¸ªäººæ¡£æ¡ˆæå–: {profile_info['personality']}")
        logger.debug(f"âœ… ä¸ªäººåå¥½æå–: {profile_info['working_habit_preference']}")

        # 4. æµ‹è¯•åˆ†ç±»æ›´æ–°æ–¹æ³•
        logger.debug("4ï¸âƒ£ æµ‹è¯•åˆ†ç±»æ›´æ–°æ–¹æ³•...")

        # æ›´æ–°åŸºç¡€ä¿¡æ¯
        base_update_data = {
            "user_name": "å¼ ä¸‰ï¼ˆæ›´æ–°ï¼‰",
            "position": "æŠ€æœ¯ä¸“å®¶",
            "age": 31,
            "department": "æŠ€æœ¯éƒ¨",
        }
        updated_memory = await repository.update_base(test_user_id, base_update_data)
        if updated_memory:
            logger.debug(
                f"âœ… åŸºç¡€ä¿¡æ¯æ›´æ–°æˆåŠŸ: {updated_memory.user_name} - {updated_memory.position}"
            )

        # æ›´æ–°ä¸ªäººæ¡£æ¡ˆ
        profile_update_data = {
            "personality": ["å¤–å‘ä¸”å–„äºæ²Ÿé€š", "å–œæ¬¢å›¢é˜Ÿåä½œ"],
            "hard_skills": {"Python": "ä¸“å®¶", "Go": "é«˜çº§", "Kubernetes": "ä¸­çº§"},
        }
        updated_memory = await repository.update_profile(
            test_user_id, profile_update_data
        )
        if updated_memory:
            logger.debug(f"âœ… ä¸ªäººæ¡£æ¡ˆæ›´æ–°æˆåŠŸ: {updated_memory.personality}")
            logger.debug(
                f"   æ›´æ–°åçš„ç¡¬æŠ€èƒ½: {len(updated_memory.hard_skills or {})} é¡¹"
            )

        # æ›´æ–°ä¸ªäººåå¥½
        preference_update_data = {
            "working_habit_preference": [
                "è¿œç¨‹å·¥ä½œ",
                "å¼¹æ€§æ—¶é—´",
                "æŠ€æœ¯æŒ‘æˆ˜",
                "åˆ›æ–°é¡¹ç›®",
            ],
            "user_goal": ["æˆä¸ºæŠ€æœ¯ä¸“å®¶", "æå‡é¢†å¯¼åŠ›", "å¼€æºè´¡çŒ®", "æŠ€æœ¯åˆ†äº«"],
        }
        updated_memory = await repository.update_profile(
            test_user_id, preference_update_data
        )
        if updated_memory:
            logger.debug(
                f"âœ… ä¸ªäººåå¥½æ›´æ–°æˆåŠŸ: {updated_memory.working_habit_preference}"
            )
            logger.debug(f"   æ›´æ–°åçš„ç›®æ ‡: {updated_memory.user_goal}")

        # 6. æµ‹è¯•æ··åˆæ•°æ®æ›´æ–°ï¼ˆéªŒè¯å­—æ®µè¿‡æ»¤ï¼‰
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ··åˆæ•°æ®æ›´æ–°...")
        mixed_data = {
            "user_name": "å¼ ä¸‰ï¼ˆæ··åˆæ›´æ–°ï¼‰",  # åŸºç¡€ä¿¡æ¯å­—æ®µ
            "personality": ["æ··åˆæ›´æ–°åçš„æ€§æ ¼"],  # ä¸ªäººæ¡£æ¡ˆå­—æ®µ
            "working_habit_preference": ["æ··åˆæ›´æ–°åå¥½"],  # ä¸ªäººåå¥½å­—æ®µ
            "invalid_field": "æ— æ•ˆå­—æ®µ",  # æ— æ•ˆå­—æ®µ
        }

        # ä½¿ç”¨ update_base åªä¼šæ›´æ–°åŸºç¡€ä¿¡æ¯å­—æ®µ
        updated_memory = await repository.update_base(test_user_id, mixed_data)
        if updated_memory:
            logger.debug(
                f"âœ… æ··åˆæ•°æ®æ›´æ–°æˆåŠŸï¼ˆåªæ›´æ–°åŸºç¡€ä¿¡æ¯ï¼‰: {updated_memory.user_name}"
            )
            logger.debug(f"   æ€§æ ¼æœªå˜: {updated_memory.personality}")
            logger.debug(f"   åå¥½æœªå˜: {updated_memory.working_habit_preference}")

        # # 7. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("7ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # deleted = await repository.delete_by_user_id(test_user_id)
        # if deleted:
        #     logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        # else:
        #     logger.debug("âŒ æ¸…ç†å¤±è´¥")

        # # éªŒè¯æ¸…ç†ç»“æœ
        # remaining_memory = await repository.get_by_user_id(test_user_id)
        # if remaining_memory is None:
        #     logger.debug("âœ… éªŒè¯æ¸…ç†ç»“æœï¼šæ•°æ®å·²å®Œå…¨åˆ é™¤")
        # else:
        #     logger.debug("âŒ éªŒè¯æ¸…ç†ç»“æœï¼šæ•°æ®æœªå®Œå…¨åˆ é™¤")

        logger.debug("ğŸ‰ æ ¸å¿ƒè®°å¿†æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ æ ¸å¿ƒè®°å¿†æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_entity_operations():
    """
    æµ‹è¯•å®ä½“åº“çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ EntityRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•å®ä½“åº“æ“ä½œ...")

        # è·å–å®ä½“åº“ä»“åº“
        repository = get_bean_by_type(EntityRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– EntityRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_entity_id = f"entity_test_{uuid.uuid4().hex[:8]}"

        logger.debug(f"ğŸ“ æµ‹è¯•å®ä½“ID: {test_entity_id}")

        # 1. æµ‹è¯•åˆ›å»ºå®ä½“
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºå®ä½“...")
        entity = Entity(
            entity_id=test_entity_id,
            name="æµ‹è¯•ç”¨æˆ·",
            type="Person",
            aliases=["æµ‹è¯•", "test_user", "ç”¨æˆ·æµ‹è¯•"],
            extend={"department": "æµ‹è¯•éƒ¨", "level": "æµ‹è¯•å·¥ç¨‹å¸ˆ"},
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await entity.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºå®ä½“: {entity.name}")

        # 2. æµ‹è¯•æ ¹æ®å®ä½“IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®å®ä½“IDæŸ¥è¯¢...")
        found_entity = await repository.get_by_entity_id(test_entity_id)
        if found_entity:
            logger.debug(f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_entity.name} - {found_entity.type}")
            logger.debug(f"   åˆ«å: {found_entity.aliases}")
            logger.debug(f"   æ‰©å±•ä¿¡æ¯: {found_entity.extend}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°å®ä½“")
            return

        # 5. æµ‹è¯•æ ¹æ®åˆ«åæŸ¥è¯¢
        logger.debug("5ï¸âƒ£ æµ‹è¯•æ ¹æ®åˆ«åæŸ¥è¯¢...")
        alias_entities = await repository.get_by_alias("æµ‹è¯•")
        logger.debug(f"âœ… æ ¹æ®åˆ«åæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(alias_entities)} ä¸ªå®ä½“")

        # 6. æµ‹è¯•æ›´æ–°æ“ä½œ
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ›´æ–°æ“ä½œ...")
        update_data = {
            "name": "æµ‹è¯•ç”¨æˆ·ï¼ˆæ›´æ–°ï¼‰",
            "aliases": ["æµ‹è¯•", "test_user", "ç”¨æˆ·æµ‹è¯•", "æ›´æ–°æµ‹è¯•"],
            "extend": {
                "department": "æµ‹è¯•éƒ¨",
                "level": "é«˜çº§æµ‹è¯•å·¥ç¨‹å¸ˆ",
                "updated": True,
            },
        }

        updated_entity = await repository.update_by_entity_id(
            test_entity_id, update_data
        )
        if updated_entity:
            logger.debug(f"âœ… æ›´æ–°æˆåŠŸ: {updated_entity.name}")
            logger.debug(f"   æ›´æ–°åçš„åˆ«å: {updated_entity.aliases}")
            logger.debug(f"   æ›´æ–°åçš„æ‰©å±•ä¿¡æ¯: {updated_entity.extend}")
        else:
            logger.error("âŒ æ›´æ–°å¤±è´¥")

        # 8. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        logger.debug("8ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        person_count = await repository.count_by_type("Person")
        total_count = await repository.count_all()
        logger.debug(
            f"âœ… ç»Ÿè®¡æˆåŠŸ: Personç±»å‹ {person_count} ä¸ªï¼Œæ€»è®¡ {total_count} ä¸ªå®ä½“"
        )

        # 9. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("9ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # deleted = await repository.delete_by_entity_id(test_entity_id)
        # if deleted:
        #     logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        # else:
        #     logger.debug("âŒ æ¸…ç†å¤±è´¥")

        logger.debug("ğŸ‰ å®ä½“åº“æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ å®ä½“åº“æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_relationship_operations():
    """
    æµ‹è¯•å…³ç³»åº“çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ RelationshipRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•å…³ç³»åº“æ“ä½œ...")

        # è·å–å…³ç³»åº“ä»“åº“
        repository = get_bean_by_type(RelationshipRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– RelationshipRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_source_id = f"entity_source_{uuid.uuid4().hex[:8]}"
        test_target_id = f"entity_target_{uuid.uuid4().hex[:8]}"

        logger.debug(f"ğŸ“ æµ‹è¯•æºå®ä½“ID: {test_source_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•ç›®æ ‡å®ä½“ID: {test_target_id}")

        # 1. æµ‹è¯•åˆ›å»ºå…³ç³»
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºå…³ç³»...")
        relationship = Relationship(
            source_entity_id=test_source_id,
            target_entity_id=test_target_id,
            relationship=[
                {
                    "type": "äººé™…å…³ç³»",
                    "content": "é¡¹ç›®åä½œ",
                    "detail": "åœ¨æµ‹è¯•é¡¹ç›®ä¸­æœ‰åˆä½œå…³ç³»",
                },
                {"type": "å·¥ä½œå…³ç³»", "content": "åŒäº‹", "detail": "åŒå±ä¸€ä¸ªå›¢é˜Ÿ"},
            ],
            extend={"strength": "medium", "context": "å·¥ä½œç¯å¢ƒ"},
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await relationship.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºå…³ç³»: {test_source_id} -> {test_target_id}")

        # 2. æµ‹è¯•æ ¹æ®å®ä½“IDæŸ¥è¯¢å…³ç³»
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®å®ä½“IDæŸ¥è¯¢å…³ç³»...")
        found_relationship = await repository.get_by_entity_ids(
            test_source_id, test_target_id
        )
        if found_relationship:
            logger.debug(f"âœ… æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ°å…³ç³»")
            logger.debug(
                f"   å…³ç³»ç±»å‹: {[r['type'] for r in found_relationship.relationship]}"
            )
            logger.debug(
                f"   å…³ç³»å†…å®¹: {[r['content'] for r in found_relationship.relationship]}"
            )
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°å…³ç³»")
            return

        # 3. æµ‹è¯•æ ¹æ®æºå®ä½“æŸ¥è¯¢
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®æºå®ä½“æŸ¥è¯¢...")
        source_relationships = await repository.get_by_source_entity(test_source_id)
        logger.debug(f"âœ… æ ¹æ®æºå®ä½“æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(source_relationships)} ä¸ªå…³ç³»")

        # 4. æµ‹è¯•æ ¹æ®ç›®æ ‡å®ä½“æŸ¥è¯¢
        logger.debug("4ï¸âƒ£ æµ‹è¯•æ ¹æ®ç›®æ ‡å®ä½“æŸ¥è¯¢...")
        target_relationships = await repository.get_by_target_entity(test_target_id)
        logger.debug(
            f"âœ… æ ¹æ®ç›®æ ‡å®ä½“æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(target_relationships)} ä¸ªå…³ç³»"
        )

        # 5. æµ‹è¯•æ ¹æ®å…³ç³»ç±»å‹æŸ¥è¯¢ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("5ï¸âƒ£ æµ‹è¯•æ ¹æ®å…³ç³»ç±»å‹æŸ¥è¯¢...")
        logger.debug("âœ… å…³ç³»ç±»å‹æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 6. æµ‹è¯•æ›´æ–°æ“ä½œ
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ›´æ–°æ“ä½œ...")
        update_data = {
            "relationship": [
                {
                    "type": "äººé™…å…³ç³»",
                    "content": "é¡¹ç›®åä½œ",
                    "detail": "åœ¨æµ‹è¯•é¡¹ç›®ä¸­æœ‰æ·±åº¦åˆä½œå…³ç³»",
                },
                {
                    "type": "å·¥ä½œå…³ç³»",
                    "content": "åŒäº‹",
                    "detail": "åŒå±ä¸€ä¸ªå›¢é˜Ÿï¼Œç»å¸¸åä½œ",
                },
                {"type": "æœ‹å‹å…³ç³»", "content": "å¥½å‹", "detail": "å·¥ä½œä¹‹å¤–ä¹Ÿæ˜¯å¥½æœ‹å‹"},
            ],
            "extend": {"strength": "strong", "context": "å·¥ä½œç¯å¢ƒ", "updated": True},
        }

        updated_relationship = await repository.update_by_entity_ids(
            test_source_id, test_target_id, update_data
        )
        if updated_relationship:
            logger.debug(
                f"âœ… æ›´æ–°æˆåŠŸ: å…³ç³»æ•°é‡ {len(updated_relationship.relationship)}"
            )
            logger.debug(
                f"   æ›´æ–°åçš„å…³ç³»ç±»å‹: {[r['type'] for r in updated_relationship.relationship]}"
            )
        else:
            logger.error("âŒ æ›´æ–°å¤±è´¥")

        # 7. æµ‹è¯•æœç´¢åŠŸèƒ½ï¼ˆå·²ç§»é™¤search_by_relationship_contentæ–¹æ³•ï¼‰
        logger.debug("7ï¸âƒ£ æµ‹è¯•æœç´¢åŠŸèƒ½...")
        logger.debug("âœ… æœç´¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 8. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        logger.debug("8ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        source_count = await repository.count_by_entity(test_source_id)
        total_count = await repository.count_all()
        logger.debug(
            f"âœ… ç»Ÿè®¡æˆåŠŸ: æºå®ä½“å…³ç³» {source_count} ä¸ªï¼Œæ€»è®¡ {total_count} ä¸ªå…³ç³»"
        )

        # 9. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("9ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # deleted = await repository.delete_by_entity_ids(test_source_id, test_target_id)
        # if deleted:
        #     logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        # else:
        #     logger.debug("âŒ æ¸…ç†å¤±è´¥")

        logger.debug("ğŸ‰ å…³ç³»åº“æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.debug(f"âŒ å…³ç³»åº“æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_behavior_history_operations():
    """
    æµ‹è¯•è¡Œä¸ºå†å²çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ BehaviorHistoryRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•è¡Œä¸ºå†å²æ“ä½œ...")

        # è·å–è¡Œä¸ºå†å²ä»“åº“
        repository = get_bean_by_type(BehaviorHistoryRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– BehaviorHistoryRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_user_id = f"user_behavior_{uuid.uuid4().hex[:8]}"
        test_timestamp = int(datetime.now().timestamp())

        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•æ—¶é—´æˆ³: {test_timestamp}")

        # 1. æµ‹è¯•åˆ›å»ºè¡Œä¸ºå†å²
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºè¡Œä¸ºå†å²...")
        behavior_history = BehaviorHistory(
            user_id=test_user_id,
            timestamp=test_timestamp,
            behavior_type=["chat", "follow-up"],
            event_id="evt_test_001",
            meta={
                "conversation_id": "conv_test_001",
                "message_count": 3,
                "duration_minutes": 10,
                "topics": ["æŠ€æœ¯è®¨è®º", "æµ‹è¯•"],
            },
            extend={"priority": "high", "location": "office"},
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await behavior_history.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºè¡Œä¸ºå†å²: {behavior_history.behavior_type}")

        # 2. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDå’Œæ—¶é—´æˆ³æŸ¥è¯¢ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDå’Œæ—¶é—´æˆ³æŸ¥è¯¢...")
        logger.debug("âœ… æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 3. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢åˆ—è¡¨
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢åˆ—è¡¨...")
        user_behaviors = await repository.get_by_user_id(test_user_id, limit=5)
        logger.debug(f"âœ… æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(user_behaviors)} ä¸ªè¡Œä¸ºå†å²")

        # 4. æµ‹è¯•æ ¹æ®è¡Œä¸ºç±»å‹æŸ¥è¯¢ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("4ï¸âƒ£ æµ‹è¯•æ ¹æ®è¡Œä¸ºç±»å‹æŸ¥è¯¢...")
        logger.debug("âœ… è¡Œä¸ºç±»å‹æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 5. æµ‹è¯•æ ¹æ®äº‹ä»¶IDæŸ¥è¯¢ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("5ï¸âƒ£ æµ‹è¯•æ ¹æ®äº‹ä»¶IDæŸ¥è¯¢...")
        logger.debug("âœ… äº‹ä»¶IDæŸ¥è¯¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 6. æµ‹è¯•æ ¹æ®æ—¶é—´èŒƒå›´æŸ¥è¯¢
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ ¹æ®æ—¶é—´èŒƒå›´æŸ¥è¯¢...")
        start_time = test_timestamp - 3600  # 1å°æ—¶å‰
        end_time = test_timestamp + 3600  # 1å°æ—¶å
        time_range_behaviors = await repository.get_by_time_range(
            start_time, end_time, test_user_id
        )
        logger.debug(
            f"âœ… æ ¹æ®æ—¶é—´èŒƒå›´æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(time_range_behaviors)} ä¸ªè¡Œä¸ºå†å²"
        )

        # 7. æµ‹è¯•è¿½åŠ æ“ä½œ
        logger.debug("7ï¸âƒ£ æµ‹è¯•è¿½åŠ æ“ä½œ...")
        additional_behavior = BehaviorHistory(
            user_id=test_user_id,
            timestamp=test_timestamp + 1,  # ä¸åŒçš„æ—¶é—´æˆ³
            behavior_type=["Smart-Reply", "Vote"],
            event_id="evt_test_002",
            meta={
                "conversation_id": "conv_test_002",
                "message_count": 2,
                "duration_minutes": 5,
                "topics": ["è¿½åŠ æµ‹è¯•", "æ–°è¡Œä¸º"],
            },
            extend={"priority": "medium", "location": "remote"},
        )

        appended_behavior = await repository.append_behavior(additional_behavior)
        if appended_behavior:
            logger.debug(f"âœ… è¿½åŠ æˆåŠŸ: {appended_behavior.behavior_type}")
            logger.debug(f"   è¿½åŠ çš„è¡Œä¸ºæ—¶é—´æˆ³: {appended_behavior.timestamp}")
        else:
            logger.error("âŒ è¿½åŠ å¤±è´¥")

        # 8. æµ‹è¯•æœç´¢åŠŸèƒ½ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("8ï¸âƒ£ æµ‹è¯•æœç´¢åŠŸèƒ½...")
        logger.debug("âœ… æœç´¢åŠŸèƒ½æµ‹è¯•è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        # 9. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        logger.debug("9ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        user_count = await repository.count_by_user(test_user_id)
        logger.debug(f"âœ… ç»Ÿè®¡æˆåŠŸ: ç”¨æˆ·è¡Œä¸º {user_count} ä¸ª")
        # 10. æ¸…ç†æµ‹è¯•æ•°æ®ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰
        logger.debug("ğŸ”Ÿ æ¸…ç†æµ‹è¯•æ•°æ®...")
        logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†è·³è¿‡ï¼ˆæ–¹æ³•å·²ç§»é™¤ï¼‰")

        logger.debug("ğŸ‰ è¡Œä¸ºå†å²æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.debug(f"âŒ è¡Œä¸ºå†å²æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_memcell_operations():
    """
    æµ‹è¯• MemCell çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ MemCellRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯• MemCell æ“ä½œ...")

        # è·å– MemCell ä»“åº“
        repository = get_bean_by_type(MemCellRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– MemCellRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_event_id = f"evt_memcell_{uuid.uuid4().hex[:8]}"
        test_user_id = f"user_memcell_{uuid.uuid4().hex[:8]}"
        test_group_id = f"group_memcell_{uuid.uuid4().hex[:8]}"
        test_timestamp = datetime.now()

        logger.debug(f"ğŸ“ æµ‹è¯•äº‹ä»¶ID: {test_event_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•ç¾¤ç»„ID: {test_group_id}")

        # 1. æµ‹è¯•åˆ›å»º MemCell
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»º MemCell...")

        # åˆ›å»ºåŸå§‹æ•°æ®
        raw_data = RawData(
            data_type=DataTypeEnum.CONVERSATION,
            messages=[
                Message(
                    content="ä»Šå¤©çš„ä¼šè®®è®¨è®ºäº†æ–°åŠŸèƒ½çš„è®¾è®¡æ–¹æ¡ˆï¼Œå¤§å®¶éƒ½å¾ˆç§¯æ",
                    files=["https://example.com/design_doc.pdf"],
                    extend={
                        "sender": "å¼ ä¸‰",
                        "message_id": "msg_001",
                        "platform": "WeChat",
                    },
                ),
                Message(
                    content="æˆ‘è§‰å¾—è¿™ä¸ªæ–¹æ¡ˆå¾ˆæœ‰å‰æ™¯ï¼Œå¯ä»¥ç»§ç»­æ¨è¿›",
                    extend={
                        "sender": "æå››",
                        "message_id": "msg_002",
                        "platform": "WeChat",
                    },
                ),
            ],
            meta={
                "chat_id": "chat_12345",
                "platform": "WeChat",
                "conversation_type": "group",
            },
        )

        memcell = MemCell(
            user_id=test_user_id,
            group_id=test_group_id,
            timestamp=test_timestamp,
            summary="å›¢é˜Ÿè®¨è®ºæ–°åŠŸèƒ½è®¾è®¡æ–¹æ¡ˆï¼Œè·å¾—ç§¯æåé¦ˆ",
            original_data=[raw_data],
            participants=["å¼ ä¸‰", "æå››", "ç‹äº”"],
            type=DataTypeEnum.CONVERSATION,
            keywords=["æ–°åŠŸèƒ½", "è®¾è®¡æ–¹æ¡ˆ", "ä¼šè®®", "è®¨è®º"],
            linked_entities=["project_001", "feature_002", "user_003"],
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await memcell.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»º MemCell: {memcell.summary}")

        # 2. æµ‹è¯•æ ¹æ®äº‹ä»¶IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®äº‹ä»¶IDæŸ¥è¯¢...")
        actual_event_id = str(memcell.id)
        found_memcell = await repository.get_by_event_id(actual_event_id)
        if found_memcell:
            logger.debug(f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_memcell.summary}")
            logger.debug(f"   ç”¨æˆ·ID: {found_memcell.user_id}")
            logger.debug(f"   ç¾¤ç»„ID: {found_memcell.group_id}")
            logger.debug(f"   å‚ä¸è€…: {found_memcell.participants}")
            logger.debug(f"   å…³é”®è¯: {found_memcell.keywords}")
            logger.debug(f"   åŸå§‹æ•°æ®æ•°é‡: {len(found_memcell.original_data)}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ° MemCell")
            return

        # 3. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢...")
        user_memcells = await repository.find_by_user_id(test_user_id, limit=5)
        logger.debug(f"âœ… æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(user_memcells)} ä¸ª MemCell")
        for i, memcell in enumerate(user_memcells[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            logger.debug(f"   {i+1}. {memcell.summary[:50]}...")

        # 4. æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢
        logger.debug("4ï¸âƒ£ æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢...")
        group_memcells = await repository.find_by_group_id(test_group_id, limit=5)
        logger.debug(f"âœ… æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(group_memcells)} ä¸ª MemCell")

        # 5. æµ‹è¯•æ ¹æ®å‚ä¸è€…æŸ¥è¯¢
        logger.debug("5ï¸âƒ£ æµ‹è¯•æ ¹æ®å‚ä¸è€…æŸ¥è¯¢...")
        participant_memcells = await repository.find_by_participants(
            ["å¼ ä¸‰"], match_all=False, limit=5
        )
        logger.debug(
            f"âœ… æ ¹æ®å‚ä¸è€…æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(participant_memcells)} ä¸ª MemCell"
        )

        # 6. æµ‹è¯•æ ¹æ®å…³é”®è¯æŸ¥è¯¢
        logger.debug("6ï¸âƒ£ æµ‹è¯•æ ¹æ®å…³é”®è¯æŸ¥è¯¢...")
        keyword_memcells = await repository.search_by_keywords(
            ["æ–°åŠŸèƒ½"], match_all=False, limit=5
        )
        logger.debug(f"âœ… æ ¹æ®å…³é”®è¯æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(keyword_memcells)} ä¸ª MemCell")

        # 7. æµ‹è¯•æ—¶é—´èŒƒå›´æŸ¥è¯¢
        logger.debug("7ï¸âƒ£ æµ‹è¯•æ—¶é—´èŒƒå›´æŸ¥è¯¢...")
        start_time = test_timestamp.replace(hour=0, minute=0, second=0, microsecond=0)
        end_time = test_timestamp.replace(
            hour=23, minute=59, second=59, microsecond=999999
        )
        time_range_memcells = await repository.find_by_user_and_time_range(
            test_user_id, start_time, end_time, limit=5
        )
        logger.debug(
            f"âœ… æ ¹æ®æ—¶é—´èŒƒå›´æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(time_range_memcells)} ä¸ª MemCell"
        )

        # 8. æµ‹è¯•æ›´æ–°æ“ä½œ
        logger.debug("8ï¸âƒ£ æµ‹è¯•æ›´æ–°æ“ä½œ...")
        update_data = {
            "summary": "å›¢é˜Ÿè®¨è®ºæ–°åŠŸèƒ½è®¾è®¡æ–¹æ¡ˆï¼Œè·å¾—ç§¯æåé¦ˆï¼ˆå·²æ›´æ–°ï¼‰",
            "keywords": ["æ–°åŠŸèƒ½", "è®¾è®¡æ–¹æ¡ˆ", "ä¼šè®®", "è®¨è®º", "æ›´æ–°"],
            "linked_entities": ["project_001", "feature_002", "user_003", "update_001"],
        }

        updated_memcell = await repository.update_by_event_id(
            actual_event_id, update_data
        )
        if updated_memcell:
            logger.debug(f"âœ… æ›´æ–°æˆåŠŸ: {updated_memcell.summary}")
            logger.debug(f"   æ›´æ–°åçš„å…³é”®è¯: {updated_memcell.keywords}")
            logger.debug(f"   æ›´æ–°åçš„å…³è”å®ä½“: {updated_memcell.linked_entities}")
        else:
            logger.error("âŒ æ›´æ–°å¤±è´¥")

        # 9. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        logger.debug("9ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        user_count = await repository.count_by_user_id(test_user_id)
        time_range_count = await repository.count_by_time_range(
            start_time, end_time, test_user_id
        )
        logger.debug(
            f"âœ… ç»Ÿè®¡æˆåŠŸ: ç”¨æˆ· MemCell {user_count} ä¸ªï¼Œæ—¶é—´èŒƒå›´å†… {time_range_count} ä¸ª"
        )

        # 10. æµ‹è¯•è·å–æœ€æ–°è®°å½•
        logger.debug("ğŸ”Ÿ æµ‹è¯•è·å–æœ€æ–°è®°å½•...")
        latest_memcells = await repository.get_latest_by_user(test_user_id, limit=3)
        logger.debug(f"âœ… è·å–æœ€æ–°è®°å½•æˆåŠŸ: è¿”å› {len(latest_memcells)} ä¸ª MemCell")
        for i, memcell in enumerate(latest_memcells):
            logger.debug(f"   {i+1}. [{memcell.timestamp}] {memcell.summary[:50]}...")

        # 11. æµ‹è¯•ç”¨æˆ·æ´»åŠ¨æ‘˜è¦
        logger.debug("1ï¸âƒ£1ï¸âƒ£ æµ‹è¯•ç”¨æˆ·æ´»åŠ¨æ‘˜è¦...")
        activity_summary = await repository.get_user_activity_summary(
            test_user_id, start_time, end_time
        )
        if activity_summary:
            logger.debug(
                f"âœ… æ´»åŠ¨æ‘˜è¦æˆåŠŸ: æ€»è®¡ {activity_summary.get('total_count', 0)} æ¡è®°å½•"
            )
            logger.debug(
                f"   ç±»å‹åˆ†å¸ƒ: {activity_summary.get('type_distribution', {})}"
            )
            logger.debug(
                f"   æœ€æ–°æ´»åŠ¨: {activity_summary.get('latest_activity', 'N/A')}"
            )
        else:
            logger.debug("âŒ æ´»åŠ¨æ‘˜è¦å¤±è´¥")

        # 12. æµ‹è¯•åˆ›å»ºæ›´å¤š MemCellï¼ˆç”¨äºæ‰¹é‡æµ‹è¯•ï¼‰
        logger.debug("1ï¸âƒ£2ï¸âƒ£ æµ‹è¯•åˆ›å»ºæ›´å¤š MemCell...")
        for i in range(2):
            additional_memcell = MemCell(
                user_id=test_user_id,
                group_id=test_group_id,
                timestamp=datetime.now(),
                summary=f"æµ‹è¯• MemCell {i+2}ï¼šæŠ€æœ¯è®¨è®ºå’Œæ–¹æ¡ˆè¯„å®¡",
                original_data=[
                    RawData(
                        data_type=DataTypeEnum.MEETING,
                        messages=[
                            Message(
                                content=f"ç¬¬ {i+2} ä¸ªæµ‹è¯•ä¼šè®®ï¼Œè®¨è®ºæŠ€æœ¯å®ç°ç»†èŠ‚",
                                extend={
                                    "sender": f"å‚ä¸è€…{i+2}",
                                    "meeting_id": f"meeting_{i+2}",
                                },
                            )
                        ],
                        meta={"meeting_type": "technical", "duration": 60},
                    )
                ],
                participants=["å¼ ä¸‰", "æå››", f"å‚ä¸è€…{i+2}"],
                type=DataTypeEnum.MEETING,
                keywords=["æŠ€æœ¯", "è®¨è®º", f"æµ‹è¯•{i+2}"],
                linked_entities=[f"meeting_{i+2}", f"tech_{i+2}"],
            )
            await additional_memcell.insert()
            logger.debug(f"   âœ… åˆ›å»ºç¬¬ {i+2} ä¸ª MemCell")

        # 13. æµ‹è¯•æ‰¹é‡æŸ¥è¯¢
        logger.debug("1ï¸âƒ£3ï¸âƒ£ æµ‹è¯•æ‰¹é‡æŸ¥è¯¢...")
        all_user_memcells = await repository.find_by_user_id(test_user_id)
        logger.debug(
            f"âœ… ç”¨æˆ· {test_user_id} æ€»å…±æœ‰ {len(all_user_memcells)} ä¸ª MemCell"
        )

        # æŒ‰æ—¶é—´æˆ³æ’åºæ˜¾ç¤º
        sorted_memcells = sorted(
            all_user_memcells, key=lambda x: x.timestamp, reverse=True
        )
        for i, memcell in enumerate(sorted_memcells[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
            logger.debug(f"   {i+1}. [{memcell.timestamp}] {memcell.summary[:50]}...")

        # 14. æµ‹è¯•é™åˆ¶æŸ¥è¯¢
        logger.debug("1ï¸âƒ£4ï¸âƒ£ æµ‹è¯•é™åˆ¶æŸ¥è¯¢...")
        limited_memcells = await repository.find_by_user_id(test_user_id, limit=2)
        logger.debug(f"âœ… é™åˆ¶æŸ¥è¯¢è¿”å› {len(limited_memcells)} æ¡è®°å½•")

        # # 15. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("1ï¸âƒ£5ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # deleted_count = await repository.delete_by_user_id(test_user_id)
        # logger.debug(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} æ¡æµ‹è¯•æ•°æ®")

        # # éªŒè¯æ¸…ç†ç»“æœ
        # remaining_memcells = await repository.find_by_user_id(test_user_id)
        # logger.debug(f"âœ… éªŒè¯æ¸…ç†ç»“æœï¼šå‰©ä½™ {len(remaining_memcells)} æ¡è®°å½•")

        logger.debug("ğŸ‰ MemCell æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ MemCell æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_conversation_status_operations():
    """
    æµ‹è¯•å¯¹è¯çŠ¶æ€çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ ConversationStatusRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•å¯¹è¯çŠ¶æ€æ“ä½œ...")

        # è·å–å¯¹è¯çŠ¶æ€ä»“åº“
        repository = get_bean_by_type(ConversationStatusRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– ConversationStatusRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_conversation_id = f"conv_test_{uuid.uuid4().hex[:8]}"
        test_group_id = f"group_test_{uuid.uuid4().hex[:8]}"
        test_timestamp = int(datetime.now().timestamp())

        logger.debug(f"ğŸ“ æµ‹è¯•å¯¹è¯ID: {test_conversation_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•ç¾¤ç»„ID: {test_group_id}")

        # 1. æµ‹è¯•åˆ›å»ºå¯¹è¯çŠ¶æ€
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºå¯¹è¯çŠ¶æ€...")
        conversation_status = ConversationStatus(
            conversation_id=test_conversation_id,
            group_id=test_group_id,
            old_msg_start_time=test_timestamp - 3600,  # 1å°æ—¶å‰
            new_msg_start_time=test_timestamp - 1800,  # 30åˆ†é’Ÿå‰
            last_memcell_time=test_timestamp - 900,  # 15åˆ†é’Ÿå‰
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await conversation_status.create()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºå¯¹è¯çŠ¶æ€: {conversation_status.conversation_id}")

        # 2. æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢...")
        found_status = await repository.get_by_group_id(test_group_id)
        if found_status:
            logger.debug(f"âœ… æŸ¥è¯¢æˆåŠŸ: {found_status.conversation_id}")
            logger.debug(f"   ç¾¤ç»„ID: {found_status.group_id}")
            logger.debug(f"   æ—§æ¶ˆæ¯èµ·å§‹æ—¶é—´: {found_status.old_msg_start_time}")
            logger.debug(f"   æ–°æ¶ˆæ¯èµ·å§‹æ—¶é—´: {found_status.new_msg_start_time}")
            logger.debug(f"   æœ€åMemCellæ—¶é—´: {found_status.last_memcell_time}")
            logger.debug(f"   åˆ›å»ºæ—¶é—´: {found_status.created_at}")
            logger.debug(f"   æ›´æ–°æ—¶é—´: {found_status.updated_at}")
        else:
            logger.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°å¯¹è¯çŠ¶æ€")
            return

        # 3. æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢...")
        found_by_group = await repository.get_by_group_id(test_group_id)
        if found_by_group:
            logger.debug(f"âœ… æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢æˆåŠŸ: {found_by_group.conversation_id}")
            logger.debug(f"   ç¾¤ç»„ID: {found_by_group.group_id}")
            logger.debug(f"   æ—§æ¶ˆæ¯èµ·å§‹æ—¶é—´: {found_by_group.old_msg_start_time}")
        else:
            logger.error("âŒ æ ¹æ®ç¾¤ç»„IDæŸ¥è¯¢å¤±è´¥")

        # 4. æµ‹è¯•æ›´æ–°æ“ä½œ
        logger.debug("4ï¸âƒ£ æµ‹è¯•æ›´æ–°æ“ä½œ...")
        update_data = {
            "old_msg_start_time": test_timestamp - 1800,  # æ›´æ–°ä¸º30åˆ†é’Ÿå‰
            "new_msg_start_time": test_timestamp - 600,  # æ›´æ–°ä¸º10åˆ†é’Ÿå‰
            "last_memcell_time": test_timestamp - 300,  # æ›´æ–°ä¸º5åˆ†é’Ÿå‰
        }

        updated_status = await repository.upsert_by_group_id(test_group_id, update_data)
        if updated_status:
            logger.debug(f"âœ… æ›´æ–°æˆåŠŸ: {updated_status.conversation_id}")
            logger.debug(
                f"   æ›´æ–°åçš„æ—§æ¶ˆæ¯èµ·å§‹æ—¶é—´: {updated_status.old_msg_start_time}"
            )
            logger.debug(
                f"   æ›´æ–°åçš„æ–°æ¶ˆæ¯èµ·å§‹æ—¶é—´: {updated_status.new_msg_start_time}"
            )
            logger.debug(
                f"   æ›´æ–°åçš„æœ€åMemCellæ—¶é—´: {updated_status.last_memcell_time}"
            )
        else:
            logger.error("âŒ æ›´æ–°å¤±è´¥")

        # 5. æµ‹è¯• upsert æ“ä½œï¼ˆæ›´æ–°ç°æœ‰è®°å½•ï¼‰
        logger.debug("5ï¸âƒ£ æµ‹è¯• upsert æ“ä½œï¼ˆæ›´æ–°ç°æœ‰è®°å½•ï¼‰...")
        upsert_data = {
            "old_msg_start_time": test_timestamp - 1200,  # æ›´æ–°ä¸º20åˆ†é’Ÿå‰
            "new_msg_start_time": test_timestamp - 300,  # æ›´æ–°ä¸º5åˆ†é’Ÿå‰
            "last_memcell_time": test_timestamp - 60,  # æ›´æ–°ä¸º1åˆ†é’Ÿå‰
        }

        upserted_status = await repository.upsert_by_group_id(
            test_group_id, upsert_data
        )
        if upserted_status:
            logger.debug(f"âœ… upsert æˆåŠŸ: {upserted_status.conversation_id}")
            logger.debug(
                f"   æ›´æ–°åçš„æ—§æ¶ˆæ¯èµ·å§‹æ—¶é—´: {upserted_status.old_msg_start_time}"
            )
            logger.debug(
                f"   æ›´æ–°åçš„æ–°æ¶ˆæ¯èµ·å§‹æ—¶é—´: {upserted_status.new_msg_start_time}"
            )
            logger.debug(
                f"   æ›´æ–°åçš„æœ€åMemCellæ—¶é—´: {upserted_status.last_memcell_time}"
            )
        else:
            logger.error("âŒ upsert å¤±è´¥")

        # 6. æµ‹è¯•åˆ›å»ºæ–°çš„å¯¹è¯çŠ¶æ€ï¼ˆç”¨äºæµ‹è¯• upsert åˆ›å»ºæ–°è®°å½•ï¼‰
        logger.debug("6ï¸âƒ£ æµ‹è¯•åˆ›å»ºæ–°çš„å¯¹è¯çŠ¶æ€...")
        new_group_id = f"group_new_{uuid.uuid4().hex[:8]}"
        new_upsert_data = {
            "old_msg_start_time": test_timestamp + 3600,  # 1å°æ—¶å
            "new_msg_start_time": test_timestamp + 3600,  # 1å°æ—¶å
            "last_memcell_time": test_timestamp + 3600,  # 1å°æ—¶å
        }

        new_upserted_status = await repository.upsert_by_group_id(
            new_group_id, new_upsert_data
        )
        if new_upserted_status:
            logger.debug(
                f"âœ… æ–°å¯¹è¯çŠ¶æ€åˆ›å»ºæˆåŠŸ: {new_upserted_status.conversation_id}"
            )
            logger.debug(f"   ç¾¤ç»„ID: {new_upserted_status.group_id}")
            logger.debug(f"   æ—§æ¶ˆæ¯èµ·å§‹æ—¶é—´: {new_upserted_status.old_msg_start_time}")
            logger.debug(f"   æ–°æ¶ˆæ¯èµ·å§‹æ—¶é—´: {new_upserted_status.new_msg_start_time}")
            logger.debug(f"   æœ€åMemCellæ—¶é—´: {new_upserted_status.last_memcell_time}")
        else:
            logger.error("âŒ æ–°å¯¹è¯çŠ¶æ€åˆ›å»ºå¤±è´¥")

        # 7. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        logger.debug("7ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        group_count = await repository.count_by_group_id(test_group_id)
        total_count = await repository.count_all()
        logger.debug(
            f"âœ… ç»Ÿè®¡æˆåŠŸ: ç¾¤ç»„å¯¹è¯çŠ¶æ€ {group_count} ä¸ªï¼Œæ€»è®¡ {total_count} ä¸ª"
        )

        # 8. æµ‹è¯•åˆ é™¤æ“ä½œ
        logger.debug("8ï¸âƒ£ æµ‹è¯•åˆ é™¤æ“ä½œ...")
        deleted = await repository.delete_by_group_id(test_group_id)
        if deleted:
            logger.debug(f"âœ… åˆ é™¤æˆåŠŸ: {test_group_id}")
        else:
            logger.error("âŒ åˆ é™¤å¤±è´¥")

        # éªŒè¯åˆ é™¤ç»“æœ
        deleted_status = await repository.get_by_group_id(test_group_id)
        if deleted_status is None:
            logger.debug("âœ… éªŒè¯åˆ é™¤ç»“æœï¼šè®°å½•å·²æˆåŠŸåˆ é™¤")
        else:
            logger.debug("âŒ éªŒè¯åˆ é™¤ç»“æœï¼šè®°å½•æœªå®Œå…¨åˆ é™¤")

        # 9. æµ‹è¯•æ‰¹é‡åˆ›å»ºå’ŒæŸ¥è¯¢
        logger.debug("9ï¸âƒ£ æµ‹è¯•æ‰¹é‡åˆ›å»ºå’ŒæŸ¥è¯¢...")
        for i in range(3):
            batch_conversation_id = f"conv_batch_{i}_{uuid.uuid4().hex[:8]}"
            batch_group_id = f"group_batch_{i}_{uuid.uuid4().hex[:8]}"

            batch_status = ConversationStatus(
                conversation_id=batch_conversation_id,
                group_id=batch_group_id,
                old_msg_start_time=test_timestamp + i * 1800,  # æ¯30åˆ†é’Ÿä¸€ä¸ª
                new_msg_start_time=test_timestamp + i * 1800 + 900,  # 15åˆ†é’Ÿå
                last_memcell_time=test_timestamp + i * 1800 + 1800,  # 30åˆ†é’Ÿå
            )

            await batch_status.create()
            logger.debug(f"   âœ… åˆ›å»ºæ‰¹é‡å¯¹è¯çŠ¶æ€ {i+1}: {batch_conversation_id}")

        # 10. æµ‹è¯•æœ€ç»ˆç»Ÿè®¡
        logger.debug("ğŸ”Ÿ æµ‹è¯•æœ€ç»ˆç»Ÿè®¡...")
        final_total_count = await repository.count_all()
        logger.debug(f"âœ… æœ€ç»ˆç»Ÿè®¡: æ€»è®¡ {final_total_count} ä¸ªå¯¹è¯çŠ¶æ€")

        # # 11. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("1ï¸âƒ£1ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # # æ¸…ç†æ‰¹é‡åˆ›å»ºçš„æµ‹è¯•æ•°æ®
        # for i in range(3):
        #     batch_conversation_id = f"conv_batch_{i}_{uuid.uuid4().hex[:8]}"
        #     await repository.delete_by_conversation_id(batch_conversation_id)
        #
        # # æ¸…ç†æ–°åˆ›å»ºçš„å¯¹è¯çŠ¶æ€
        # await repository.delete_by_conversation_id(new_upserted_status.conversation_id)
        #
        # logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")

        logger.debug("ğŸ‰ å¯¹è¯çŠ¶æ€æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ å¯¹è¯çŠ¶æ€æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def test_employee_organization_operations():
    """
    æµ‹è¯•å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»çš„æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ

    è¯¥å‡½æ•°ç”¨äºéªŒè¯ EmployeeOrganizationRawRepository çš„åŸºæœ¬åŠŸèƒ½
    """
    try:
        logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»æ“ä½œ...")

        # è·å–å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»ä»“åº“
        repository = get_bean_by_type(EmployeeOrganizationRawRepository)
        if not repository:
            logger.error("âŒ æ— æ³•è·å– EmployeeOrganizationRawRepository å®ä¾‹")
            return

        # æµ‹è¯•æ•°æ®
        test_user_id = f"user_org_{uuid.uuid4().hex[:8]}"
        test_email = f"test_{uuid.uuid4().hex[:8]}@company.com"
        test_direct_manager_id = f"manager_{uuid.uuid4().hex[:8]}"
        test_org_id = f"org_{uuid.uuid4().hex[:8]}"

        logger.debug(f"ğŸ“ æµ‹è¯•ç”¨æˆ·ID: {test_user_id}")
        logger.debug(f"ğŸ“ æµ‹è¯•é‚®ç®±: {test_email}")

        # 1. æµ‹è¯•åˆ›å»ºå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»
        logger.debug("1ï¸âƒ£ æµ‹è¯•åˆ›å»ºå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»...")
        employee_organization = EmployeeOrganization(
            full_name="Shan ZHANG",
            team="Tanka",
            user_id=test_user_id,
            email=test_email,
            direct_manager="Si LI",
            direct_manager_id=test_direct_manager_id,
            skip_level_manager="Wu WANG",
            phone="13800138000",
            org_id=test_org_id,
        )

        # æ’å…¥åˆ°æ•°æ®åº“
        await employee_organization.insert()
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»: {employee_organization.full_name}")

        # è·å–ç”Ÿæˆçš„ID
        actual_id = str(employee_organization.id)
        logger.debug(f"ğŸ“ ç”Ÿæˆçš„å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»ID: {actual_id}")

        # 2. æµ‹è¯•æ ¹æ®IDæŸ¥è¯¢
        logger.debug("2ï¸âƒ£ æµ‹è¯•æ ¹æ®IDæŸ¥è¯¢...")
        found_by_id = await repository.get_by_id(actual_id)
        if found_by_id:
            logger.debug(
                f"âœ… æ ¹æ®IDæŸ¥è¯¢æˆåŠŸ: {found_by_id.full_name} - {found_by_id.team}"
            )
            logger.debug(f"   ç”¨æˆ·ID: {found_by_id.user_id}")
            logger.debug(f"   é‚®ç®±: {found_by_id.email}")
            logger.debug(f"   ç›´å±ç»ç†: {found_by_id.direct_manager}")
            logger.debug(f"   éš”çº§ç»ç†: {found_by_id.skip_level_manager}")
            logger.debug(f"   ç»„ç»‡ID: {found_by_id.org_id}")
        else:
            logger.error("âŒ æ ¹æ®IDæŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»")
            return

        # 3. æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("3ï¸âƒ£ æµ‹è¯•æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢...")
        found_by_user_id = await repository.get_by_user_id(test_user_id)
        if found_by_user_id:
            logger.debug(f"âœ… æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢æˆåŠŸ: {found_by_user_id.full_name}")
            logger.debug(f"   å›¢é˜Ÿ: {found_by_user_id.team}")
            logger.debug(f"   é‚®ç®±: {found_by_user_id.email}")
        else:
            logger.error("âŒ æ ¹æ®ç”¨æˆ·IDæŸ¥è¯¢å¤±è´¥ï¼šæœªæ‰¾åˆ°å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»")
            return

        # 4. æµ‹è¯•æ ¹æ®å¤šä¸ªç”¨æˆ·IDæ‰¹é‡æŸ¥è¯¢
        logger.debug("4ï¸âƒ£ æµ‹è¯•æ ¹æ®å¤šä¸ªç”¨æˆ·IDæ‰¹é‡æŸ¥è¯¢...")

        # åˆ›å»ºæ›´å¤šæµ‹è¯•æ•°æ®
        test_user_ids = [test_user_id]
        for i in range(2):
            additional_user_id = f"user_org_{uuid.uuid4().hex[:8]}"
            additional_email = f"test_{uuid.uuid4().hex[:8]}@company.com"

            additional_employee = EmployeeOrganization(
                full_name=f"Employee {i+2}",
                team="Tanka",
                user_id=additional_user_id,
                email=additional_email,
                direct_manager=f"Manager {i+2}",
                phone=f"1380013800{i+1}",
                org_id=test_org_id,
            )

            await additional_employee.insert()
            test_user_ids.append(additional_user_id)
            logger.debug(
                f"   âœ… åˆ›å»ºç¬¬ {i+2} ä¸ªå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»: {additional_employee.full_name}"
            )

        # æ‰¹é‡æŸ¥è¯¢
        batch_results = await repository.get_by_user_ids(test_user_ids)
        logger.debug(f"âœ… æ‰¹é‡æŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {len(batch_results)} ä¸ªå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»")
        for i, emp in enumerate(batch_results):
            logger.debug(f"   {i+1}. {emp.full_name} - {emp.team} - {emp.user_id}")

        # 5. æµ‹è¯•ç©ºåˆ—è¡¨æŸ¥è¯¢
        logger.debug("5ï¸âƒ£ æµ‹è¯•ç©ºåˆ—è¡¨æŸ¥è¯¢...")
        empty_results = await repository.get_by_user_ids([])
        logger.debug(f"âœ… ç©ºåˆ—è¡¨æŸ¥è¯¢æˆåŠŸ: è¿”å› {len(empty_results)} ä¸ªç»“æœ")

        # 6. æµ‹è¯•ä¸å­˜åœ¨çš„ç”¨æˆ·IDæŸ¥è¯¢
        logger.debug("6ï¸âƒ£ æµ‹è¯•ä¸å­˜åœ¨çš„ç”¨æˆ·IDæŸ¥è¯¢...")
        non_existent_user_id = f"non_existent_{uuid.uuid4().hex[:8]}"
        found_non_existent = await repository.get_by_user_id(non_existent_user_id)
        if found_non_existent is None:
            logger.debug("âœ… ä¸å­˜åœ¨çš„ç”¨æˆ·IDæŸ¥è¯¢æ­£ç¡®è¿”å› None")
        else:
            logger.error("âŒ ä¸å­˜åœ¨çš„ç”¨æˆ·IDæŸ¥è¯¢åº”è¯¥è¿”å› None")

        # 7. æµ‹è¯•ä¸å­˜åœ¨çš„IDæŸ¥è¯¢
        logger.debug("7ï¸âƒ£ æµ‹è¯•ä¸å­˜åœ¨çš„IDæŸ¥è¯¢...")
        non_existent_id = "507f1f77bcf86cd799439011"  # æœ‰æ•ˆçš„ObjectIdæ ¼å¼ä½†ä¸å­˜åœ¨
        found_non_existent_id = await repository.get_by_id(non_existent_id)
        if found_non_existent_id is None:
            logger.debug("âœ… ä¸å­˜åœ¨çš„IDæŸ¥è¯¢æ­£ç¡®è¿”å› None")
        else:
            logger.error("âŒ ä¸å­˜åœ¨çš„IDæŸ¥è¯¢åº”è¯¥è¿”å› None")

        # 8. æµ‹è¯•æ— æ•ˆIDæ ¼å¼æŸ¥è¯¢
        logger.debug("8ï¸âƒ£ æµ‹è¯•æ— æ•ˆIDæ ¼å¼æŸ¥è¯¢...")
        try:
            invalid_id = "invalid_id_format"
            found_invalid_id = await repository.get_by_id(invalid_id)
            logger.debug(f"âœ… æ— æ•ˆIDæ ¼å¼æŸ¥è¯¢å¤„ç†æˆåŠŸ: {found_invalid_id}")
        except Exception as e:
            logger.debug(f"âœ… æ— æ•ˆIDæ ¼å¼æŸ¥è¯¢æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {e}")

        # 9. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½ï¼ˆé€šè¿‡æ‰¹é‡æŸ¥è¯¢ç»“æœï¼‰
        logger.debug("9ï¸âƒ£ æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½...")
        all_employees = await repository.get_by_user_ids(test_user_ids)
        logger.debug(
            f"âœ… ç»Ÿè®¡æˆåŠŸ: æµ‹è¯•ç”¨æˆ·ç»„å…±æœ‰ {len(all_employees)} ä¸ªå‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»"
        )

        # æŒ‰å›¢é˜Ÿåˆ†ç»„ç»Ÿè®¡
        team_stats = {}
        for emp in all_employees:
            team = emp.team
            team_stats[team] = team_stats.get(team, 0) + 1
        logger.debug(f"   å›¢é˜Ÿåˆ†å¸ƒ: {team_stats}")

        # 10. æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯
        logger.debug("ğŸ”Ÿ æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯...")
        for emp in all_employees:
            # éªŒè¯å¿…å¡«å­—æ®µ
            assert emp.full_name, "å‘˜å·¥å…¨åä¸èƒ½ä¸ºç©º"
            assert emp.team, "å›¢é˜Ÿä¸èƒ½ä¸ºç©º"
            assert emp.user_id, "ç”¨æˆ·IDä¸èƒ½ä¸ºç©º"
            assert emp.email, "é‚®ç®±ä¸èƒ½ä¸ºç©º"

            # éªŒè¯é‚®ç®±æ ¼å¼
            assert "@" in emp.email, "é‚®ç®±æ ¼å¼ä¸æ­£ç¡®"

            logger.debug(f"   âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡: {emp.full_name}")

        # # 11. æ¸…ç†æµ‹è¯•æ•°æ®
        # logger.debug("1ï¸âƒ£1ï¸âƒ£ æ¸…ç†æµ‹è¯•æ•°æ®...")
        # for emp in all_employees:
        #     await emp.delete()
        #     logger.debug(f"   âœ… åˆ é™¤å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»: {emp.full_name}")
        # logger.debug("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")

        logger.debug("ğŸ‰ å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


async def run_all_tests():
    """
    è¿è¡Œæ‰€æœ‰å†…å­˜æ“ä½œæµ‹è¯•

    åŒ…æ‹¬ï¼š
    - è¯­ä¹‰è®°å¿†æµ‹è¯•
    - æƒ…æ™¯è®°å¿†æµ‹è¯•
    - æ ¸å¿ƒè®°å¿†æµ‹è¯•
    - å®ä½“åº“æµ‹è¯•
    - å…³ç³»åº“æµ‹è¯•
    - è¡Œä¸ºå†å²æµ‹è¯•
    - MemCell æµ‹è¯•
    - å¯¹è¯çŠ¶æ€æµ‹è¯•
    - å‘˜å·¥ç»„ç»‡æ¶æ„å…³ç³»æµ‹è¯•
    """
    try:
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰å†…å­˜æ“ä½œæµ‹è¯•...")

        # è¿è¡Œå„ä¸ªæµ‹è¯•
        await test_semantic_memory_operations()
        await test_episodic_memory_operations()
        await test_core_memory_operations()
        await test_entity_operations()
        await test_relationship_operations()
        await test_behavior_history_operations()
        await test_memcell_operations()
        await test_conversation_status_operations()
        await test_employee_organization_operations()

        logger.info("ğŸ‰ æ‰€æœ‰å†…å­˜æ“ä½œæµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ è¿è¡Œæ‰€æœ‰æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    """
    ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    """
    import asyncio

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    asyncio.run(run_all_tests())
